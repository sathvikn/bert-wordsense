{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Selecting Words from Set of High-Entropy SEMCOR Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/randscore_entropy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['num_senses'] > 2) & (df['Principle Components'] == 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "164"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>Principle Components</th>\n",
       "      <th>WordNet Mean_tsne</th>\n",
       "      <th>WordNet SD_tsne</th>\n",
       "      <th>Random Mean_tsne</th>\n",
       "      <th>Random SD_tsne</th>\n",
       "      <th>WordNet Mean_pca</th>\n",
       "      <th>WordNet SD_pca</th>\n",
       "      <th>Random Mean_pca</th>\n",
       "      <th>Random SD_pca</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_senses</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>v</th>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Lemma  Principle Components  WordNet Mean_tsne  WordNet SD_tsne  \\\n",
       "pos                                                                    \n",
       "a        3                     3                  3                3   \n",
       "n       48                    48                 48               48   \n",
       "r        6                     6                  6                6   \n",
       "s        2                     2                  2                2   \n",
       "v      105                   105                105              105   \n",
       "\n",
       "     Random Mean_tsne  Random SD_tsne  WordNet Mean_pca  WordNet SD_pca  \\\n",
       "pos                                                                       \n",
       "a                   3               3                 3               3   \n",
       "n                  48              48                48              48   \n",
       "r                   6               6                 6               6   \n",
       "s                   2               2                 2               2   \n",
       "v                 105             105               105             105   \n",
       "\n",
       "     Random Mean_pca  Random SD_pca  entropy  num_senses  freq  \n",
       "pos                                                             \n",
       "a                  3              3        3           3     3  \n",
       "n                 48             48       48          48    48  \n",
       "r                  6              6        6           6     6  \n",
       "s                  2              2        2           2     2  \n",
       "v                105            105      105         105   105  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pos = lambda l: l.split('.')[1]\n",
    "df['pos'] = df['Lemma'].apply(get_pos)\n",
    "df.groupby(\"pos\").agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['pos'].isin(['v', 'n'])]\n",
    "df = df[['Lemma', 'entropy', 'num_senses', 'freq', 'pos']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_senses</th>\n",
       "      <th>freq</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thing.n</td>\n",
       "      <td>2.812869</td>\n",
       "      <td>8</td>\n",
       "      <td>264</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>life.n</td>\n",
       "      <td>2.040158</td>\n",
       "      <td>5</td>\n",
       "      <td>217</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>time.n</td>\n",
       "      <td>2.002842</td>\n",
       "      <td>5</td>\n",
       "      <td>505</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>trouble.n</td>\n",
       "      <td>1.973889</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>line.n</td>\n",
       "      <td>1.912234</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>death.n</td>\n",
       "      <td>1.894325</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>world.n</td>\n",
       "      <td>1.865668</td>\n",
       "      <td>4</td>\n",
       "      <td>202</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>force.n</td>\n",
       "      <td>1.861400</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>system.n</td>\n",
       "      <td>1.832076</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>history.n</td>\n",
       "      <td>1.798130</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>change.n</td>\n",
       "      <td>1.781964</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>end.n</td>\n",
       "      <td>1.772543</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>side.n</td>\n",
       "      <td>1.767755</td>\n",
       "      <td>5</td>\n",
       "      <td>129</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>section.n</td>\n",
       "      <td>1.746882</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>day.n</td>\n",
       "      <td>1.744650</td>\n",
       "      <td>4</td>\n",
       "      <td>313</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>place.n</td>\n",
       "      <td>1.718519</td>\n",
       "      <td>4</td>\n",
       "      <td>141</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>state.n</td>\n",
       "      <td>1.651143</td>\n",
       "      <td>4</td>\n",
       "      <td>190</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>part.n</td>\n",
       "      <td>1.612206</td>\n",
       "      <td>4</td>\n",
       "      <td>188</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>spirit.n</td>\n",
       "      <td>1.569815</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>course.n</td>\n",
       "      <td>1.566352</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>expression.n</td>\n",
       "      <td>1.559790</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>direction.n</td>\n",
       "      <td>1.543730</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>corner.n</td>\n",
       "      <td>1.541524</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>experience.n</td>\n",
       "      <td>1.535854</td>\n",
       "      <td>3</td>\n",
       "      <td>125</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>stage.n</td>\n",
       "      <td>1.535657</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>performance.n</td>\n",
       "      <td>1.523350</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>space.n</td>\n",
       "      <td>1.518751</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>sense.n</td>\n",
       "      <td>1.496387</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>item.n</td>\n",
       "      <td>1.491512</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>answer.n</td>\n",
       "      <td>1.489527</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>sound.n</td>\n",
       "      <td>1.471293</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>game.n</td>\n",
       "      <td>1.470731</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>party.n</td>\n",
       "      <td>1.454181</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>heart.n</td>\n",
       "      <td>1.442482</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>light.n</td>\n",
       "      <td>1.415633</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>point.n</td>\n",
       "      <td>1.413418</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>position.n</td>\n",
       "      <td>1.392461</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>field.n</td>\n",
       "      <td>1.391613</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>value.n</td>\n",
       "      <td>1.360964</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>quality.n</td>\n",
       "      <td>1.344250</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>result.n</td>\n",
       "      <td>1.327661</td>\n",
       "      <td>3</td>\n",
       "      <td>131</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>source.n</td>\n",
       "      <td>1.325752</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>case.n</td>\n",
       "      <td>1.211936</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>surface.n</td>\n",
       "      <td>1.201350</td>\n",
       "      <td>3</td>\n",
       "      <td>136</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>man.n</td>\n",
       "      <td>1.187622</td>\n",
       "      <td>4</td>\n",
       "      <td>638</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>interest.n</td>\n",
       "      <td>1.104984</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>area.n</td>\n",
       "      <td>1.002968</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>way.n</td>\n",
       "      <td>0.728521</td>\n",
       "      <td>3</td>\n",
       "      <td>269</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lemma   entropy  num_senses  freq pos\n",
       "0          thing.n  2.812869           8   264   n\n",
       "20          life.n  2.040158           5   217   n\n",
       "24          time.n  2.002842           5   505   n\n",
       "28       trouble.n  1.973889           4    61   n\n",
       "36          line.n  1.912234           5   100   n\n",
       "44         death.n  1.894325           4   103   n\n",
       "52         world.n  1.865668           4   202   n\n",
       "54         force.n  1.861400           4    84   n\n",
       "60        system.n  1.832076           4    98   n\n",
       "64       history.n  1.798130           4    99   n\n",
       "68        change.n  1.781964           4   103   n\n",
       "70           end.n  1.772543           4   112   n\n",
       "72          side.n  1.767755           5   129   n\n",
       "80       section.n  1.746882           4    95   n\n",
       "82           day.n  1.744650           4   313   n\n",
       "84         place.n  1.718519           4   141   n\n",
       "94         state.n  1.651143           4   190   n\n",
       "96          part.n  1.612206           4   188   n\n",
       "110       spirit.n  1.569815           3    68   n\n",
       "118       course.n  1.566352           4    99   n\n",
       "124   expression.n  1.559790           3    46   n\n",
       "126    direction.n  1.543730           3    48   n\n",
       "128       corner.n  1.541524           3    45   n\n",
       "132   experience.n  1.535854           3   125   n\n",
       "134        stage.n  1.535657           3    59   n\n",
       "144  performance.n  1.523350           3    59   n\n",
       "150        space.n  1.518751           3    59   n\n",
       "164        sense.n  1.496387           3    80   n\n",
       "166         item.n  1.491512           3    63   n\n",
       "170       answer.n  1.489527           3    58   n\n",
       "184        sound.n  1.471293           3    53   n\n",
       "186         game.n  1.470731           3    76   n\n",
       "192        party.n  1.454181           3    54   n\n",
       "198        heart.n  1.442482           3    66   n\n",
       "212        light.n  1.415633           3    77   n\n",
       "214        point.n  1.413418           3   118   n\n",
       "228     position.n  1.392461           3    73   n\n",
       "232        field.n  1.391613           3    81   n\n",
       "240        value.n  1.360964           3   130   n\n",
       "250      quality.n  1.344250           3    70   n\n",
       "262       result.n  1.327661           3   131   n\n",
       "264       source.n  1.325752           3    67   n\n",
       "278         case.n  1.211936           3   127   n\n",
       "282      surface.n  1.201350           3   136   n\n",
       "284          man.n  1.187622           4   638   n\n",
       "298     interest.n  1.104984           3   126   n\n",
       "302         area.n  1.002968           3   200   n\n",
       "818          way.n  0.728521           3   269   n"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns = df[df['pos'] == 'n']\n",
    "nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_senses</th>\n",
       "      <th>freq</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meet.v</td>\n",
       "      <td>2.774648</td>\n",
       "      <td>9</td>\n",
       "      <td>214</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lead.v</td>\n",
       "      <td>2.684982</td>\n",
       "      <td>7</td>\n",
       "      <td>170</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>serve.v</td>\n",
       "      <td>2.359147</td>\n",
       "      <td>6</td>\n",
       "      <td>194</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>give.v</td>\n",
       "      <td>2.268538</td>\n",
       "      <td>9</td>\n",
       "      <td>704</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>raise.v</td>\n",
       "      <td>2.234669</td>\n",
       "      <td>5</td>\n",
       "      <td>111</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>pay.v</td>\n",
       "      <td>0.913283</td>\n",
       "      <td>3</td>\n",
       "      <td>190</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>believe.v</td>\n",
       "      <td>0.889375</td>\n",
       "      <td>3</td>\n",
       "      <td>215</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>help.v</td>\n",
       "      <td>0.877312</td>\n",
       "      <td>3</td>\n",
       "      <td>226</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>expect.v</td>\n",
       "      <td>0.816499</td>\n",
       "      <td>3</td>\n",
       "      <td>234</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>appear.v</td>\n",
       "      <td>0.711120</td>\n",
       "      <td>3</td>\n",
       "      <td>230</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lemma   entropy  num_senses  freq pos\n",
       "2       meet.v  2.774648           9   214   v\n",
       "4       lead.v  2.684982           7   170   v\n",
       "6      serve.v  2.359147           6   194   v\n",
       "8       give.v  2.268538           9   704   v\n",
       "10     raise.v  2.234669           5   111   v\n",
       "..         ...       ...         ...   ...  ..\n",
       "628      pay.v  0.913283           3   190   v\n",
       "688  believe.v  0.889375           3   215   v\n",
       "700     help.v  0.877312           3   226   v\n",
       "768   expect.v  0.816499           3   234   v\n",
       "830   appear.v  0.711120           3   230   v\n",
       "\n",
       "[105 rows x 5 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs = df[df['pos'] == 'v']\n",
    "verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /anaconda3/envs/bert/lib/python3.7/site-packages (0.10.0)\n",
      "Requirement already satisfied: matplotlib>=2.1.2 in /anaconda3/envs/bert/lib/python3.7/site-packages (from seaborn) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /anaconda3/envs/bert/lib/python3.7/site-packages (from seaborn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in /anaconda3/envs/bert/lib/python3.7/site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: pandas>=0.22.0 in /anaconda3/envs/bert/lib/python3.7/site-packages (from seaborn) (0.25.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /anaconda3/envs/bert/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (2.4.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /anaconda3/envs/bert/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /anaconda3/envs/bert/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /anaconda3/envs/bert/lib/python3.7/site-packages (from matplotlib>=2.1.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /anaconda3/envs/bert/lib/python3.7/site-packages (from pandas>=0.22.0->seaborn) (2019.3)\n",
      "Requirement already satisfied: six in /anaconda3/envs/bert/lib/python3.7/site-packages (from cycler>=0.10->matplotlib>=2.1.2->seaborn) (1.13.0)\n",
      "Requirement already satisfied: setuptools in /anaconda3/envs/bert/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib>=2.1.2->seaborn) (44.0.0.post20200106)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir ../data/figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(nouns['num_senses'], alpha = 0.5, label = \"Nouns\")\n",
    "plt.hist(verbs['num_senses'], alpha = 0.5, label = \"Verbs\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of Senses\")\n",
    "plt.ylabel(\"Number of Lemmas\")\n",
    "plt.title(\"Lemmas with Number of Senses\")\n",
    "plt.savefig(\"../data/figures/numsensehist.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(tips, col=\"num_senses\")\n",
    "g = g.map(plt.hist, \"num_\", bins=bins, color=\"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nounplot = sns.jointplot(x=\"entropy\", y=\"freq\", data=nouns)\n",
    "nounplot.set_axis_labels('Entropy', 'Frequency in Semcor')\n",
    "#plt.subplots_adjust(top=0.9, left = 0.2)\n",
    "nounplot.fig.suptitle(\"Entropy and Frequency for Nouns with 3+ Senses\", y=1.04)\n",
    "plt.savefig(\"../data/figures/nounentfreq.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "verbplot = sns.jointplot(x=\"entropy\", y=\"freq\", data=verbs)\n",
    "nounplot.set_axis_labels('Entropy', 'Frequency in Semcor')\n",
    "#plt.subplots_adjust(top=0.9, left = 0.2)\n",
    "nounplot.fig.suptitle(\"Entropy and Frequency for Verbs with 3+ Senses\", y=1.04)\n",
    "plt.savefig(\"../data/figures/verbentfreq.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    67\n",
       "4    18\n",
       "5    13\n",
       "7     3\n",
       "9     2\n",
       "6     2\n",
       "Name: num_senses, dtype: int64"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs['num_senses'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    28\n",
       "4    15\n",
       "5     4\n",
       "8     1\n",
       "Name: num_senses, dtype: int64"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns['num_senses'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_senses</th>\n",
       "      <th>freq</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thing.n</td>\n",
       "      <td>2.812869</td>\n",
       "      <td>8</td>\n",
       "      <td>264</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Lemma   entropy  num_senses  freq pos\n",
       "0  thing.n  2.812869           8   264   n"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns[nouns['num_senses'] == 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_senses</th>\n",
       "      <th>freq</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meet.v</td>\n",
       "      <td>2.774648</td>\n",
       "      <td>9</td>\n",
       "      <td>214</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lead.v</td>\n",
       "      <td>2.684982</td>\n",
       "      <td>7</td>\n",
       "      <td>170</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>serve.v</td>\n",
       "      <td>2.359147</td>\n",
       "      <td>6</td>\n",
       "      <td>194</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>give.v</td>\n",
       "      <td>2.268538</td>\n",
       "      <td>9</td>\n",
       "      <td>704</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>raise.v</td>\n",
       "      <td>2.234669</td>\n",
       "      <td>5</td>\n",
       "      <td>111</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cover.v</td>\n",
       "      <td>2.159471</td>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>play.v</td>\n",
       "      <td>2.151680</td>\n",
       "      <td>5</td>\n",
       "      <td>205</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>grow.v</td>\n",
       "      <td>2.103438</td>\n",
       "      <td>5</td>\n",
       "      <td>157</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>apply.v</td>\n",
       "      <td>2.069493</td>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>follow.v</td>\n",
       "      <td>2.018523</td>\n",
       "      <td>7</td>\n",
       "      <td>243</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>find.v</td>\n",
       "      <td>1.996950</td>\n",
       "      <td>6</td>\n",
       "      <td>663</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>make.v</td>\n",
       "      <td>1.903911</td>\n",
       "      <td>7</td>\n",
       "      <td>1401</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>show.v</td>\n",
       "      <td>1.896588</td>\n",
       "      <td>5</td>\n",
       "      <td>424</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>feel.v</td>\n",
       "      <td>1.894922</td>\n",
       "      <td>5</td>\n",
       "      <td>403</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>reach.v</td>\n",
       "      <td>1.878220</td>\n",
       "      <td>5</td>\n",
       "      <td>213</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>write.v</td>\n",
       "      <td>1.835113</td>\n",
       "      <td>5</td>\n",
       "      <td>271</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>receive.v</td>\n",
       "      <td>1.756106</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>know.v</td>\n",
       "      <td>1.603402</td>\n",
       "      <td>5</td>\n",
       "      <td>872</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>go.v</td>\n",
       "      <td>1.568681</td>\n",
       "      <td>5</td>\n",
       "      <td>461</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>keep.v</td>\n",
       "      <td>1.335392</td>\n",
       "      <td>5</td>\n",
       "      <td>303</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lemma   entropy  num_senses  freq pos\n",
       "2       meet.v  2.774648           9   214   v\n",
       "4       lead.v  2.684982           7   170   v\n",
       "6      serve.v  2.359147           6   194   v\n",
       "8       give.v  2.268538           9   704   v\n",
       "10     raise.v  2.234669           5   111   v\n",
       "12     cover.v  2.159471           5   118   v\n",
       "14      play.v  2.151680           5   205   v\n",
       "16      grow.v  2.103438           5   157   v\n",
       "18     apply.v  2.069493           5   116   v\n",
       "22    follow.v  2.018523           7   243   v\n",
       "26      find.v  1.996950           6   663   v\n",
       "38      make.v  1.903911           7  1401   v\n",
       "40      show.v  1.896588           5   424   v\n",
       "42      feel.v  1.894922           5   403   v\n",
       "48     reach.v  1.878220           5   213   v\n",
       "58     write.v  1.835113           5   271   v\n",
       "78   receive.v  1.756106           5   200   v\n",
       "98      know.v  1.603402           5   872   v\n",
       "114       go.v  1.568681           5   461   v\n",
       "252     keep.v  1.335392           5   303   v"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs[verbs['num_senses'].isin(np.arange(5, 10))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_senses</th>\n",
       "      <th>freq</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thing.n</td>\n",
       "      <td>2.812869</td>\n",
       "      <td>8</td>\n",
       "      <td>264</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>life.n</td>\n",
       "      <td>2.040158</td>\n",
       "      <td>5</td>\n",
       "      <td>217</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>time.n</td>\n",
       "      <td>2.002842</td>\n",
       "      <td>5</td>\n",
       "      <td>505</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>trouble.n</td>\n",
       "      <td>1.973889</td>\n",
       "      <td>4</td>\n",
       "      <td>61</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>line.n</td>\n",
       "      <td>1.912234</td>\n",
       "      <td>5</td>\n",
       "      <td>100</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>death.n</td>\n",
       "      <td>1.894325</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>world.n</td>\n",
       "      <td>1.865668</td>\n",
       "      <td>4</td>\n",
       "      <td>202</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>force.n</td>\n",
       "      <td>1.861400</td>\n",
       "      <td>4</td>\n",
       "      <td>84</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>system.n</td>\n",
       "      <td>1.832076</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>history.n</td>\n",
       "      <td>1.798130</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>change.n</td>\n",
       "      <td>1.781964</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>end.n</td>\n",
       "      <td>1.772543</td>\n",
       "      <td>4</td>\n",
       "      <td>112</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>side.n</td>\n",
       "      <td>1.767755</td>\n",
       "      <td>5</td>\n",
       "      <td>129</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>section.n</td>\n",
       "      <td>1.746882</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>day.n</td>\n",
       "      <td>1.744650</td>\n",
       "      <td>4</td>\n",
       "      <td>313</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>place.n</td>\n",
       "      <td>1.718519</td>\n",
       "      <td>4</td>\n",
       "      <td>141</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>state.n</td>\n",
       "      <td>1.651143</td>\n",
       "      <td>4</td>\n",
       "      <td>190</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>part.n</td>\n",
       "      <td>1.612206</td>\n",
       "      <td>4</td>\n",
       "      <td>188</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>course.n</td>\n",
       "      <td>1.566352</td>\n",
       "      <td>4</td>\n",
       "      <td>99</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>man.n</td>\n",
       "      <td>1.187622</td>\n",
       "      <td>4</td>\n",
       "      <td>638</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lemma   entropy  num_senses  freq pos\n",
       "0      thing.n  2.812869           8   264   n\n",
       "20      life.n  2.040158           5   217   n\n",
       "24      time.n  2.002842           5   505   n\n",
       "28   trouble.n  1.973889           4    61   n\n",
       "36      line.n  1.912234           5   100   n\n",
       "44     death.n  1.894325           4   103   n\n",
       "52     world.n  1.865668           4   202   n\n",
       "54     force.n  1.861400           4    84   n\n",
       "60    system.n  1.832076           4    98   n\n",
       "64   history.n  1.798130           4    99   n\n",
       "68    change.n  1.781964           4   103   n\n",
       "70       end.n  1.772543           4   112   n\n",
       "72      side.n  1.767755           5   129   n\n",
       "80   section.n  1.746882           4    95   n\n",
       "82       day.n  1.744650           4   313   n\n",
       "84     place.n  1.718519           4   141   n\n",
       "94     state.n  1.651143           4   190   n\n",
       "96      part.n  1.612206           4   188   n\n",
       "118   course.n  1.566352           4    99   n\n",
       "284      man.n  1.187622           4   638   n"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns[nouns['num_senses'] != 3].sort_values('entropy', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_words = ['life.n', 'lead.v', 'time.n', 'world.n', 'death.n', 'man.n', 'begin.v', 'cover.v', 'raise.v', 'drive.v',\n",
    "    'ask.v', 'indicate.v', 'put.v', 'produce.v', 'consider.v', 'way.n', 'area.n', 'point.n', 'light.n', 'case.n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_senses</th>\n",
       "      <th>freq</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lead.v</td>\n",
       "      <td>2.684982</td>\n",
       "      <td>7</td>\n",
       "      <td>170</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>raise.v</td>\n",
       "      <td>2.234669</td>\n",
       "      <td>5</td>\n",
       "      <td>111</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cover.v</td>\n",
       "      <td>2.159471</td>\n",
       "      <td>5</td>\n",
       "      <td>118</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>life.n</td>\n",
       "      <td>2.040158</td>\n",
       "      <td>5</td>\n",
       "      <td>217</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>time.n</td>\n",
       "      <td>2.002842</td>\n",
       "      <td>5</td>\n",
       "      <td>505</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>death.n</td>\n",
       "      <td>1.894325</td>\n",
       "      <td>4</td>\n",
       "      <td>103</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>world.n</td>\n",
       "      <td>1.865668</td>\n",
       "      <td>4</td>\n",
       "      <td>202</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>drive.v</td>\n",
       "      <td>1.683292</td>\n",
       "      <td>4</td>\n",
       "      <td>106</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>indicate.v</td>\n",
       "      <td>1.572229</td>\n",
       "      <td>3</td>\n",
       "      <td>177</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>produce.v</td>\n",
       "      <td>1.473220</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>light.n</td>\n",
       "      <td>1.415633</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>point.n</td>\n",
       "      <td>1.413418</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>put.v</td>\n",
       "      <td>1.402340</td>\n",
       "      <td>3</td>\n",
       "      <td>257</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>consider.v</td>\n",
       "      <td>1.394831</td>\n",
       "      <td>3</td>\n",
       "      <td>229</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>begin.v</td>\n",
       "      <td>1.300172</td>\n",
       "      <td>4</td>\n",
       "      <td>390</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>case.n</td>\n",
       "      <td>1.211936</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>man.n</td>\n",
       "      <td>1.187622</td>\n",
       "      <td>4</td>\n",
       "      <td>638</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>ask.v</td>\n",
       "      <td>1.178508</td>\n",
       "      <td>3</td>\n",
       "      <td>408</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>area.n</td>\n",
       "      <td>1.002968</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>way.n</td>\n",
       "      <td>0.728521</td>\n",
       "      <td>3</td>\n",
       "      <td>269</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Lemma   entropy  num_senses  freq pos\n",
       "4        lead.v  2.684982           7   170   v\n",
       "10      raise.v  2.234669           5   111   v\n",
       "12      cover.v  2.159471           5   118   v\n",
       "20       life.n  2.040158           5   217   n\n",
       "24       time.n  2.002842           5   505   n\n",
       "44      death.n  1.894325           4   103   n\n",
       "52      world.n  1.865668           4   202   n\n",
       "90      drive.v  1.683292           4   106   v\n",
       "108  indicate.v  1.572229           3   177   v\n",
       "178   produce.v  1.473220           3   130   v\n",
       "212     light.n  1.415633           3    77   n\n",
       "214     point.n  1.413418           3   118   n\n",
       "224       put.v  1.402340           3   257   v\n",
       "226  consider.v  1.394831           3   229   v\n",
       "268     begin.v  1.300172           4   390   v\n",
       "278      case.n  1.211936           3   127   n\n",
       "284       man.n  1.187622           4   638   n\n",
       "288       ask.v  1.178508           3   408   v\n",
       "302      area.n  1.002968           3   200   n\n",
       "818       way.n  0.728521           3   269   n"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Lemma'].isin(sel_words)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['Lemma'].isin(sel_words)].to_csv('../data/expt_semcor_types.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_senses</th>\n",
       "      <th>freq</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>ask.v</td>\n",
       "      <td>1.178508</td>\n",
       "      <td>3</td>\n",
       "      <td>408</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>look.v</td>\n",
       "      <td>1.207066</td>\n",
       "      <td>3</td>\n",
       "      <td>361</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>include.v</td>\n",
       "      <td>0.916274</td>\n",
       "      <td>3</td>\n",
       "      <td>292</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>put.v</td>\n",
       "      <td>1.402340</td>\n",
       "      <td>3</td>\n",
       "      <td>257</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>live.v</td>\n",
       "      <td>1.158151</td>\n",
       "      <td>3</td>\n",
       "      <td>235</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>suffer.v</td>\n",
       "      <td>1.584432</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>gain.v</td>\n",
       "      <td>1.500788</td>\n",
       "      <td>3</td>\n",
       "      <td>51</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>break.v</td>\n",
       "      <td>1.516624</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>hang.v</td>\n",
       "      <td>1.454751</td>\n",
       "      <td>3</td>\n",
       "      <td>50</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>paint.v</td>\n",
       "      <td>1.565574</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Lemma   entropy  num_senses  freq pos\n",
       "288      ask.v  1.178508           3   408   v\n",
       "280     look.v  1.207066           3   361   v\n",
       "624  include.v  0.916274           3   292   v\n",
       "224      put.v  1.402340           3   257   v\n",
       "290     live.v  1.158151           3   235   v\n",
       "..         ...       ...         ...   ...  ..\n",
       "100   suffer.v  1.584432           3    52   v\n",
       "162     gain.v  1.500788           3    51   v\n",
       "154    break.v  1.516624           3    50   v\n",
       "190     hang.v  1.454751           3    50   v\n",
       "120    paint.v  1.565574           3    39   v\n",
       "\n",
       "[67 rows x 5 columns]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs[verbs['num_senses'] == 3].sort_values('freq', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lemma</th>\n",
       "      <th>entropy</th>\n",
       "      <th>num_senses</th>\n",
       "      <th>freq</th>\n",
       "      <th>pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>way.n</td>\n",
       "      <td>0.728521</td>\n",
       "      <td>3</td>\n",
       "      <td>269</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>area.n</td>\n",
       "      <td>1.002968</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>surface.n</td>\n",
       "      <td>1.201350</td>\n",
       "      <td>3</td>\n",
       "      <td>136</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>result.n</td>\n",
       "      <td>1.327661</td>\n",
       "      <td>3</td>\n",
       "      <td>131</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>value.n</td>\n",
       "      <td>1.360964</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>case.n</td>\n",
       "      <td>1.211936</td>\n",
       "      <td>3</td>\n",
       "      <td>127</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>interest.n</td>\n",
       "      <td>1.104984</td>\n",
       "      <td>3</td>\n",
       "      <td>126</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>experience.n</td>\n",
       "      <td>1.535854</td>\n",
       "      <td>3</td>\n",
       "      <td>125</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>point.n</td>\n",
       "      <td>1.413418</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>field.n</td>\n",
       "      <td>1.391613</td>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>sense.n</td>\n",
       "      <td>1.496387</td>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>light.n</td>\n",
       "      <td>1.415633</td>\n",
       "      <td>3</td>\n",
       "      <td>77</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>game.n</td>\n",
       "      <td>1.470731</td>\n",
       "      <td>3</td>\n",
       "      <td>76</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>position.n</td>\n",
       "      <td>1.392461</td>\n",
       "      <td>3</td>\n",
       "      <td>73</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>quality.n</td>\n",
       "      <td>1.344250</td>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>spirit.n</td>\n",
       "      <td>1.569815</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>source.n</td>\n",
       "      <td>1.325752</td>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>heart.n</td>\n",
       "      <td>1.442482</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>item.n</td>\n",
       "      <td>1.491512</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>space.n</td>\n",
       "      <td>1.518751</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>performance.n</td>\n",
       "      <td>1.523350</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>stage.n</td>\n",
       "      <td>1.535657</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>answer.n</td>\n",
       "      <td>1.489527</td>\n",
       "      <td>3</td>\n",
       "      <td>58</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>party.n</td>\n",
       "      <td>1.454181</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>sound.n</td>\n",
       "      <td>1.471293</td>\n",
       "      <td>3</td>\n",
       "      <td>53</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>direction.n</td>\n",
       "      <td>1.543730</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>expression.n</td>\n",
       "      <td>1.559790</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>corner.n</td>\n",
       "      <td>1.541524</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Lemma   entropy  num_senses  freq pos\n",
       "818          way.n  0.728521           3   269   n\n",
       "302         area.n  1.002968           3   200   n\n",
       "282      surface.n  1.201350           3   136   n\n",
       "262       result.n  1.327661           3   131   n\n",
       "240        value.n  1.360964           3   130   n\n",
       "278         case.n  1.211936           3   127   n\n",
       "298     interest.n  1.104984           3   126   n\n",
       "132   experience.n  1.535854           3   125   n\n",
       "214        point.n  1.413418           3   118   n\n",
       "232        field.n  1.391613           3    81   n\n",
       "164        sense.n  1.496387           3    80   n\n",
       "212        light.n  1.415633           3    77   n\n",
       "186         game.n  1.470731           3    76   n\n",
       "228     position.n  1.392461           3    73   n\n",
       "250      quality.n  1.344250           3    70   n\n",
       "110       spirit.n  1.569815           3    68   n\n",
       "264       source.n  1.325752           3    67   n\n",
       "198        heart.n  1.442482           3    66   n\n",
       "166         item.n  1.491512           3    63   n\n",
       "150        space.n  1.518751           3    59   n\n",
       "144  performance.n  1.523350           3    59   n\n",
       "134        stage.n  1.535657           3    59   n\n",
       "170       answer.n  1.489527           3    58   n\n",
       "192        party.n  1.454181           3    54   n\n",
       "184        sound.n  1.471293           3    53   n\n",
       "126    direction.n  1.543730           3    48   n\n",
       "124   expression.n  1.559790           3    46   n\n",
       "128       corner.n  1.541524           3    45   n"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns[nouns['num_senses'] == 3].sort_values('freq', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 7.,  8., 21., 57., 22., 23.,  9.,  3.,  0.,  3.]),\n",
       " array([0.71112038, 0.92129519, 1.13147   , 1.34164482, 1.55181963,\n",
       "        1.76199444, 1.97216926, 2.18234407, 2.39251888, 2.6026937 ,\n",
       "        2.81286851]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df['entropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Words showing Polysemous Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = pd.read_csv('../data/semcor_tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>word</th>\n",
       "      <th>pos</th>\n",
       "      <th>sense</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lemma('group.n.01.group')</td>\n",
       "      <td>group</td>\n",
       "      <td>n</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lemma('state.v.01.say')</td>\n",
       "      <td>say</td>\n",
       "      <td>v</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lemma('friday.n.01.Friday')</td>\n",
       "      <td>Friday</td>\n",
       "      <td>n</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lemma('probe.n.01.investigation')</td>\n",
       "      <td>investigation</td>\n",
       "      <td>n</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lemma('atlanta.n.01.Atlanta')</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>n</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235074</th>\n",
       "      <td>Lemma('be.v.01.be')</td>\n",
       "      <td>be</td>\n",
       "      <td>v</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235075</th>\n",
       "      <td>Lemma('let.v.01.let')</td>\n",
       "      <td>let</td>\n",
       "      <td>v</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235076</th>\n",
       "      <td>Lemma('make.v.01.make')</td>\n",
       "      <td>make</td>\n",
       "      <td>v</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235077</th>\n",
       "      <td>turn_into.v.00</td>\n",
       "      <td>turn_into</td>\n",
       "      <td>v</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235078</th>\n",
       "      <td>Lemma('state.v.01.say')</td>\n",
       "      <td>say</td>\n",
       "      <td>v</td>\n",
       "      <td>01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235079 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    lemma           word pos sense\n",
       "0               Lemma('group.n.01.group')          group   n    01\n",
       "1                 Lemma('state.v.01.say')            say   v    01\n",
       "2             Lemma('friday.n.01.Friday')         Friday   n    01\n",
       "3       Lemma('probe.n.01.investigation')  investigation   n    01\n",
       "4           Lemma('atlanta.n.01.Atlanta')        Atlanta   n    01\n",
       "...                                   ...            ...  ..   ...\n",
       "235074                Lemma('be.v.01.be')             be   v    01\n",
       "235075              Lemma('let.v.01.let')            let   v    01\n",
       "235076            Lemma('make.v.01.make')           make   v    01\n",
       "235077                     turn_into.v.00      turn_into   v    00\n",
       "235078            Lemma('state.v.01.say')            say   v    01\n",
       "\n",
       "[235079 rows x 4 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_type_cnts(word, pos):\n",
    "    df = tags[(tags['word'] == word) & (tags['pos'] == pos)]\n",
    "    sense_freqs = df.groupby('sense').agg('count')\n",
    "    return sense_freqs.drop(['word', 'pos'], axis = 1).rename({'lemma':'freq'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "01       47\n",
       "02       10\n",
       "05        2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('book', 'n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RepCont: book.n, 1 is the contents, 2 is physical object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prd: newspaper.n, 1 is the newspaper, 2 is the company, only picked this because it was also in RepCont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "01       23\n",
       "02       12\n",
       "03        4"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('glass', 'n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MatArt: glass.n, 1 is material, 2 is container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2;1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "00        1\n",
       "01      131\n",
       "03        4\n",
       "2;1       1"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('door', 'n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks confusing so we'll call the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = SemCorSelector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senses for word door.n\n",
      "Number of sentences for sense Synset('door.n.03') 4\n",
      "Number of sentences for sense Synset('door.n.01') 97\n",
      "Number of sentences for sense Synset('doorway.n.01') 34\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['The suburban branch is thereby credited with a sale which would have been made even if its glass doors had never opened .',\n",
       "  'On all sides doors were being slammed in his face .',\n",
       "  'His broad interest in literary , political , and philosophical movements opened many doors to him .',\n",
       "  'When words can be used in a more fresh and primitive way so that they strike with the force of sights and sounds , when tones of sound and colors of paint and the carven shape all strike the sensibilities with an undeniable force of data in and of themselves , compelling the observer into an attitude of attention , all this imitates the way experience itself in its deepest character strikes upon the door of consciousness and clamors for entrance .',\n",
       "  \"Russell had reached the house as Cook surmised , dismounted , but just as the old trapper opened the door to receive him , he fell into the trapper 's arms - dead .\",\n",
       "  \"When they were refused entrance to his brother 's house nearby , they smashed down the door , broke the window , and threw lighted clothes wet with kerosene into the room .\",\n",
       "  'As he pushed open the door he fell on his face , one of his comrades pulling him inside .',\n",
       "  'When the house was about half consumed , his comrade ran to the door and threw up his hands , declaring repeatedly that he did not know the whereabouts of Manuel .',\n",
       "  'But it is an answer which opens the door wide to an onrush of objections and denials .',\n",
       "  \"The monk who opened the door immediately calmed his worries about his reception : `` I speak English '' , the old man said , `` but I do not hear it very well '' .\",\n",
       "  'A nigger boy opened the door .',\n",
       "  'Someone blocked the door from inside .',\n",
       "  'At the rear of the auditorium , upstairs , some men tried to push open the door to the box corridor .',\n",
       "  'Someone opened the corridor door from the inside , and called for a doctor .',\n",
       "  'He pulled with all his strength at the heavy , brass bound door , and shuffled along the wainscoted wall .',\n",
       "  'Aggie might fly into a closet , shut the door and bury her head in the clothes ; he dared to wait for the lightning .',\n",
       "  'But he recalled that Rameau had once had a private performance of his opera Armide , behind closed doors , just for himself alone .',\n",
       "  'Over the door was a board with large , inept lettering :',\n",
       "  'He saw the sign above the door of the hut : Home Sweet Home .',\n",
       "  'Pullen James humbly lowered his head , pushed aside the hardtack box door of the hut , and was gone from sight .',\n",
       "  'Adam stared at the door and remembered that Simms Purdew had been awarded the Medal of Honor for gallantry at Antietam .',\n",
       "  'In their search for what turned out to be the right breakfast china but the wrong table silver , they opened every cupboard door in the kitchen and pantry .',\n",
       "  \"He did n't , but it was not really a question , and so he left the room , walked down the hall to the front of the apartment , hesitated , and then knocked lightly on the closed door of the study .\",\n",
       "  'At that moment the bathroom door flew open and Eugene came out , with his face lathered for shaving , and strode down the hall , tying the sash of his dressing gown as he went .',\n",
       "  'Before he left the apartment he knocked on their door and asked if there was anything he could do for them .',\n",
       "  'Looking around slowly , he saw a marble fireplace , a desk , a low bookcase of mahogany with criss-crossed brass wire instead of glass panes in the doors .',\n",
       "  'He tried the doors of the bookcase .',\n",
       "  'When he opened the door , there stood Eugene , on his way out of the apartment .',\n",
       "  'Juanita stopped just inside the open door , her hand to her mouth .',\n",
       "  'She was told by the manservant who opened the door that his lordship was engaged on work from which he had left strict orders he was not to be disturbed .',\n",
       "  'But the Blevins were away ; their maid gave him an envelope with a check in it and shut the door .',\n",
       "  'She took a good look at herself in the mirror before she turned and , walking with very small steps , started toward the door .',\n",
       "  'He was about to get up so I got out , slamming the door .',\n",
       "  \"He did n't even bother to wipe himself off and he chopped part of Pa 's door down before he stopped .\",\n",
       "  \"The evaporative cooler had been moved to Granny 's room , and her door was kept shut ; so that the rest of the house stayed open , though there was a question as to whether it was hotter or cooler that way .\",\n",
       "  \"Bobby Joe took a gun from behind the door , and with a quick `` Bye now '' was gone for the day .\",\n",
       "  \"A knocking at Alex 's door roused him at six o'clock the following morning .\",\n",
       "  'Time elapsed but the doctor was obviously unconscious of its passage until an unwelcome knock on the door interrupted the processes of nature .',\n",
       "  'Startled , he jumped up to pull hen and case out of view , and Alex went to the door .',\n",
       "  'Giselle was reluctant but Alex succeeded in persuading her to come back in five minutes and the door was shut again .',\n",
       "  'The doctor sat down rather wearily , caressing the hen and remarking that the city was not the place for a poultry loving man , but no sooner was the remark out than a knock at this door obliged him to cover the hen with his greatcoat once more .',\n",
       "  'At the door Alex managed to persuade the increasingly astonished fille de chambre to return in ten minutes .',\n",
       "  'They waited three minutes and then crept out on tip-toe ; the halls were empty and they passed down the stairs to number nine and listened at the door .',\n",
       "  \"A bustle of sheets being smoothed and pillows being arranged indicated the fille de chambre 's presence inside ; they listened and suddenly a step towards the door announced another important fact .\",\n",
       "  \"At five o'clock that night it was already dark , and behind my closed door I was dressing as carefully as a groom .\",\n",
       "  'When Felix first opened the door on it , all these shades were tightly drawn and the whole studio was as dark as night .',\n",
       "  'The children rushed off to get rid of their sweaters ; and Arlene began tapping the kitchen door open .',\n",
       "  \"`` Arlene 's a good girl '' , my uncle remarked to us ; but he said it too soon , for it came out just before the tap to which the door responded .\",\n",
       "  'They were pushed gently into the room by Arlene - whose only part appearing were hands that crept quickly back around to the kitchen side of the door .',\n",
       "  'The doors of the D train slid shut , and as I dropped into a seat and , exhaling , looked up across the aisle , the whole aviary in my head burst into song .',\n",
       "  'A somewhat less fragmented hebephrenic patient of mine , who used to often seclude herself in her room , often sounded through the closed door - as I would find on passing by , between our sessions - for all the world like two persons , a scolding mother and a defensive child .',\n",
       "  'He got out of there in a hurry , brushing past another man in the door , mopping his brow .',\n",
       "  'But she was talking of Emile when she saw the black line of the open door ; Sarah remembered it clearly .',\n",
       "  \"Miss Celie 's taken to her bed , with the door locked .\",\n",
       "  'Her skin crawled : Lolotte had told Maude that she was in the hall and the door was open .',\n",
       "  'Sarah had begun to tell Lucien of Emile , she had begun to question and a little draft had crept across the room from the bedroom door , open barely enough to show a rim of blackness in the hall .',\n",
       "  'Sarah found the right key and unlocked the door .',\n",
       "  'She started back for the house , saw a light in the office , opened the door and surprised a domestic little scene which was far outside the dark realm of murder or attempted murder .',\n",
       "  'Without taking off his coat , he sat in the blue chair which still faced the closed bedroom door .',\n",
       "  \"Blanche knew all this because the door to Stanley 's office was open and , without straining too hard , she could hear everything that was said .\",\n",
       "  'The old man opened the door and stepped out into the sunlight .',\n",
       "  \"`` Is n't enough time to go into it '' , he finished , and slammed the door in his son 's face .\",\n",
       "  \"`` Through a door conveniently unlocked '' , Madden supplemented .\",\n",
       "  \"`` That damn door '' , said the police chief .\",\n",
       "  '`` If there was collusion between an outside murderer and a member of the household it would be an elementary precaution to check on the door later .',\n",
       "  'The door opened and three men and a woman in a sari swept past him and down the stairs .',\n",
       "  'He climbed the steps of the first and opened the door to the vestibule .',\n",
       "  'He opened the inner door ; the cooking odors were stronger - all over the city , at this hour , housewives would be fussing over stoves .',\n",
       "  'He paused on the landing to steady his breathing and then bent to examine the single door by the light of the weak bulb overhead .',\n",
       "  \"Now he was certain : the lock had not yielded to Muller 's collection of keys ; fresh scars showed that the door had been prized open .\",\n",
       "  'It had been shut again , but the lock was broken ; he noted with a thrill of fear that the door moved under his touch .',\n",
       "  'Hoag pushed open the door : at the far end of the long dark room Muller was faintly silhouetted against the window , the rifle still raised ; he stood with his feet apart on a kitchen table he had dragged to the sill .',\n",
       "  'Gun went to the connecting door , which was open , and stood at attention while Orville Torrence Killpath , in full uniform , finished combing his hair .',\n",
       "  'In fact , he did not think about Jerry Burton at all until he entered his living room and closed the door behind him .',\n",
       "  'He opened the door and got out .',\n",
       "  'The door of the lockup was of oak planks and banded with strap iron .',\n",
       "  'Macklin balked again , not wanting to unlock and open the door .',\n",
       "  'Once the door was open , they crowded him inside the dark building .',\n",
       "  'He was uttering threats in a low but savage voice when they closed and padlocked the door .',\n",
       "  'This was the message found tacked to the cabin door .',\n",
       "  'There was no lock on the door , only an iron hook which he unfastened .',\n",
       "  'He opened the door and went in , pulling it shut behind him .',\n",
       "  'As Curt had hoped , the house door banged open .',\n",
       "  'Curt moved over beside the door and waited .',\n",
       "  \"The door swung open , and Jess said sourly , `` What the hell 's the matter with you ? ''\",\n",
       "  'He reached out to pull the door shut and fasten it with a sliding bolt .',\n",
       "  'Jess painfully got to his feet as someone rattled the door .',\n",
       "  'Curt opened the door , grabbed Black by the shoulder , and pulled him into the barn .',\n",
       "  'Curt followed , reaching behind him to shut the door and hook it .',\n",
       "  'All the doors were open at this hour except one , and it was toward this that Stevens made his way with Russ close at his shoulder .',\n",
       "  'The door was locked .',\n",
       "  'Johnson unwired the right hand door , whose window was , like the left one , merely loosely taped fragments of glass , and Johnson wadded himself into a narrow seat made still more narrow by three cases of beer .',\n",
       "  'Back at the Factory-to-You with the other old maids , back there she was the youngest clerk and she was thirty-four , which made her young enough to resent the usual ideal working conditions , like the unventilated toilet with the door you had to hold shut while you sat down .',\n",
       "  'She could not count the times Herman had rapped on the door , just a couple of bangs that shook the whole damned closet and might , someday , break away the pipe connections from the wall .',\n",
       "  'The two little bangs meant that he was getting impatient to have a crowd of customers waited on and that if he had to he would jerk open the door and drag out , by the opposite door handle which she would be clutching , whichever-the-hell clerk it was who thought she could waste so much store time on the pot .',\n",
       "  \"After a short time , both George and Donald joined the class with me so they would n't feel lonely , and we used to hang a sign on the door of the Brush-off reading `` out to work '' .\",\n",
       "  'and Phil banged his locker door shut and spun around .',\n",
       "  'Phil followed Eddie into the office and shut the door .',\n",
       "  'Phil shut the door behind him .',\n",
       "  \"Doors that won n't open , and doors that won n't close and shelves and broken '' .\",\n",
       "  \"Doors that won n't open , and doors that won n't close and shelves and broken '' .\",\n",
       "  'It should be installed over a door that is in full view of everyone , and a chair should be placed under it , a little to one side .',\n",
       "  'He was promised that no harm would befall him if he would come out , but he cursed and replied that he would shoot any man coming near the door .',\n",
       "  'Shot near the heart , he turned to one side and plunged for a door to another room several feet away , three bullets following him .',\n",
       "  \"In 1846 Matthew B. Goodwin , jeweler and watchmaker , became the town 's first telegrapher in a dwelling he built for himself and his business `` two doors north of the Equinox House '' or `` one door north of the Bank , Manchester , Vermont '' .\",\n",
       "  \"In 1846 Matthew B. Goodwin , jeweler and watchmaker , became the town 's first telegrapher in a dwelling he built for himself and his business `` two doors north of the Equinox House '' or `` one door north of the Bank , Manchester , Vermont '' .\",\n",
       "  \"Frederick Seward said his father was sleeping , and then went through a pantomime at his father 's door , to prove the statement .\",\n",
       "  'He clattered down the stairs and out of the door .',\n",
       "  'When McFeeley was halfway to the door , the proprietor emerged - a mountainous , dark man , his head thick with resiny black hair , his eyes like two of the black olives he imported in boatloads .',\n",
       "  'Skopas expressed no curiosity over the case , offered no expression of sympathy , made no move to escort McFeeley to the door .',\n",
       "  'The door was answered by a slender man in his sixties - straight backed , somewhat clerical in manner , wearing rimless glasses .',\n",
       "  'He beckoned to her from the door and she slipped quietly outside .',\n",
       "  'Now she could let out the three parakeets without fear they would be stepped on or that Stowey would let them out one of the doors ; she could dust the plants , then break off suddenly and pick up an old novel and read from the middle on ; improvise cha-chas on the harp ; and finally , the best part of all , simply sit at the plank table in the kitchen with a bottle of wine and the newspapers , reading the ads as well as the news , registering nothing on her mind but letting her soul suspend itself above all wishing and desire .',\n",
       "  'Through the door , he had seen Mr. Jack walking around , waiting for Miss Ada .',\n",
       "  'Should I accompany her to the door of her home , or should I ask to be invited in ?',\n",
       "  'The meat wagon , therefore , was not out in front of the house any more , but the cluster of squad cars was still there and there was a cop on the door downstairs to screen any comings and goings .',\n",
       "  'You shoulder your way through the cluster of the curious and you barge up to the cop on the door .',\n",
       "  'Instead of answering you , he sticks his head in the door and shouts up the stairs .',\n",
       "  'Hub was sitting in a chair that blocked the hall door .',\n",
       "  'If these facilities are not at the door , getting them may cost more than you expect .',\n",
       "  'Every path from back door to barn was covered by a grape-arbor , and every yard had its fruit trees .',\n",
       "  \"For the occasion on which everyone already knows everyone else and the host wishes them to meet one or a few honored newcomers , then the `` open house '' system is advantageous because the honored guests are fixed connective points and the drifting guests make and break connections at the door .\",\n",
       "  'At the door she turned back , her Roman nose looking very long now and satiric .',\n",
       "  'As she reached the kitchen door the answer presented itself ; if she told anyone of the opium it must be Lucien , her husband .',\n",
       "  'She paused at the kitchen door , caught her breath , told herself firmly that the opium was only an attempt to frighten her and went into the kitchen , where Glendora was eyeing the chickens dismally and Maude was cleaning lamp chimneys .',\n",
       "  'What was that old sign , supposed to be painted over a door somewhere , Abandon hope , all ye who enter here ?',\n",
       "  \"Pamela North said , `` Hi '' , to her cats , and added that proper cats met their humans at the door .\",\n",
       "  \"It would be all right with him , he decided , if his investigation of the fraud , with its probable by-product of murder , led to Garth 's door .\",\n",
       "  'He and Hogan waited by the door , one to either side .',\n",
       "  'Resignedly , Macklin turned to the back door .',\n",
       "  'Vastly relieved , Summers nodded and started toward the door .',\n",
       "  'Jess stumbled through the door .',\n",
       "  'Climbing the steps steadily , they reached the top and headed for the door .',\n",
       "  'I spun about and clattered through the front room to the door .',\n",
       "  'There was a tap at the door and Oliver entered with the word that Heiser wished to see the Captain .'],\n",
       " [[['The'],\n",
       "   Tree(Lemma('suburban.a.01.suburban'), ['suburban']),\n",
       "   Tree(Lemma('branch.n.01.branch'), ['branch']),\n",
       "   ['is'],\n",
       "   Tree(Lemma('thereby.r.01.thereby'), ['thereby']),\n",
       "   Tree(Lemma('accredit.v.03.credit'), ['credited']),\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('sale.n.01.sale'), ['sale']),\n",
       "   ['which'],\n",
       "   ['would'],\n",
       "   ['have'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('make.v.01.make'), ['made']),\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   ['if'],\n",
       "   ['its'],\n",
       "   Tree(Lemma('glass.n.02.glass'), ['glass']),\n",
       "   Tree(Lemma('door.n.03.door'), ['doors']),\n",
       "   ['had'],\n",
       "   Tree(Lemma('never.r.01.never'), ['never']),\n",
       "   Tree(Lemma('open.a.01.open'), ['opened']),\n",
       "   ['.']],\n",
       "  [['On'],\n",
       "   Tree(Lemma('all.a.01.all'), ['all']),\n",
       "   Tree(Lemma('side.n.06.side'), ['sides']),\n",
       "   Tree(Lemma('door.n.03.door'), ['doors']),\n",
       "   ['were'],\n",
       "   ['being'],\n",
       "   Tree(Lemma('slam.v.01.slam'), ['slammed']),\n",
       "   ['in'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('face.n.01.face'), ['face']),\n",
       "   ['.']],\n",
       "  [['His'],\n",
       "   Tree(Lemma('wide.a.01.broad'), ['broad']),\n",
       "   Tree(Lemma('interest.n.01.interest'), ['interest']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('literary.a.01.literary'), ['literary']),\n",
       "   [','],\n",
       "   Tree(Lemma('political.a.01.political'), ['political']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('philosophic.a.01.philosophical'), ['philosophical']),\n",
       "   Tree(Lemma('campaign.n.02.movement'), ['movements']),\n",
       "   Tree(Lemma('open.v.06.open'), ['opened']),\n",
       "   Tree(Lemma('many.a.01.many'), ['many']),\n",
       "   Tree(Lemma('door.n.03.door'), ['doors']),\n",
       "   ['to'],\n",
       "   ['him'],\n",
       "   ['.']],\n",
       "  [['When'],\n",
       "   Tree(Lemma('word.n.01.word'), ['words']),\n",
       "   ['can'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('use.v.01.use'), ['used']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('more.r.01.more'), ['more']),\n",
       "   Tree(Lemma('fresh.s.04.fresh'), ['fresh']),\n",
       "   ['and'],\n",
       "   Tree('primitive.s.00', ['primitive']),\n",
       "   Tree(Lemma('manner.n.01.way'), ['way']),\n",
       "   Tree(Lemma('so.r.02.so'), ['so']),\n",
       "   ['that'],\n",
       "   ['they'],\n",
       "   Tree(Lemma('affect.v.05.strike'), ['strike']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('force.n.01.force'), ['force']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('sight.n.02.sight'), ['sights']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('sound.n.02.sound'), ['sounds']),\n",
       "   [','],\n",
       "   ['when'],\n",
       "   Tree(Lemma('timbre.n.01.tone'), ['tones']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('sound.n.02.sound'), ['sound']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('color.n.01.color'), ['colors']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('paint.n.01.paint'), ['paint']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('carved.a.01.carven'), ['carven']),\n",
       "   Tree(Lemma('shape.n.01.shape'), ['shape']),\n",
       "   ['all'],\n",
       "   Tree(Lemma('affect.v.05.strike'), ['strike']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('sensibility.n.01.sensibility'), ['sensibilities']),\n",
       "   ['with'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('undeniable.a.01.undeniable'), ['undeniable']),\n",
       "   Tree(Lemma('force.n.01.force'), ['force']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('datum.n.01.datum'), ['data']),\n",
       "   ['in'],\n",
       "   ['and'],\n",
       "   ['of'],\n",
       "   ['themselves'],\n",
       "   [','],\n",
       "   Tree(Lemma('compel.v.01.compel'), ['compelling']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('perceiver.n.01.observer'), ['observer']),\n",
       "   ['into'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('attitude.n.01.attitude'), ['attitude']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('attention.n.01.attention'), ['attention']),\n",
       "   [','],\n",
       "   ['all'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('imitate.v.01.imitate'), ['imitates']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('manner.n.01.way'), ['way']),\n",
       "   Tree(Lemma('experience.n.02.experience'), ['experience']),\n",
       "   ['itself'],\n",
       "   ['in'],\n",
       "   ['its'],\n",
       "   Tree(Lemma('deep.s.02.deep'), ['deepest']),\n",
       "   Tree(Lemma('quality.n.03.character'), ['character']),\n",
       "   Tree(Lemma('strike.v.01.strike'), ['strikes']),\n",
       "   ['upon'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.03.door'), ['door']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('consciousness.n.01.consciousness'), ['consciousness']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('clamor.v.02.clamor'), ['clamors']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('entrance.n.02.entrance'), ['entrance']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Russell'])]),\n",
       "   ['had'],\n",
       "   Tree(Lemma('reach.v.01.reach'), ['reached']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('house.n.01.house'), ['house']),\n",
       "   ['as'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Cook'])]),\n",
       "   Tree(Lemma('surmise.v.01.surmise'), ['surmised']),\n",
       "   [','],\n",
       "   Tree(Lemma('unhorse.v.01.dismount'), ['dismounted']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   Tree(Lemma('precisely.r.01.just'), ['just']),\n",
       "   ['as'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('old.a.01.old'), ['old']),\n",
       "   Tree(Lemma('trapper.n.01.trapper'), ['trapper']),\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('receive.v.05.receive'), ['receive']),\n",
       "   ['him'],\n",
       "   [','],\n",
       "   ['he'],\n",
       "   Tree(Lemma('fall.v.01.fall'), ['fell']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('trapper.n.01.trapper'), ['trapper']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('arm.n.01.arm'), ['arms']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('dead.a.01.dead'), ['dead']),\n",
       "   ['.']],\n",
       "  [['When'],\n",
       "   ['they'],\n",
       "   ['were'],\n",
       "   Tree(Lemma('refuse.v.02.refuse'), ['refused']),\n",
       "   Tree(Lemma('entrance.n.03.entrance'), ['entrance']),\n",
       "   ['to'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('brother.n.01.brother'), ['brother']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('house.n.01.house'), ['house']),\n",
       "   Tree(Lemma('nearby.r.01.nearby'), ['nearby']),\n",
       "   [','],\n",
       "   ['they'],\n",
       "   Tree(Lemma('smash.v.02.smash'), ['smashed']),\n",
       "   Tree(Lemma('down.r.01.down'), ['down']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   Tree(Lemma('break.v.04.break'), ['broke']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('window.n.01.window'), ['window']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('throw.v.01.throw'), ['threw']),\n",
       "   Tree(Lemma('lighted.a.01.lighted'), ['lighted']),\n",
       "   Tree(Lemma('apparel.n.01.clothes'), ['clothes']),\n",
       "   Tree(Lemma('wet.a.01.wet'), ['wet']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('kerosene.n.01.kerosene'), ['kerosene']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('room.n.01.room'), ['room']),\n",
       "   ['.']],\n",
       "  [['As'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('push.v.01.push'), ['pushed']),\n",
       "   Tree(Lemma('open.a.02.open'), ['open']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('fall.v.01.fall'), ['fell']),\n",
       "   ['on'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('face.n.01.face'), ['face']),\n",
       "   [','],\n",
       "   Tree(Lemma('one.s.01.one'), ['one']),\n",
       "   ['of'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('companion.n.01.comrade'), ['comrades']),\n",
       "   Tree(Lemma('pull.v.01.pull'), ['pulling']),\n",
       "   ['him'],\n",
       "   Tree(Lemma('inside.r.01.inside'), ['inside']),\n",
       "   ['.']],\n",
       "  [['When'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('house.n.01.house'), ['house']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('approximately.r.01.about'), ['about']),\n",
       "   Tree(Lemma('half.r.01.half'), ['half']),\n",
       "   Tree(Lemma('consume.v.04.consume'), ['consumed']),\n",
       "   [','],\n",
       "   ['his'],\n",
       "   Tree(Lemma('companion.n.01.comrade'), ['comrade']),\n",
       "   Tree(Lemma('run.v.01.run'), ['ran']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('throw.v.01.throw'), ['threw']),\n",
       "   ['up'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('hand.n.01.hand'), ['hands']),\n",
       "   [','],\n",
       "   Tree(Lemma('declare.v.01.declare'), ['declaring']),\n",
       "   Tree(Lemma('repeatedly.r.01.repeatedly'), ['repeatedly']),\n",
       "   ['that'],\n",
       "   ['he'],\n",
       "   ['did'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('know.v.01.know'), ['know']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('whereabouts.n.01.whereabouts'), ['whereabouts']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Manuel'])]),\n",
       "   ['.']],\n",
       "  [['But'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   ['an'],\n",
       "   Tree(Lemma('answer.n.01.answer'), ['answer']),\n",
       "   ['which'],\n",
       "   Tree(Lemma('open.v.01.open'), ['opens']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('wide.r.02.wide'), ['wide']),\n",
       "   ['to'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('attack.n.01.onrush'), ['onrush']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('objection.n.02.objection'), ['objections']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('denial.n.01.denial'), ['denials']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('monk.n.01.monk'), ['monk']),\n",
       "   ['who'],\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('immediately.r.01.immediately'), ['immediately']),\n",
       "   Tree(Lemma('calm.v.01.calm'), ['calmed']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('concern.n.04.worry'), ['worries']),\n",
       "   ['about'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('reception.n.01.reception'), ['reception']),\n",
       "   [':'],\n",
       "   ['``'],\n",
       "   ['I'],\n",
       "   Tree(Lemma('speak.v.03.speak'), ['speak']),\n",
       "   Tree(Lemma('english.n.01.English'), ['English']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('old_man.n.01.old_man'), ['old', 'man']),\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   [','],\n",
       "   ['``'],\n",
       "   ['but'],\n",
       "   ['I'],\n",
       "   ['do'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('hear.v.01.hear'), ['hear']),\n",
       "   ['it'],\n",
       "   Tree(Lemma('first-rate.r.01.very_well'), ['very', 'well']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['A'],\n",
       "   Tree(Lemma('nigger.n.01.nigger'), ['nigger']),\n",
       "   Tree(Lemma('male_child.n.01.boy'), ['boy']),\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.someone'), ['Someone']),\n",
       "   Tree(Lemma('barricade.v.01.block'), ['blocked']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('inside.n.02.inside'), ['inside']),\n",
       "   ['.']],\n",
       "  [['At'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('back.n.03.rear'), ['rear']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('auditorium.n.01.auditorium'), ['auditorium']),\n",
       "   [','],\n",
       "   Tree(Lemma('upstairs.a.01.upstairs'), ['upstairs']),\n",
       "   [','],\n",
       "   ['some'],\n",
       "   Tree(Lemma('man.n.01.man'), ['men']),\n",
       "   Tree(Lemma('try.v.01.try'), ['tried']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('push.v.01.push'), ['push']),\n",
       "   Tree(Lemma('open.v.01.open'), ['open']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('box.n.02.box'), ['box']),\n",
       "   Tree(Lemma('corridor.n.01.corridor'), ['corridor']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.someone'), ['Someone']),\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('corridor.n.01.corridor'), ['corridor']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('inside.n.02.inside'), ['inside']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree('call_for.v.00', ['called', 'for']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('doctor.n.01.doctor'), ['doctor']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('pull.v.01.pull'), ['pulled']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('all.a.01.all'), ['all']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('force.n.03.strength'), ['strength']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heavy.a.01.heavy'), ['heavy']),\n",
       "   [','],\n",
       "   Tree(Lemma('brass.n.01.brass'), ['brass']),\n",
       "   Tree(Lemma('bound.a.03.bound'), ['bound']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('shuffle.v.01.shuffle'), ['shuffled']),\n",
       "   ['along'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('paneled.s.01.wainscoted'), ['wainscoted']),\n",
       "   Tree(Lemma('wall.n.01.wall'), ['wall']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Aggie'])]),\n",
       "   ['might'],\n",
       "   Tree(Lemma('fly.v.02.fly'), ['fly']),\n",
       "   ['into'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('cupboard.n.01.closet'), ['closet']),\n",
       "   [','],\n",
       "   Tree(Lemma('close.v.01.shut'), ['shut']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('bury.v.01.bury'), ['bury']),\n",
       "   ['her'],\n",
       "   Tree(Lemma('head.n.01.head'), ['head']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('apparel.n.01.clothes'), ['clothes']),\n",
       "   [';'],\n",
       "   ['he'],\n",
       "   ['dared'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('wait.v.01.wait'), ['wait']),\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('lightning.n.01.lightning'), ['lightning']),\n",
       "   ['.']],\n",
       "  [['But'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('remember.v.01.recall'), ['recalled']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Rameau'])]),\n",
       "   ['had'],\n",
       "   Tree(Lemma('once.r.01.once'), ['once']),\n",
       "   Tree(Lemma('hold.v.03.have'), ['had']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('private.a.01.private'), ['private']),\n",
       "   Tree(Lemma('performance.n.01.performance'), ['performance']),\n",
       "   ['of'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('opera.n.01.opera'), ['opera']),\n",
       "   Tree('NE', ['Armide']),\n",
       "   [','],\n",
       "   ['behind'],\n",
       "   Tree(Lemma('closed.a.01.closed'), ['closed']),\n",
       "   Tree(Lemma('door.n.01.door'), ['doors']),\n",
       "   [','],\n",
       "   Tree(Lemma('merely.r.01.just'), ['just']),\n",
       "   ['for'],\n",
       "   ['himself'],\n",
       "   Tree(Lemma('entirely.r.02.alone'), ['alone']),\n",
       "   ['.']],\n",
       "  [['Over'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('be.v.03.be'), ['was']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('board.n.02.board'), ['board']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('large.a.01.large'), ['large']),\n",
       "   [','],\n",
       "   Tree(Lemma('awkward.s.04.inept'), ['inept']),\n",
       "   Tree(Lemma('inscription.n.01.lettering'), ['lettering']),\n",
       "   [':']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('see.v.01.see'), ['saw']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('sign.n.02.sign'), ['sign']),\n",
       "   ['above'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('hut.n.01.hut'), ['hut']),\n",
       "   [':'],\n",
       "   ['Home', 'Sweet', 'Home'],\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Pullen', 'James'])]),\n",
       "   Tree(Lemma('humbly.r.01.humbly'), ['humbly']),\n",
       "   Tree(Lemma('lower.v.01.lower'), ['lowered']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('head.n.01.head'), ['head']),\n",
       "   [','],\n",
       "   Tree(Lemma('push_aside.v.01.push_aside'), ['pushed', 'aside']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('hardtack.n.02.hardtack'), ['hardtack']),\n",
       "   Tree(Lemma('box.n.01.box'), ['box']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('hut.n.01.hut'), ['hut']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('go.v.09.go'), ['gone']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('sight.n.03.sight'), ['sight']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Adam'])]),\n",
       "   Tree(Lemma('gaze.v.01.stare'), ['stared']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('remember.v.01.remember'), ['remembered']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Simms', 'Purdew'])]),\n",
       "   ['had'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('award.v.01.award'), ['awarded']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('medal_of_honor.n.01.Medal_of_Honor'), ['Medal', 'of', 'Honor']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('heroism.n.01.gallantry'), ['gallantry']),\n",
       "   ['at'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Antietam'])]),\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   ['their'],\n",
       "   Tree(Lemma('search.n.01.search'), ['search']),\n",
       "   ['for'],\n",
       "   ['what'],\n",
       "   Tree(Lemma('prove.v.01.turn_out'), ['turned', 'out']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('correct.s.02.right'), ['right']),\n",
       "   Tree(Lemma('breakfast.n.01.breakfast'), ['breakfast']),\n",
       "   Tree(Lemma('china.n.02.china'), ['china']),\n",
       "   ['but'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('wrong.a.02.wrong'), ['wrong']),\n",
       "   Tree(Lemma('table.n.03.table'), ['table']),\n",
       "   Tree(Lemma('flatware.n.02.silver'), ['silver']),\n",
       "   [','],\n",
       "   ['they'],\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   Tree('every.s.01', ['every']),\n",
       "   Tree(Lemma('cupboard.n.01.cupboard'), ['cupboard']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('kitchen.n.01.kitchen'), ['kitchen']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('pantry.n.01.pantry'), ['pantry']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   ['did'],\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('be.v.02.be'), ['was']),\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('truly.r.01.really'), ['really']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('question.n.01.question'), ['question']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['so'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('leave.v.01.leave'), ['left']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('room.n.01.room'), ['room']),\n",
       "   [','],\n",
       "   Tree(Lemma('walk.v.01.walk'), ['walked']),\n",
       "   ['down'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('hallway.n.01.hall'), ['hall']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('front.n.01.front'), ['front']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('apartment.n.01.apartment'), ['apartment']),\n",
       "   [','],\n",
       "   Tree(Lemma('hesitate.v.02.hesitate'), ['hesitated']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('then.r.01.then'), ['then']),\n",
       "   Tree(Lemma('knock.v.02.knock'), ['knocked']),\n",
       "   Tree(Lemma('lightly.r.04.lightly'), ['lightly']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('closed.a.01.closed'), ['closed']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('study.n.05.study'), ['study']),\n",
       "   ['.']],\n",
       "  [['At'],\n",
       "   ['that'],\n",
       "   Tree(Lemma('moment.n.01.moment'), ['moment']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('bathroom.n.01.bathroom'), ['bathroom']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('fly_open.v.01.fly_open'), ['flew', 'open']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Eugene'])]),\n",
       "   Tree(Lemma('come_on.v.01.come_out'), ['came', 'out']),\n",
       "   [','],\n",
       "   ['with'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('face.n.01.face'), ['face']),\n",
       "   Tree('lather.v.00', ['lathered']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('shave.n.01.shaving'), ['shaving']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree('stride.v.00', ['strode']),\n",
       "   ['down'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('hallway.n.01.hall'), ['hall']),\n",
       "   [','],\n",
       "   Tree(Lemma('tie.v.01.tie'), ['tying']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('girdle.n.02.sash'), ['sash']),\n",
       "   ['of'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('dressing_gown.n.01.dressing_gown'), ['dressing', 'gown']),\n",
       "   ['as'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('travel.v.01.go'), ['went']),\n",
       "   ['.']],\n",
       "  [['Before'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('leave.v.01.leave'), ['left']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('apartment.n.01.apartment'), ['apartment']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('knock.v.02.knock'), ['knocked']),\n",
       "   ['on'],\n",
       "   ['their'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('ask.v.01.ask'), ['asked']),\n",
       "   ['if'],\n",
       "   ['there'],\n",
       "   Tree(Lemma('exist.v.01.be'), ['was']),\n",
       "   ['anything'],\n",
       "   ['he'],\n",
       "   ['could'],\n",
       "   Tree(Lemma('make.v.01.do'), ['do']),\n",
       "   ['for'],\n",
       "   ['them'],\n",
       "   ['.']],\n",
       "  [Tree(Lemma('look_around.v.01.look_around'), ['Looking', 'around']),\n",
       "   Tree(Lemma('slowly.r.01.slowly'), ['slowly']),\n",
       "   [','],\n",
       "   ['he'],\n",
       "   Tree(Lemma('see.v.01.see'), ['saw']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('marble.n.01.marble'), ['marble']),\n",
       "   Tree(Lemma('fireplace.n.01.fireplace'), ['fireplace']),\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree(Lemma('desk.n.01.desk'), ['desk']),\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree(Lemma('low.a.02.low'), ['low']),\n",
       "   Tree(Lemma('bookcase.n.01.bookcase'), ['bookcase']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('mahogany.n.01.mahogany'), ['mahogany']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('crisscross.s.01.crisscrossed'), ['criss-crossed']),\n",
       "   Tree(Lemma('brass.n.01.brass'), ['brass']),\n",
       "   Tree(Lemma('wire.n.01.wire'), ['wire']),\n",
       "   Tree(Lemma('alternatively.r.01.instead'), ['instead']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('glass.n.01.glass'), ['glass']),\n",
       "   Tree(Lemma('pane.n.01.pane'), ['panes']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['doors']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('try.v.01.try'), ['tried']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['doors']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bookcase.n.01.bookcase'), ['bookcase']),\n",
       "   ['.']],\n",
       "  [['When'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   Tree(Lemma('there.r.01.there'), ['there']),\n",
       "   Tree(Lemma('stand.v.01.stand'), ['stood']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Eugene'])]),\n",
       "   [','],\n",
       "   ['on'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('way.n.07.way'), ['way']),\n",
       "   ['out', 'of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('apartment.n.01.apartment'), ['apartment']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Juanita'])]),\n",
       "   Tree(Lemma('stop.v.01.stop'), ['stopped']),\n",
       "   Tree(Lemma('precisely.r.01.just'), ['just']),\n",
       "   Tree(Lemma('inside.r.01.inside'), ['inside']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   ['her'],\n",
       "   Tree(Lemma('hand.n.01.hand'), ['hand']),\n",
       "   ['to'],\n",
       "   ['her'],\n",
       "   Tree(Lemma('mouth.n.01.mouth'), ['mouth']),\n",
       "   ['.']],\n",
       "  [['She'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('state.v.01.tell'), ['told']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('manservant.n.01.manservant'), ['manservant']),\n",
       "   ['who'],\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['that'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('lordship.n.01.Lordship'), ['lordship']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('absorb.v.09.engage'), ['engaged']),\n",
       "   ['on'],\n",
       "   Tree(Lemma('work.n.01.work'), ['work']),\n",
       "   ['from'],\n",
       "   ['which'],\n",
       "   ['he'],\n",
       "   ['had'],\n",
       "   Tree(Lemma('impart.v.01.leave'), ['left']),\n",
       "   Tree(Lemma('hard-and-fast.s.01.strict'), ['strict']),\n",
       "   Tree(Lemma('order.n.01.order'), ['orders']),\n",
       "   ['he'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   ['to'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('interrupt.v.02.disturb'), ['disturbed']),\n",
       "   ['.']],\n",
       "  [['But'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Blevins'])]),\n",
       "   Tree(Lemma('be.v.01.be'), ['were']),\n",
       "   Tree('away.s.00', ['away']),\n",
       "   [';'],\n",
       "   ['their'],\n",
       "   Tree(Lemma('maid.n.01.maid'), ['maid']),\n",
       "   Tree(Lemma('give.v.14.give'), ['gave']),\n",
       "   ['him'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('envelope.n.01.envelope'), ['envelope']),\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('check.n.01.check'), ['check']),\n",
       "   ['in'],\n",
       "   ['it'],\n",
       "   ['and'],\n",
       "   Tree(Lemma('close.v.01.shut'), ['shut']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['She'],\n",
       "   Tree(Lemma('take_a_look.v.01.take_a_look'), ['took']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('full.s.06.good'), ['good']),\n",
       "   ['look'],\n",
       "   ['at'],\n",
       "   ['herself'],\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('mirror.n.01.mirror'), ['mirror']),\n",
       "   ['before'],\n",
       "   ['she'],\n",
       "   Tree(Lemma('turn.v.01.turn'), ['turned']),\n",
       "   ['and'],\n",
       "   [','],\n",
       "   Tree(Lemma('walk.v.01.walk'), ['walking']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('very.r.01.very'), ['very']),\n",
       "   Tree(Lemma('small.a.01.small'), ['small']),\n",
       "   Tree(Lemma('footstep.n.03.step'), ['steps']),\n",
       "   [','],\n",
       "   Tree(Lemma('depart.v.03.start'), ['started']),\n",
       "   ['toward'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   ['was', 'about', 'to'],\n",
       "   Tree(Lemma('get_up.v.04.get_up'), ['get', 'up']),\n",
       "   ['so'],\n",
       "   ['I'],\n",
       "   Tree(Lemma('exit.v.01.get_out'), ['got', 'out']),\n",
       "   [','],\n",
       "   Tree(Lemma('slam.v.01.slam'), ['slamming']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   ['did'],\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   Tree(Lemma('trouble_oneself.v.01.bother'), ['bother']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('wipe_off.v.01.wipe_off'), ['wipe']),\n",
       "   ['himself'],\n",
       "   ['off'],\n",
       "   ['and'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('chop_down.v.01.chop_down'), ['chopped']),\n",
       "   Tree(Lemma('part.n.02.part'), ['part']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('dad.n.01.pa'), ['Pa']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['down'],\n",
       "   ['before'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('discontinue.v.01.stop'), ['stopped']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('evaporative_cooler.n.01.evaporative_cooler'), ['evaporative', 'cooler']),\n",
       "   ['had'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('move.v.03.move'), ['moved']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('grandma.n.01.granny'), ['Granny']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('room.n.01.room'), ['room']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['her'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('keep.v.01.keep'), ['kept']),\n",
       "   Tree(Lemma('close.v.02.shut'), ['shut']),\n",
       "   [';'],\n",
       "   Tree(Lemma('so.r.02.so'), ['so']),\n",
       "   ['that'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('remainder.n.01.rest'), ['rest']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('house.n.01.house'), ['house']),\n",
       "   Tree(Lemma('stay.v.01.stay'), ['stayed']),\n",
       "   Tree(Lemma('open.a.02.open'), ['open']),\n",
       "   [','],\n",
       "   ['though'],\n",
       "   ['there'],\n",
       "   Tree(Lemma('exist.v.01.be'), ['was']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('question.n.01.question'), ['question']),\n",
       "   ['as'],\n",
       "   ['to'],\n",
       "   ['whether'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('hot.a.01.hot'), ['hotter']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('cool.a.01.cool'), ['cooler']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('manner.n.01.way'), ['way']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Bobby', 'Joe'])]),\n",
       "   Tree(Lemma('remove.v.01.take'), ['took']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('gun.n.01.gun'), ['gun']),\n",
       "   ['from'],\n",
       "   ['behind'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('flying.s.02.quick'), ['quick']),\n",
       "   ['``'],\n",
       "   ['Bye', 'now'],\n",
       "   [\"''\"],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree('gone.s.00', ['gone']),\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('day.n.04.day'), ['day']),\n",
       "   ['.']],\n",
       "  [['A'],\n",
       "   Tree(Lemma('knock.n.01.knocking'), ['knocking']),\n",
       "   ['at'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Alex'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('bestir.v.01.rouse'), ['roused']),\n",
       "   ['him'],\n",
       "   ['at'],\n",
       "   Tree(Lemma('six.s.01.six'), ['six']),\n",
       "   [\"o'clock\"],\n",
       "   ['the'],\n",
       "   Tree('following.s.02', ['following']),\n",
       "   Tree(Lemma('morning.n.01.morning'), ['morning']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('time.n.02.time'), ['Time']),\n",
       "   Tree(Lemma('elapse.v.01.elapse'), ['elapsed']),\n",
       "   ['but'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doctor.n.01.doctor'), ['doctor']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('obviously.r.01.obviously'), ['obviously']),\n",
       "   Tree(Lemma('unconscious.s.03.unconscious'), ['unconscious']),\n",
       "   ['of'],\n",
       "   ['its'],\n",
       "   Tree(Lemma('passage.n.01.passage'), ['passage']),\n",
       "   ['until'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('unwelcome.a.01.unwelcome'), ['unwelcome']),\n",
       "   Tree(Lemma('knock.n.01.knock'), ['knock']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('interrupt.v.01.interrupt'), ['interrupted']),\n",
       "   ['the'],\n",
       "   Tree('process.n.00', ['processes']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('nature.n.03.nature'), ['nature']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('startled.s.01.startled'), ['Startled']),\n",
       "   [','],\n",
       "   ['he'],\n",
       "   Tree(Lemma('startle.v.02.jump'), ['jumped']),\n",
       "   ['up'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('pull.n.01.pull'), ['pull']),\n",
       "   Tree(Lemma('hen.n.01.hen'), ['hen']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('case.n.05.case'), ['case']),\n",
       "   ['out'],\n",
       "   ['of'],\n",
       "   Tree(Lemma('view.n.04.view'), ['view']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Alex'])]),\n",
       "   Tree('go_to.v.00', ['went', 'to']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Giselle'])]),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('loath.s.01.reluctant'), ['reluctant']),\n",
       "   ['but'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Alex'])]),\n",
       "   Tree(Lemma('succeed.v.01.succeed'), ['succeeded']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('carry.v.23.persuade'), ['persuading']),\n",
       "   ['her'],\n",
       "   ['to'],\n",
       "   Tree('come_back.v.00', ['come', 'back']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('five.s.01.five'), ['five']),\n",
       "   Tree(Lemma('minute.n.01.minute'), ['minutes']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('close.v.01.shut'), ['shut']),\n",
       "   Tree(Lemma('again.r.01.again'), ['again']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('doctor.n.01.doctor'), ['doctor']),\n",
       "   Tree(Lemma('sit_down.v.01.sit_down'), ['sat', 'down']),\n",
       "   Tree(Lemma('rather.r.02.rather'), ['rather']),\n",
       "   Tree(Lemma('tiredly.r.01.wearily'), ['wearily']),\n",
       "   [','],\n",
       "   Tree(Lemma('caress.v.01.caress'), ['caressing']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('hen.n.01.hen'), ['hen']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('note.v.01.remark'), ['remarking']),\n",
       "   ['that'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('city.n.01.city'), ['city']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('topographic_point.n.01.place'), ['place']),\n",
       "   ['for'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('domestic_fowl.n.01.poultry'), ['poultry']),\n",
       "   Tree(Lemma('loving.a.01.loving'), ['loving']),\n",
       "   Tree(Lemma('man.n.01.man'), ['man']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   ['no', 'sooner'],\n",
       "   Tree(Lemma('be.v.05.be'), ['was']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('remark.n.01.remark'), ['remark']),\n",
       "   ['out'],\n",
       "   ['than'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('knock.n.01.knock'), ['knock']),\n",
       "   ['at'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('compel.v.01.oblige'), ['obliged']),\n",
       "   ['him'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('cover.v.01.cover'), ['cover']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('hen.n.01.hen'), ['hen']),\n",
       "   ['with'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('greatcoat.n.01.greatcoat'), ['greatcoat']),\n",
       "   Tree(Lemma('again.r.01.once_more'), ['once', 'more']),\n",
       "   ['.']],\n",
       "  [['At'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Alex'])]),\n",
       "   Tree(Lemma('pull_off.v.03.manage'), ['managed']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('carry.v.23.persuade'), ['persuade']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('increasingly.r.01.increasingly'), ['increasingly']),\n",
       "   Tree(Lemma('amazed.s.01.astonished'), ['astonished']),\n",
       "   Tree(Lemma('chambermaid.n.01.fille_de_chambre'), ['fille', 'de', 'chambre']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('return.v.01.return'), ['return']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('ten.s.01.ten'), ['ten']),\n",
       "   Tree(Lemma('minute.n.01.minute'), ['minutes']),\n",
       "   ['.']],\n",
       "  [['They'],\n",
       "   Tree(Lemma('wait.v.01.wait'), ['waited']),\n",
       "   Tree(Lemma('three.s.01.three'), ['three']),\n",
       "   Tree(Lemma('minute.n.01.minute'), ['minutes']),\n",
       "   Tree(Lemma('then.r.01.and_then'), ['and', 'then']),\n",
       "   Tree(Lemma('sneak.v.01.creep'), ['crept']),\n",
       "   Tree('out.r.00', ['out']),\n",
       "   ['on'],\n",
       "   Tree(Lemma('tiptoe.r.01.tiptoe'), ['tip-toe']),\n",
       "   [';'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('hallway.n.01.hall'), ['halls']),\n",
       "   Tree(Lemma('be.v.01.be'), ['were']),\n",
       "   Tree(Lemma('empty.a.01.empty'), ['empty']),\n",
       "   ['and'],\n",
       "   ['they'],\n",
       "   Tree(Lemma('pass.v.01.pass'), ['passed']),\n",
       "   Tree(Lemma('downstairs.r.01.down_the_stairs'), ['down', 'the', 'stairs']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('number.n.02.number'), ['number']),\n",
       "   Tree(Lemma('nine.n.01.nine'), ['nine']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('listen.v.02.listen'), ['listened']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['A'],\n",
       "   Tree(Lemma('bustle.n.01.bustle'), ['bustle']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('sheet.n.03.sheet'), ['sheets']),\n",
       "   ['being'],\n",
       "   Tree(Lemma('smooth.v.01.smooth'), ['smoothed']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('pillow.n.01.pillow'), ['pillows']),\n",
       "   ['being'],\n",
       "   Tree(Lemma('arrange.v.01.arrange'), ['arranged']),\n",
       "   Tree(Lemma('bespeak.v.01.indicate'), ['indicated']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('chambermaid.n.01.fille_de_chambre'), ['fille', 'de', 'chambre']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('presence.n.01.presence'), ['presence']),\n",
       "   Tree(Lemma('inside.r.02.inside'), ['inside']),\n",
       "   [';'],\n",
       "   ['they'],\n",
       "   Tree(Lemma('listen.v.02.listen'), ['listened']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('suddenly.r.01.suddenly'), ['suddenly']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('footstep.n.03.step'), ['step']),\n",
       "   ['towards'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('announce.v.01.announce'), ['announced']),\n",
       "   ['another'],\n",
       "   Tree(Lemma('important.a.01.important'), ['important']),\n",
       "   Tree(Lemma('fact.n.01.fact'), ['fact']),\n",
       "   ['.']],\n",
       "  [['At'],\n",
       "   Tree(Lemma('five.s.01.five'), ['five']),\n",
       "   Tree(Lemma('o'clock.r.01.o'clock'), [\"o'clock\"]),\n",
       "   ['that'],\n",
       "   Tree(Lemma('night.n.01.night'), ['night']),\n",
       "   ['it'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('already.r.01.already'), ['already']),\n",
       "   Tree(Lemma('night.n.01.dark'), ['dark']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['behind'],\n",
       "   ['my'],\n",
       "   Tree(Lemma('shut.a.01.closed'), ['closed']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['I'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('dress.v.01.dress'), ['dressing']),\n",
       "   ['as'],\n",
       "   Tree(Lemma('carefully.r.01.carefully'), ['carefully']),\n",
       "   ['as'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('groom.n.01.groom'), ['groom']),\n",
       "   ['.']],\n",
       "  [['When'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Felix'])]),\n",
       "   Tree(Lemma('first.r.02.first'), ['first']),\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['on', 'it'],\n",
       "   [','],\n",
       "   ['all'],\n",
       "   ['these'],\n",
       "   Tree(Lemma('shade.n.03.shade'), ['shades']),\n",
       "   ['were'],\n",
       "   Tree(Lemma('tightly.r.02.tightly'), ['tightly']),\n",
       "   Tree(Lemma('draw.v.20.draw'), ['drawn']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('whole.a.01.whole'), ['whole']),\n",
       "   Tree(Lemma('studio.n.01.studio'), ['studio']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   ['as'],\n",
       "   Tree(Lemma('dark.a.01.dark'), ['dark']),\n",
       "   ['as'],\n",
       "   Tree(Lemma('night.n.01.night'), ['night']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('child.n.01.child'), ['children']),\n",
       "   Tree(Lemma('rush_off.v.01.rush_off'), ['rushed', 'off']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('get_rid_of.v.01.get_rid_of'), ['get', 'rid', 'of']),\n",
       "   ['their'],\n",
       "   Tree(Lemma('sweater.n.01.sweater'), ['sweaters']),\n",
       "   [';'],\n",
       "   ['and'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Arlene'])]),\n",
       "   Tree(Lemma('get_down.v.07.begin'), ['began']),\n",
       "   Tree(Lemma('tap.v.03.tap'), ['tapping']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('kitchen.n.01.kitchen'), ['kitchen']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Arlene'])]),\n",
       "   Tree(Lemma('be.v.01.be'), [\"'s\"]),\n",
       "   ['a'],\n",
       "   Tree(Lemma('good.a.01.good'), ['good']),\n",
       "   Tree(Lemma('girl.n.01.girl'), ['girl']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   ['my'],\n",
       "   Tree(Lemma('uncle.n.01.uncle'), ['uncle']),\n",
       "   Tree(Lemma('note.v.01.remark'), ['remarked']),\n",
       "   ['to'],\n",
       "   ['us'],\n",
       "   [';'],\n",
       "   ['but'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['it'],\n",
       "   Tree(Lemma('early.r.02.too_soon'), ['too', 'soon']),\n",
       "   [','],\n",
       "   ['for'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('issue.v.04.come_out'), ['came', 'out']),\n",
       "   Tree(Lemma('precisely.r.01.just'), ['just']),\n",
       "   ['before'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('pat.n.01.tap'), ['tap']),\n",
       "   ['to'],\n",
       "   ['which'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('react.v.01.respond'), ['responded']),\n",
       "   ['.']],\n",
       "  [['They'],\n",
       "   ['were'],\n",
       "   Tree(Lemma('push.v.01.push'), ['pushed']),\n",
       "   Tree(Lemma('lightly.r.03.gently'), ['gently']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('room.n.01.room'), ['room']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Arlene'])]),\n",
       "   ['-'],\n",
       "   ['whose'],\n",
       "   Tree('only.s.00', ['only']),\n",
       "   Tree(Lemma('part.n.02.part'), ['part']),\n",
       "   Tree(Lemma('appear.v.02.appear'), ['appearing']),\n",
       "   Tree(Lemma('be.v.02.be'), ['were']),\n",
       "   Tree(Lemma('hand.n.01.hand'), ['hands']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('creep.v.03.creep'), ['crept']),\n",
       "   Tree(Lemma('quickly.r.01.quickly'), ['quickly']),\n",
       "   Tree(Lemma('back.r.01.back'), ['back']),\n",
       "   ['around'],\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('kitchen.n.01.kitchen'), ['kitchen']),\n",
       "   Tree(Lemma('side.n.01.side'), ['side']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('door.n.01.door'), ['doors']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   ['D'],\n",
       "   Tree(Lemma('train.n.01.train'), ['train']),\n",
       "   Tree(Lemma('skid.v.04.slide'), ['slid']),\n",
       "   Tree(Lemma('shut.a.01.shut'), ['shut']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['as'],\n",
       "   ['I'],\n",
       "   Tree(Lemma('sink.v.01.drop'), ['dropped']),\n",
       "   ['into'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('seat.n.01.seat'), ['seat']),\n",
       "   ['and'],\n",
       "   [','],\n",
       "   Tree(Lemma('exhale.v.01.exhale'), ['exhaling']),\n",
       "   [','],\n",
       "   Tree(Lemma('look.v.01.look'), ['looked']),\n",
       "   ['up'],\n",
       "   ['across'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('aisle.n.02.aisle'), ['aisle']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('whole.a.01.whole'), ['whole']),\n",
       "   Tree(Lemma('aviary.n.01.aviary'), ['aviary']),\n",
       "   ['in'],\n",
       "   ['my'],\n",
       "   Tree(Lemma('head.n.01.head'), ['head']),\n",
       "   Tree(Lemma('explode.v.02.burst'), ['burst']),\n",
       "   ['into'],\n",
       "   Tree(Lemma('birdcall.n.01.song'), ['song']),\n",
       "   ['.']],\n",
       "  [['A'],\n",
       "   Tree(Lemma('slightly.r.01.somewhat'), ['somewhat']),\n",
       "   Tree(Lemma('less.r.01.less'), ['less']),\n",
       "   Tree('fragmented.s.00', ['fragmented']),\n",
       "   Tree(Lemma('hebephrenic.s.01.hebephrenic'), ['hebephrenic']),\n",
       "   Tree(Lemma('patient.n.01.patient'), ['patient']),\n",
       "   ['of'],\n",
       "   ['mine'],\n",
       "   [','],\n",
       "   ['who'],\n",
       "   ['used', 'to'],\n",
       "   Tree(Lemma('frequently.r.01.often'), ['often']),\n",
       "   Tree(Lemma('seclude.v.01.seclude'), ['seclude']),\n",
       "   ['herself'],\n",
       "   ['in'],\n",
       "   ['her'],\n",
       "   Tree(Lemma('room.n.01.room'), ['room']),\n",
       "   [','],\n",
       "   Tree(Lemma('frequently.r.01.often'), ['often']),\n",
       "   Tree(Lemma('sound.v.03.sound'), ['sounded']),\n",
       "   ['through'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('shut.a.01.closed'), ['closed']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['-'],\n",
       "   ['as'],\n",
       "   ['I'],\n",
       "   ['would'],\n",
       "   Tree(Lemma('detect.v.01.find'), ['find']),\n",
       "   ['on'],\n",
       "   Tree(Lemma('travel_by.v.01.pass_by'), ['passing', 'by']),\n",
       "   [','],\n",
       "   ['between'],\n",
       "   ['our'],\n",
       "   Tree(Lemma('session.n.01.session'), ['sessions']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('for_love_or_money.r.01.for_all_the_world'), ['for', 'all', 'the', 'world']),\n",
       "   ['like'],\n",
       "   Tree(Lemma('two.s.01.two'), ['two']),\n",
       "   Tree(Lemma('person.n.01.person'), ['persons']),\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree('scolding.a.00', ['scolding']),\n",
       "   Tree(Lemma('mother.n.01.mother'), ['mother']),\n",
       "   ['and'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('defensive.s.02.defensive'), ['defensive']),\n",
       "   Tree(Lemma('child.n.02.child'), ['child']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('exit.v.01.get_out'), ['got', 'out']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('there.r.01.there'), ['there']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('haste.n.01.hurry'), ['hurry']),\n",
       "   [','],\n",
       "   Tree(Lemma('brush.v.02.brush'), ['brushing']),\n",
       "   Tree(Lemma('by.r.01.past'), ['past']),\n",
       "   ['another'],\n",
       "   Tree(Lemma('man.n.01.man'), ['man']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   Tree(Lemma('wipe_up.v.01.mop'), ['mopping']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('brow.n.01.brow'), ['brow']),\n",
       "   ['.']],\n",
       "  [['But'],\n",
       "   ['she'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('talk.v.01.talk'), ['talking']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Emile'])]),\n",
       "   ['when'],\n",
       "   ['she'],\n",
       "   Tree(Lemma('see.v.01.see'), ['saw']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('black.s.08.black'), ['black']),\n",
       "   Tree(Lemma('line.n.02.line'), ['line']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [';'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Sarah'])]),\n",
       "   Tree(Lemma('remember.v.01.remember'), ['remembered']),\n",
       "   ['it'],\n",
       "   Tree(Lemma('distinctly.r.01.clearly'), ['clearly']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Miss', 'Celie'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('take.v.27.take'), ['taken']),\n",
       "   ['to'],\n",
       "   ['her'],\n",
       "   Tree(Lemma('bed.n.01.bed'), ['bed']),\n",
       "   [','],\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree('locked.s.00', ['locked']),\n",
       "   ['.']],\n",
       "  [['Her'],\n",
       "   Tree(Lemma('skin.n.01.skin'), ['skin']),\n",
       "   Tree(Lemma('crawl.v.02.crawl'), ['crawled']),\n",
       "   [':'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Lolotte'])]),\n",
       "   ['had'],\n",
       "   Tree(Lemma('tell.v.02.tell'), ['told']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Maude'])]),\n",
       "   ['that'],\n",
       "   ['she'],\n",
       "   Tree(Lemma('be.v.03.be'), ['was']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('hallway.n.01.hall'), ['hall']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Sarah'])]),\n",
       "   ['had'],\n",
       "   Tree(Lemma('get_down.v.07.begin'), ['begun']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('tell.v.03.tell'), ['tell']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Lucien'])]),\n",
       "   ['of'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Emile'])]),\n",
       "   [','],\n",
       "   ['she'],\n",
       "   ['had'],\n",
       "   Tree(Lemma('get_down.v.07.begin'), ['begun']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('question.v.03.question'), ['question']),\n",
       "   ['and'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('small.a.01.little'), ['little']),\n",
       "   Tree(Lemma('draft.n.02.draft'), ['draft']),\n",
       "   ['had'],\n",
       "   Tree(Lemma('crawl.v.01.creep'), ['crept']),\n",
       "   ['across'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('room.n.01.room'), ['room']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bedroom.n.01.bedroom'), ['bedroom']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   Tree(Lemma('barely.r.01.barely'), ['barely']),\n",
       "   Tree(Lemma('enough.r.01.enough'), ['enough']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('show.v.04.show'), ['show']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('rim.n.01.rim'), ['rim']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('total_darkness.n.01.blackness'), ['blackness']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('hallway.n.01.hall'), ['hall']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Sarah'])]),\n",
       "   Tree(Lemma('find.v.03.find'), ['found']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('correct.s.02.right'), ['right']),\n",
       "   Tree(Lemma('key.n.01.key'), ['key']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('unlock.v.01.unlock'), ['unlocked']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['She'],\n",
       "   Tree(Lemma('depart.v.03.start'), ['started']),\n",
       "   Tree(Lemma('back.r.01.back'), ['back']),\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('house.n.01.house'), ['house']),\n",
       "   [','],\n",
       "   Tree(Lemma('see.v.01.see'), ['saw']),\n",
       "   ['a'],\n",
       "   Tree('light.n.5;1', ['light']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('office.n.01.office'), ['office']),\n",
       "   [','],\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('surprise.v.02.surprise'), ['surprised']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('domestic.a.03.domestic'), ['domestic']),\n",
       "   Tree('little.s.00', ['little']),\n",
       "   Tree(Lemma('view.n.02.scene'), ['scene']),\n",
       "   ['which'],\n",
       "   Tree(Lemma('be.v.03.be'), ['was']),\n",
       "   Tree(Lemma('far.r.01.far'), ['far']),\n",
       "   ['outside'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('black.s.05.dark'), ['dark']),\n",
       "   Tree(Lemma('kingdom.n.01.realm'), ['realm']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('murder.n.01.murder'), ['murder']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('attempted.s.01.attempted'), ['attempted']),\n",
       "   Tree(Lemma('murder.n.01.murder'), ['murder']),\n",
       "   ['.']],\n",
       "  [['Without'],\n",
       "   Tree(Lemma('take_off.v.02.take_off'), ['taking', 'off']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('coat.n.01.coat'), ['coat']),\n",
       "   [','],\n",
       "   ['he'],\n",
       "   Tree(Lemma('sit_down.v.01.sit'), ['sat']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('blue.s.01.blue'), ['blue']),\n",
       "   Tree(Lemma('chair.n.01.chair'), ['chair']),\n",
       "   ['which'],\n",
       "   Tree(Lemma('still.r.01.still'), ['still']),\n",
       "   Tree(Lemma('front.v.01.face'), ['faced']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('shut.a.01.closed'), ['closed']),\n",
       "   Tree(Lemma('bedroom.n.01.bedroom'), ['bedroom']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Blanche'])]),\n",
       "   Tree(Lemma('know.v.01.know'), ['knew']),\n",
       "   ['all'],\n",
       "   ['this'],\n",
       "   ['because'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Stanley'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('office.n.01.office'), ['office']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   ['and'],\n",
       "   [','],\n",
       "   ['without'],\n",
       "   Tree(Lemma('strive.v.02.strain'), ['straining']),\n",
       "   Tree(Lemma('excessively.r.01.too'), ['too']),\n",
       "   Tree(Lemma('hard.r.01.hard'), ['hard']),\n",
       "   [','],\n",
       "   ['she'],\n",
       "   ['could'],\n",
       "   Tree(Lemma('hear.v.01.hear'), ['hear']),\n",
       "   ['everything'],\n",
       "   ['that'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('old_man.n.01.old_man'), ['old', 'man']),\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('step.v.01.step'), ['stepped']),\n",
       "   Tree('out.r.00', ['out']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('sunlight.n.01.sunlight'), ['sunlight']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   ['Is'],\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   Tree(Lemma('adequate.s.02.enough'), ['enough']),\n",
       "   Tree(Lemma('time.n.02.time'), ['time']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('go.v.02.go'), ['go']),\n",
       "   ['into'],\n",
       "   ['it'],\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   ['he'],\n",
       "   Tree(Lemma('finish_up.v.02.finish'), ['finished']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('slam.v.01.slam'), ['slammed']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['in'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('son.n.01.son'), ['son']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('face.n.01.face'), ['face']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   ['Through'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('handily.r.01.conveniently'), ['conveniently']),\n",
       "   Tree(Lemma('unbarred.s.01.unlocked'), ['unlocked']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Madden'])]),\n",
       "   Tree(Lemma('supplement.v.01.supplement'), ['supplemented']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   ['That'],\n",
       "   Tree(Lemma('damn.s.01.damn'), ['damn']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('captain.n.03.police_chief'), ['police', 'chief']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   ['If'],\n",
       "   ['there'],\n",
       "   Tree(Lemma('exist.v.01.be'), ['was']),\n",
       "   Tree(Lemma('collusion.n.01.collusion'), ['collusion']),\n",
       "   ['between'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('external.s.02.outside'), ['outside']),\n",
       "   Tree(Lemma('murderer.n.01.murderer'), ['murderer']),\n",
       "   ['and'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('member.n.01.member'), ['member']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('family.n.01.household'), ['household']),\n",
       "   ['it'],\n",
       "   ['would'],\n",
       "   Tree(Lemma('be.v.02.be'), ['be']),\n",
       "   ['an'],\n",
       "   Tree(Lemma('elementary.s.01.elementary'), ['elementary']),\n",
       "   Tree(Lemma('precaution.n.01.precaution'), ['precaution']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('check.v.01.check'), ['check']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('subsequently.r.01.later'), ['later']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('open.v.03.open'), ['opened']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('three.s.01.three'), ['three']),\n",
       "   Tree(Lemma('man.n.01.man'), ['men']),\n",
       "   ['and'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('woman.n.01.woman'), ['woman']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('sari.n.01.sari'), ['sari']),\n",
       "   Tree(Lemma('sweep.v.02.sweep'), ['swept']),\n",
       "   ['past'],\n",
       "   ['him'],\n",
       "   ['and'],\n",
       "   Tree(Lemma('downstairs.r.01.down_the_stairs'), ['down', 'the', 'stairs']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('climb.v.01.climb'), ['climbed']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('stairs.n.01.steps'), ['steps']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('first.a.01.first'), ['first']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('anteroom.n.01.vestibule'), ['vestibule']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('inner.a.02.inner'), ['inner']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [';'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('cooking.n.01.cooking'), ['cooking']),\n",
       "   Tree(Lemma('olfactory_property.n.01.odor'), ['odors']),\n",
       "   Tree(Lemma('be.v.01.be'), ['were']),\n",
       "   Tree(Lemma('strong.s.02.strong'), ['stronger']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('everywhere.r.01.all_over'), ['all', 'over']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('city.n.01.city'), ['city']),\n",
       "   [','],\n",
       "   ['at'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('hour.n.02.hour'), ['hour']),\n",
       "   [','],\n",
       "   Tree(Lemma('housewife.n.01.housewife'), ['housewives']),\n",
       "   ['would'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('fuss.v.01.fuss'), ['fussing']),\n",
       "   ['over'],\n",
       "   Tree(Lemma('stove.n.01.stove'), ['stoves']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('hesitate.v.02.pause'), ['paused']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('landing.n.01.landing'), ['landing']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('steady.v.01.steady'), ['steady']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('breathing.n.01.breathing'), ['breathing']),\n",
       "   Tree(Lemma('then.r.01.and_then'), ['and', 'then']),\n",
       "   Tree(Lemma('crouch.v.01.bend'), ['bent']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('examine.v.02.examine'), ['examine']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('individual.a.01.single'), ['single']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('light.n.02.light'), ['light']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('weak.a.01.weak'), ['weak']),\n",
       "   Tree(Lemma('light_bulb.n.01.bulb'), ['bulb']),\n",
       "   Tree(Lemma('overhead.a.01.overhead'), ['overhead']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('now.n.01.now'), ['Now']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('certain.a.02.certain'), ['certain']),\n",
       "   [':'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('lock.n.01.lock'), ['lock']),\n",
       "   ['had'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('give_way.v.03.yield'), ['yielded']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Muller'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('collection.n.01.collection'), ['collection']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('key.n.01.key'), ['keys']),\n",
       "   [';'],\n",
       "   Tree(Lemma('fresh.s.02.fresh'), ['fresh']),\n",
       "   Tree(Lemma('scratch.n.10.scar'), ['scars']),\n",
       "   Tree('show.v.7;2', ['showed']),\n",
       "   ['that'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['had'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('pry.v.01.prise'), ['prized']),\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   ['had'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('shut.a.01.shut'), ['shut']),\n",
       "   Tree(Lemma('again.r.01.again'), ['again']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('lock.n.01.lock'), ['lock']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('broken.a.01.broken'), ['broken']),\n",
       "   [';'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('notice.v.02.note'), ['noted']),\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('frisson.n.01.thrill'), ['thrill']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('fear.n.01.fear'), ['fear']),\n",
       "   ['that'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('move.v.03.move'), ['moved']),\n",
       "   ['under'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('touch.n.01.touch'), ['touch']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Hoag'])]),\n",
       "   Tree(Lemma('push.v.01.push'), ['pushed']),\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [':'],\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('far.a.01.far'), ['far']),\n",
       "   Tree(Lemma('end.n.01.end'), ['end']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('long.a.02.long'), ['long']),\n",
       "   Tree(Lemma('dark.a.01.dark'), ['dark']),\n",
       "   Tree(Lemma('room.n.01.room'), ['room']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Muller'])]),\n",
       "   ['was'],\n",
       "   Tree(Lemma('faintly.r.01.faintly'), ['faintly']),\n",
       "   Tree(Lemma('silhouette.v.01.silhouette'), ['silhouetted']),\n",
       "   ['against'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('window.n.01.window'), ['window']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('rifle.n.01.rifle'), ['rifle']),\n",
       "   Tree(Lemma('still.r.01.still'), ['still']),\n",
       "   Tree(Lemma('raise.v.02.raise'), ['raised']),\n",
       "   [';'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('stand.v.01.stand'), ['stood']),\n",
       "   ['with'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('foot.n.01.foot'), ['feet']),\n",
       "   Tree(Lemma('apart.r.01.apart'), ['apart']),\n",
       "   ['on'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('kitchen_table.n.01.kitchen_table'), ['kitchen', 'table']),\n",
       "   ['he'],\n",
       "   ['had'],\n",
       "   Tree(Lemma('haul.v.01.drag'), ['dragged']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('sill.n.01.sill'), ['sill']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Gun'])]),\n",
       "   Tree(Lemma('travel.v.01.go'), ['went']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree('connecting.s.00', ['connecting']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   ['which'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('stand.v.01.stand'), ['stood']),\n",
       "   ['at'],\n",
       "   Tree(Lemma('attention.n.06.attention'), ['attention']),\n",
       "   ['while'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Orville', 'Torrence', 'Killpath'])]),\n",
       "   [','],\n",
       "   ['in'],\n",
       "   Tree(Lemma('full.s.03.full'), ['full']),\n",
       "   Tree(Lemma('uniform.n.01.uniform'), ['uniform']),\n",
       "   [','],\n",
       "   Tree(Lemma('complete.v.01.finish'), ['finished']),\n",
       "   Tree(Lemma('comb.v.03.comb'), ['combing']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('hair.n.01.hair'), ['hair']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('in_fact.r.01.in_fact'), ['In', 'fact']),\n",
       "   [','],\n",
       "   ['he'],\n",
       "   ['did'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('think_about.v.01.think_about'), ['think', 'about']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Jerry', 'Burton'])]),\n",
       "   Tree(Lemma('at_all.r.01.at_all'), ['at', 'all']),\n",
       "   ['until'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('enter.v.01.enter'), ['entered']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('living_room.n.01.living_room'), ['living', 'room']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('close.v.01.close'), ['closed']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['behind'],\n",
       "   ['him'],\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('exit.v.01.get_out'), ['got', 'out']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('lockup.n.01.lockup'), ['lockup']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('oak.n.01.oak'), ['oak']),\n",
       "   Tree(Lemma('board.n.02.plank'), ['planks']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('band.v.01.band'), ['banded']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('strap.n.01.strap'), ['strap']),\n",
       "   Tree(Lemma('iron.n.01.iron'), ['iron']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Macklin'])]),\n",
       "   Tree(Lemma('resist.v.06.balk'), ['balked']),\n",
       "   Tree(Lemma('again.r.01.again'), ['again']),\n",
       "   [','],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('desire.v.01.want'), ['wanting']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('unlock.v.01.unlock'), ['unlock']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('open.v.01.open'), ['open']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('once.r.02.once'), ['Once']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   [','],\n",
       "   ['they'],\n",
       "   Tree(Lemma('herd.v.01.crowd'), ['crowded']),\n",
       "   ['him'],\n",
       "   ['inside'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('dark.a.01.dark'), ['dark']),\n",
       "   Tree(Lemma('building.n.01.building'), ['building']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('utter.v.02.utter'), ['uttering']),\n",
       "   Tree(Lemma('threat.n.02.threat'), ['threats']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('low.s.03.low'), ['low']),\n",
       "   ['but'],\n",
       "   Tree(Lemma('barbarous.s.01.savage'), ['savage']),\n",
       "   Tree(Lemma('voice.n.02.voice'), ['voice']),\n",
       "   ['when'],\n",
       "   ['they'],\n",
       "   Tree(Lemma('close.v.01.close'), ['closed']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('padlock.v.01.padlock'), ['padlocked']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['This'],\n",
       "   Tree(Lemma('be.v.02.be'), ['was']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('message.n.01.message'), ['message']),\n",
       "   Tree(Lemma('detect.v.01.find'), ['found']),\n",
       "   Tree(Lemma('tack.v.01.tack'), ['tacked']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('cabin.n.02.cabin'), ['cabin']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['There'],\n",
       "   ['was'],\n",
       "   ['no'],\n",
       "   Tree(Lemma('lock.n.01.lock'), ['lock']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   Tree(Lemma('merely.r.01.only'), ['only']),\n",
       "   ['an'],\n",
       "   Tree(Lemma('iron.n.01.iron'), ['iron']),\n",
       "   Tree(Lemma('hook.n.01.hook'), ['hook']),\n",
       "   ['which'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('unfasten.v.01.unfasten'), ['unfastened']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('enter.v.01.go_in'), ['went', 'in']),\n",
       "   [','],\n",
       "   Tree(Lemma('pull.v.01.pull'), ['pulling']),\n",
       "   ['it'],\n",
       "   Tree(Lemma('shut.a.01.shut'), ['shut']),\n",
       "   ['behind'],\n",
       "   ['him'],\n",
       "   ['.']],\n",
       "  [['As'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Curt'])]),\n",
       "   ['had'],\n",
       "   Tree(Lemma('hope.v.03.hope'), ['hoped']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('house.n.01.house'), ['house']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('bang.v.04.bang'), ['banged']),\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Curt'])]),\n",
       "   Tree(Lemma('move_over.v.01.move_over'), ['moved', 'over']),\n",
       "   ['beside'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   Tree('wait.v.2;1', ['waited']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('swing.v.02.swing'), ['swung']),\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Jess'])]),\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   Tree(Lemma('sourly.r.01.sourly'), ['sourly']),\n",
       "   [','],\n",
       "   ['``'],\n",
       "   ['What'],\n",
       "   ['the'],\n",
       "   ['hell'],\n",
       "   [\"'s\"],\n",
       "   Tree('the_matter.s.00', ['the', 'matter']),\n",
       "   ['with'],\n",
       "   ['you'],\n",
       "   ['?'],\n",
       "   [\"''\"]],\n",
       "  [['He'],\n",
       "   Tree(Lemma('reach.v.03.reach_out'), ['reached', 'out']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('pull.v.01.pull'), ['pull']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('shut.a.01.shut'), ['shut']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('fasten.v.01.fasten'), ['fasten']),\n",
       "   ['it'],\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('sliding.s.01.sliding'), ['sliding']),\n",
       "   Tree(Lemma('bolt.n.03.bolt'), ['bolt']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Jess'])]),\n",
       "   Tree(Lemma('painfully.r.01.painfully'), ['painfully']),\n",
       "   Tree(Lemma('become.v.01.get'), ['got']),\n",
       "   ['to'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('foot.n.01.foot'), ['feet']),\n",
       "   ['as'],\n",
       "   ['someone'],\n",
       "   Tree(Lemma('rattle.v.02.rattle'), ['rattled']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Curt'])]),\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   Tree(Lemma('catch.v.04.grab'), ['grabbed']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Black'])]),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('shoulder.n.01.shoulder'), ['shoulder']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('pull.v.01.pull'), ['pulled']),\n",
       "   ['him'],\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('barn.n.01.barn'), ['barn']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Curt'])]),\n",
       "   Tree(Lemma('follow.v.01.follow'), ['followed']),\n",
       "   [','],\n",
       "   Tree(Lemma('reach.v.03.reach'), ['reaching']),\n",
       "   ['behind'],\n",
       "   ['him'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('close.v.01.shut'), ['shut']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('hook.v.01.hook'), ['hook']),\n",
       "   ['it'],\n",
       "   ['.']],\n",
       "  [['All'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['doors']),\n",
       "   Tree(Lemma('be.v.01.be'), ['were']),\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   ['at'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('hour.n.02.hour'), ['hour']),\n",
       "   ['except'],\n",
       "   Tree('one.s.00', ['one']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['it'],\n",
       "   ['was'],\n",
       "   ['toward'],\n",
       "   ['this'],\n",
       "   ['that'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Stevens'])]),\n",
       "   Tree(Lemma('reach.v.07.make'), ['made']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('direction.n.01.way'), ['way']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Russ'])]),\n",
       "   Tree(Lemma('near.r.01.close'), ['close']),\n",
       "   ['at'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('shoulder.n.01.shoulder'), ['shoulder']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree('locked.s.00', ['locked']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Johnson'])]),\n",
       "   Tree(Lemma('unwire.v.01.unwire'), ['unwired']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('right-hand.s.01.right-hand'), ['right', 'hand']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   ['whose'],\n",
       "   Tree(Lemma('window.n.01.window'), ['window']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   [','],\n",
       "   ['like'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('left.a.01.left'), ['left']),\n",
       "   ['one'],\n",
       "   [','],\n",
       "   Tree(Lemma('merely.r.01.merely'), ['merely']),\n",
       "   Tree(Lemma('loosely.r.01.loosely'), ['loosely']),\n",
       "   Tree(Lemma('taped.s.01.taped'), ['taped']),\n",
       "   Tree(Lemma('shard.n.01.fragment'), ['fragments']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('glass.n.01.glass'), ['glass']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Johnson'])]),\n",
       "   Tree(Lemma('pack.v.03.wad'), ['wadded']),\n",
       "   ['himself'],\n",
       "   ['into'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('narrow.a.01.narrow'), ['narrow']),\n",
       "   Tree(Lemma('seat.n.01.seat'), ['seat']),\n",
       "   Tree(Lemma('make.v.02.make'), ['made']),\n",
       "   Tree(Lemma('even.r.03.still'), ['still']),\n",
       "   Tree(Lemma('more.r.01.more'), ['more']),\n",
       "   Tree(Lemma('narrow.a.01.narrow'), ['narrow']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('three.s.01.three'), ['three']),\n",
       "   Tree('case.n.10;5', ['cases']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('beer.n.01.beer'), ['beer']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('back.r.01.back'), ['Back']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Factory-to-You'])]),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree('other.s.00', ['other']),\n",
       "   Tree(Lemma('spinster.n.01.old_maid'), ['old', 'maids']),\n",
       "   [','],\n",
       "   Tree(Lemma('back.r.01.back'), ['back']),\n",
       "   Tree(Lemma('there.r.01.there'), ['there']),\n",
       "   ['she'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('young.a.01.young'), ['youngest']),\n",
       "   Tree(Lemma('salesclerk.n.01.clerk'), ['clerk']),\n",
       "   ['and'],\n",
       "   ['she'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   ['thirty-four'],\n",
       "   [','],\n",
       "   ['which'],\n",
       "   Tree(Lemma('make.v.02.make'), ['made']),\n",
       "   ['her'],\n",
       "   Tree(Lemma('young.a.01.young'), ['young']),\n",
       "   Tree(Lemma('enough.r.01.enough'), ['enough']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('resent.v.01.resent'), ['resent']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('usual.a.01.usual'), ['usual']),\n",
       "   Tree(Lemma('ideal.s.01.ideal'), ['ideal']),\n",
       "   Tree(Lemma('working.s.01.working'), ['working']),\n",
       "   Tree(Lemma('condition.n.01.condition'), ['conditions']),\n",
       "   [','],\n",
       "   ['like'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('unventilated.a.01.unventilated'), ['unventilated']),\n",
       "   Tree(Lemma('toilet.n.01.toilet'), ['toilet']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['you'],\n",
       "   Tree('have.v.00', ['had']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('keep.v.01.hold'), ['hold']),\n",
       "   Tree(Lemma('shut.a.01.shut'), ['shut']),\n",
       "   ['while'],\n",
       "   ['you'],\n",
       "   Tree(Lemma('sit.v.01.sit_down'), ['sat', 'down']),\n",
       "   ['.']],\n",
       "  [['She'],\n",
       "   ['could'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('count.v.01.count'), ['count']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('time.n.01.time'), ['times']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Herman'])]),\n",
       "   ['had'],\n",
       "   Tree(Lemma('rap.v.01.rap'), ['rapped']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   Tree(Lemma('merely.r.01.just'), ['just']),\n",
       "   Tree(Lemma('a_few.s.01.a_couple_of'), ['a', 'couple', 'of']),\n",
       "   Tree(Lemma('knock.n.03.bang'), ['bangs']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('judder.v.01.shake'), ['shook']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('whole.a.01.whole'), ['whole']),\n",
       "   Tree(Lemma('blasted.s.01.damned'), ['damned']),\n",
       "   Tree(Lemma('water_closet.n.01.closet'), ['closet']),\n",
       "   ['and'],\n",
       "   ['might'],\n",
       "   [','],\n",
       "   Tree(Lemma('someday.r.01.someday'), ['someday']),\n",
       "   [','],\n",
       "   Tree(Lemma('chip.v.01.break_away'), ['break', 'away']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('pipe.n.02.pipe'), ['pipe']),\n",
       "   Tree(Lemma('connection.n.03.connection'), ['connections']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('wall.n.01.wall'), ['wall']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('two.s.01.two'), ['two']),\n",
       "   Tree(Lemma('small.a.01.little'), ['little']),\n",
       "   Tree(Lemma('knock.n.03.bang'), ['bangs']),\n",
       "   Tree(Lemma('mean.v.01.mean'), ['meant']),\n",
       "   ['that'],\n",
       "   ['he'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('become.v.01.get'), ['getting']),\n",
       "   Tree(Lemma('impatient.a.01.impatient'), ['impatient']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('get.v.03.have'), ['have']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('crowd.n.01.crowd'), ['crowd']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('customer.n.01.customer'), ['customers']),\n",
       "   Tree(Lemma('wait.v.04.wait'), ['waited']),\n",
       "   ['on'],\n",
       "   ['and'],\n",
       "   ['that'],\n",
       "   ['if'],\n",
       "   ['he'],\n",
       "   Tree('have.v.00', ['had']),\n",
       "   ['to'],\n",
       "   ['he'],\n",
       "   ['would'],\n",
       "   Tree(Lemma('yank.v.01.jerk'), ['jerk']),\n",
       "   Tree(Lemma('open.a.01.open'), ['open']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('haul.v.01.drag'), ['drag']),\n",
       "   Tree('out.a.00', ['out']),\n",
       "   [','],\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('opposite.s.01.opposite'), ['opposite']),\n",
       "   Tree(Lemma('doorknob.n.01.doorhandle'), ['door', 'handle']),\n",
       "   ['which'],\n",
       "   ['she'],\n",
       "   ['would'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('cling_to.v.01.clutch'), ['clutching']),\n",
       "   [','],\n",
       "   ['whichever-the-hell'],\n",
       "   Tree(Lemma('salesclerk.n.01.clerk'), ['clerk']),\n",
       "   ['it'],\n",
       "   Tree(Lemma('be.v.02.be'), ['was']),\n",
       "   ['who'],\n",
       "   Tree(Lemma('think.v.02.think'), ['thought']),\n",
       "   ['she'],\n",
       "   ['could'],\n",
       "   Tree(Lemma('waste.v.02.waste'), ['waste']),\n",
       "   Tree('so_much.s.00', ['so', 'much']),\n",
       "   Tree(Lemma('shop.n.01.store'), ['store']),\n",
       "   Tree(Lemma('time.n.02.time'), ['time']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('toilet.n.02.pot'), ['pot']),\n",
       "   ['.']],\n",
       "  [['After'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('short.a.01.short'), ['short']),\n",
       "   Tree(Lemma('time.n.03.time'), ['time']),\n",
       "   [','],\n",
       "   ['both'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['George'])]),\n",
       "   ['and'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Donald'])]),\n",
       "   Tree(Lemma('join.v.01.join'), ['joined']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('class.n.02.class'), ['class']),\n",
       "   ['with'],\n",
       "   ['me'],\n",
       "   Tree(Lemma('so.r.02.so'), ['so']),\n",
       "   ['they'],\n",
       "   ['would'],\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   Tree(Lemma('feel.v.01.feel'), ['feel']),\n",
       "   Tree(Lemma('lonely.s.02.lonely'), ['lonely']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['we'],\n",
       "   ['used', 'to'],\n",
       "   Tree(Lemma('hang.v.02.hang'), ['hang']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('sign.n.02.sign'), ['sign']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   ['Brush-off'],\n",
       "   Tree(Lemma('read.v.02.read'), ['reading']),\n",
       "   ['``'],\n",
       "   Tree('out.a.00', ['out']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('work.n.01.work'), ['work']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['and'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Phil'])]),\n",
       "   Tree(Lemma('slam.v.01.bang'), ['banged']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('cabinet.n.03.locker'), ['locker']),\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   Tree(Lemma('shut.a.01.shut'), ['shut']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('spin.v.01.spin_around'), ['spun', 'around']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Phil'])]),\n",
       "   Tree(Lemma('follow.v.01.follow'), ['followed']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Eddie'])]),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('office.n.01.office'), ['office']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('close.v.01.shut'), ['shut']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Phil'])]),\n",
       "   Tree(Lemma('close.v.01.shut'), ['shut']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('door.n.01.door'), ['door']),\n",
       "   ['behind'],\n",
       "   ['him'],\n",
       "   ['.']],\n",
       "  [Tree(Lemma('door.n.01.door'), ['Doors']),\n",
       "   ['that'],\n",
       "   ['won'],\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   Tree(Lemma('open.v.01.open'), ['open']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('door.n.01.door'), ['doors']),\n",
       "   ['that'],\n",
       "   ['won'],\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   Tree(Lemma('close.v.02.close'), ['close']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('shelf.n.01.shelf'), ['shelves']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('broken.a.01.broken'), ['broken']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [Tree(Lemma('door.n.01.door'), ['Doors']),\n",
       "   ['that'],\n",
       "   ['won'],\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   Tree(Lemma('open.v.01.open'), ['open']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('door.n.01.door'), ['doors']),\n",
       "   ['that'],\n",
       "   ['won'],\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   Tree(Lemma('close.v.02.close'), ['close']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('shelf.n.01.shelf'), ['shelves']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('broken.a.01.broken'), ['broken']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   ['should'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('install.v.01.install'), ['installed']),\n",
       "   ['over'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['that'],\n",
       "   ['is'],\n",
       "   Tree('in_full_view.s.00', ['in', 'full', 'view']),\n",
       "   ['of'],\n",
       "   ['everyone'],\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('chair.n.01.chair'), ['chair']),\n",
       "   ['should'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('put.v.01.place'), ['placed']),\n",
       "   ['under'],\n",
       "   ['it'],\n",
       "   [','],\n",
       "   Tree(Lemma('a_bit.r.01.a_little'), ['a', 'little']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('one.s.01.one'), ['one']),\n",
       "   Tree(Lemma('side.n.01.side'), ['side']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('promise.v.02.promise'), ['promised']),\n",
       "   ['that'],\n",
       "   ['no'],\n",
       "   Tree(Lemma('injury.n.01.harm'), ['harm']),\n",
       "   ['would'],\n",
       "   Tree(Lemma('befall.v.01.befall'), ['befall']),\n",
       "   ['him'],\n",
       "   ['if'],\n",
       "   ['he'],\n",
       "   ['would'],\n",
       "   Tree(Lemma('come_on.v.01.come_out'), ['come', 'out']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('curse.v.01.curse'), ['cursed']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('answer.v.01.reply'), ['replied']),\n",
       "   ['that'],\n",
       "   ['he'],\n",
       "   ['would'],\n",
       "   Tree(Lemma('shoot.v.02.shoot'), ['shoot']),\n",
       "   ['any'],\n",
       "   Tree(Lemma('man.n.01.man'), ['man']),\n",
       "   Tree(Lemma('approach.v.01.come_near'), ['coming', 'near']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('shoot.v.01.shoot'), ['Shot']),\n",
       "   ['near'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   [','],\n",
       "   ['he'],\n",
       "   Tree(Lemma('turn.v.01.turn'), ['turned']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('one.s.01.one'), ['one']),\n",
       "   Tree(Lemma('side.n.03.side'), ['side']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('dive.v.01.plunge'), ['plunged']),\n",
       "   ['for'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['to'],\n",
       "   ['another'],\n",
       "   Tree(Lemma('room.n.01.room'), ['room']),\n",
       "   Tree('several.s.01', ['several']),\n",
       "   Tree(Lemma('foot.n.02.foot'), ['feet']),\n",
       "   Tree(Lemma('away.r.02.away'), ['away']),\n",
       "   [','],\n",
       "   Tree(Lemma('three.s.01.three'), ['three']),\n",
       "   Tree(Lemma('bullet.n.01.bullet'), ['bullets']),\n",
       "   Tree(Lemma('follow.v.01.follow'), ['following']),\n",
       "   ['him'],\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   ['1846'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Matthew', 'B.', 'Goodwin'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('jewelry_maker.n.01.jeweler'), ['jeweler']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('watchmaker.n.01.watchmaker'), ['watchmaker']),\n",
       "   [','],\n",
       "   Tree(Lemma('become.v.02.become'), ['became']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('town.n.01.town'), ['town']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('first.a.01.first'), ['first']),\n",
       "   Tree(Lemma('telegrapher.n.01.telegrapher'), ['telegrapher']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('dwelling.n.01.dwelling'), ['dwelling']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('construct.v.01.build'), ['built']),\n",
       "   ['for'],\n",
       "   ['himself'],\n",
       "   ['and'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('business.n.01.business'), ['business']),\n",
       "   ['``'],\n",
       "   Tree(Lemma('two.s.01.two'), ['two']),\n",
       "   Tree(Lemma('doorway.n.01.door'), ['doors']),\n",
       "   Tree(Lemma('north.a.01.north'), ['north']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Equinox', 'House'])]),\n",
       "   [\"''\"],\n",
       "   ['or'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('one.s.01.one'), ['one']),\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   Tree(Lemma('north.r.01.north'), ['north']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Bank'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('manchester.n.02.Manchester'), ['Manchester']),\n",
       "   [','],\n",
       "   Tree(Lemma('vermont.n.01.Vermont'), ['Vermont']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   ['1846'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Matthew', 'B.', 'Goodwin'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('jewelry_maker.n.01.jeweler'), ['jeweler']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('watchmaker.n.01.watchmaker'), ['watchmaker']),\n",
       "   [','],\n",
       "   Tree(Lemma('become.v.02.become'), ['became']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('town.n.01.town'), ['town']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('first.a.01.first'), ['first']),\n",
       "   Tree(Lemma('telegrapher.n.01.telegrapher'), ['telegrapher']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('dwelling.n.01.dwelling'), ['dwelling']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('construct.v.01.build'), ['built']),\n",
       "   ['for'],\n",
       "   ['himself'],\n",
       "   ['and'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('business.n.01.business'), ['business']),\n",
       "   ['``'],\n",
       "   Tree(Lemma('two.s.01.two'), ['two']),\n",
       "   Tree(Lemma('doorway.n.01.door'), ['doors']),\n",
       "   Tree(Lemma('north.a.01.north'), ['north']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Equinox', 'House'])]),\n",
       "   [\"''\"],\n",
       "   ['or'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('one.s.01.one'), ['one']),\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   Tree(Lemma('north.r.01.north'), ['north']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Bank'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('manchester.n.02.Manchester'), ['Manchester']),\n",
       "   [','],\n",
       "   Tree(Lemma('vermont.n.01.Vermont'), ['Vermont']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Frederick', 'Seward'])]),\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('father.n.01.father'), ['father']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('sleep.v.01.sleep'), ['sleeping']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('then.r.01.then'), ['then']),\n",
       "   Tree(Lemma('go.v.02.go'), ['went']),\n",
       "   ['through'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('mime.n.02.pantomime'), ['pantomime']),\n",
       "   ['at'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('father.n.01.father'), ['father']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   ['to'],\n",
       "   Tree(Lemma('prove.v.02.prove'), ['prove']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('statement.n.01.statement'), ['statement']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('clatter.v.01.clatter'), ['clattered']),\n",
       "   Tree(Lemma('downstairs.r.01.down_the_stairs'), ['down', 'the', 'stairs']),\n",
       "   ['and'],\n",
       "   ['out'],\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['When'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['McFeeley'])]),\n",
       "   Tree(Lemma('be.v.03.be'), ['was']),\n",
       "   Tree(Lemma('center.s.01.halfway'), ['halfway']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('owner.n.01.proprietor'), ['proprietor']),\n",
       "   Tree(Lemma('emerge.v.01.emerge'), ['emerged']),\n",
       "   ['-'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('mountainous.s.02.mountainous'), ['mountainous']),\n",
       "   [','],\n",
       "   Tree(Lemma('dark.s.03.dark'), ['dark']),\n",
       "   Tree(Lemma('man.n.01.man'), ['man']),\n",
       "   [','],\n",
       "   ['his'],\n",
       "   Tree(Lemma('head.n.01.head'), ['head']),\n",
       "   Tree('thick_with.s.00', ['thick', 'with']),\n",
       "   Tree(Lemma('pitchy.s.02.resiny'), ['resiny']),\n",
       "   Tree(Lemma('black.a.01.black'), ['black']),\n",
       "   Tree(Lemma('hair.n.01.hair'), ['hair']),\n",
       "   [','],\n",
       "   ['his'],\n",
       "   Tree(Lemma('eye.n.01.eye'), ['eyes']),\n",
       "   ['like'],\n",
       "   Tree(Lemma('two.n.01.two'), ['two']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('black_olive.n.01.black_olive'), ['black', 'olives']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('import.v.01.import'), ['imported']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('boatload.n.01.boatload'), ['boatloads']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Skopas'])]),\n",
       "   Tree(Lemma('express.v.02.express'), ['expressed']),\n",
       "   ['no'],\n",
       "   Tree(Lemma('curiosity.n.01.curiosity'), ['curiosity']),\n",
       "   ['over'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('case.n.08.case'), ['case']),\n",
       "   [','],\n",
       "   Tree(Lemma('offer.v.05.offer'), ['offered']),\n",
       "   ['no'],\n",
       "   Tree(Lemma('expression.n.03.expression'), ['expression']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('sympathy.n.02.sympathy'), ['sympathy']),\n",
       "   [','],\n",
       "   Tree(Lemma('make.v.01.make'), ['made']),\n",
       "   Tree(Lemma('no.r.01.no'), ['no']),\n",
       "   Tree(Lemma('move.n.01.move'), ['move']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('escort.v.01.escort'), ['escort']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['McFeeley'])]),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('answer.v.02.answer'), ['answered']),\n",
       "   ['by'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('slender.s.01.slender'), ['slender']),\n",
       "   Tree(Lemma('man.n.01.man'), ['man']),\n",
       "   ['in'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('sixties.n.02.sixties'), ['sixties']),\n",
       "   ['-'],\n",
       "   Tree('straight-backed.s.00', ['straight', 'backed']),\n",
       "   [','],\n",
       "   Tree(Lemma('slightly.r.01.somewhat'), ['somewhat']),\n",
       "   Tree(Lemma('clerical.a.02.clerical'), ['clerical']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('manner.n.02.manner'), ['manner']),\n",
       "   [','],\n",
       "   Tree(Lemma('wear.v.02.wear'), ['wearing']),\n",
       "   Tree(Lemma('rimless.a.01.rimless'), ['rimless']),\n",
       "   Tree(Lemma('spectacles.n.01.glasses'), ['glasses']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('beckon.v.01.beckon'), ['beckoned']),\n",
       "   ['to'],\n",
       "   ['her'],\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   ['she'],\n",
       "   Tree(Lemma('steal.v.02.slip'), ['slipped']),\n",
       "   Tree(Lemma('quietly.r.03.quietly'), ['quietly']),\n",
       "   Tree(Lemma('outdoor.a.01.outside'), ['outside']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('now.r.01.now'), ['Now']),\n",
       "   ['she'],\n",
       "   ['could'],\n",
       "   Tree(Lemma('let.v.02.let'), ['let']),\n",
       "   Tree('out.r.00', ['out']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('three.s.01.three'), ['three']),\n",
       "   Tree(Lemma('parakeet.n.01.parakeet'), ['parakeets']),\n",
       "   Tree('without_fear.r.00', ['without', 'fear']),\n",
       "   ['they'],\n",
       "   ['would'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('step_on.v.01.step_on'), ['stepped', 'on']),\n",
       "   ['or'],\n",
       "   ['that'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Stowey'])]),\n",
       "   ['would'],\n",
       "   Tree(Lemma('let.v.02.let'), ['let']),\n",
       "   ['them'],\n",
       "   ['out'],\n",
       "   ['one'],\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['doors']),\n",
       "   [';'],\n",
       "   ['she'],\n",
       "   ['could'],\n",
       "   Tree(Lemma('dust.v.01.dust'), ['dust']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('plant.n.02.plant'), ['plants']),\n",
       "   [','],\n",
       "   Tree(Lemma('then.r.01.then'), ['then']),\n",
       "   Tree(Lemma('cut_short.v.01.break_off'), ['break', 'off']),\n",
       "   Tree(Lemma('abruptly.r.01.suddenly'), ['suddenly']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('pick_up.v.02.pick_up'), ['pick', 'up']),\n",
       "   ['an'],\n",
       "   Tree(Lemma('old.a.02.old'), ['old']),\n",
       "   Tree(Lemma('novel.n.01.novel'), ['novel']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('read.v.01.read'), ['read']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('center.n.01.middle'), ['middle']),\n",
       "   ['on'],\n",
       "   [';'],\n",
       "   Tree(Lemma('improvise.v.01.improvise'), ['improvise']),\n",
       "   Tree(Lemma('cha-cha.n.01.cha-cha'), ['cha-chas']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('harp.n.01.harp'), ['harp']),\n",
       "   [';'],\n",
       "   ['and'],\n",
       "   Tree(Lemma('last.r.02.finally'), ['finally']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('best.a.01.best'), ['best']),\n",
       "   Tree(Lemma('part.n.01.part'), ['part']),\n",
       "   ['of'],\n",
       "   ['all'],\n",
       "   [','],\n",
       "   Tree(Lemma('merely.r.01.simply'), ['simply']),\n",
       "   Tree(Lemma('sit.v.01.sit'), ['sit']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('board.n.02.plank'), ['plank']),\n",
       "   Tree(Lemma('table.n.02.table'), ['table']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('kitchen.n.01.kitchen'), ['kitchen']),\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('bottle.n.01.bottle'), ['bottle']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('wine.n.01.wine'), ['wine']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('newspaper.n.01.newspaper'), ['newspapers']),\n",
       "   [','],\n",
       "   Tree(Lemma('read.v.01.read'), ['reading']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('ad.n.01.ad'), ['ads']),\n",
       "   ['as', 'well', 'as'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('news.n.02.news'), ['news']),\n",
       "   [','],\n",
       "   Tree(Lemma('record.v.04.register'), ['registering']),\n",
       "   Tree(Lemma('nothing.n.01.nothing'), ['nothing']),\n",
       "   ['on'],\n",
       "   ['her'],\n",
       "   Tree(Lemma('mind.n.01.mind'), ['mind']),\n",
       "   ['but'],\n",
       "   Tree(Lemma('let.v.01.let'), ['letting']),\n",
       "   ['her'],\n",
       "   Tree(Lemma('soul.n.01.soul'), ['soul']),\n",
       "   Tree(Lemma('suspend.v.01.suspend'), ['suspend']),\n",
       "   ['itself'],\n",
       "   ['above'],\n",
       "   Tree(Lemma('all.a.01.all'), ['all']),\n",
       "   Tree(Lemma('wish.n.01.wishing'), ['wishing']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('desire.n.01.desire'), ['desire']),\n",
       "   ['.']],\n",
       "  [['Through'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   ['he'],\n",
       "   ['had'],\n",
       "   Tree(Lemma('see.v.01.see'), ['seen']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Mr.', 'Jack'])]),\n",
       "   Tree(Lemma('perambulate.v.02.walk_around'), ['walking', 'around']),\n",
       "   [','],\n",
       "   Tree(Lemma('expect.v.03.wait'), ['waiting']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Miss', 'Ada'])]),\n",
       "   ['.']],\n",
       "  [['Should'],\n",
       "   ['I'],\n",
       "   Tree(Lemma('accompany.v.02.accompany'), ['accompany']),\n",
       "   ['her'],\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['of'],\n",
       "   ['her'],\n",
       "   Tree(Lemma('dwelling.n.01.home'), ['home']),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   ['should'],\n",
       "   ['I'],\n",
       "   Tree(Lemma('ask.v.02.ask'), ['ask']),\n",
       "   ['to'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('invite.v.06.invite'), ['invited']),\n",
       "   Tree('in.a.00', ['in']),\n",
       "   ['?']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('meat.n.01.meat'), ['meat']),\n",
       "   Tree(Lemma('wagon.n.01.wagon'), ['wagon']),\n",
       "   [','],\n",
       "   Tree(Lemma('therefore.r.01.therefore'), ['therefore']),\n",
       "   [','],\n",
       "   Tree(Lemma('be.v.03.be'), ['was']),\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree('out.r.00', ['out']),\n",
       "   ['in', 'front'],\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('house.n.01.house'), ['house']),\n",
       "   Tree(Lemma('anymore.r.01.anymore'), ['any', 'more']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bunch.n.01.cluster'), ['cluster']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('cruiser.n.01.squad_car'), ['squad', 'cars']),\n",
       "   Tree(Lemma('be.v.03.be'), ['was']),\n",
       "   Tree(Lemma('still.r.01.still'), ['still']),\n",
       "   Tree(Lemma('there.r.01.there'), ['there']),\n",
       "   ['and'],\n",
       "   ['there'],\n",
       "   Tree(Lemma('be.v.05.be'), ['was']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('bull.n.05.cop'), ['cop']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   Tree(Lemma('downstairs.r.01.downstairs'), ['downstairs']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('screen.v.01.screen'), ['screen']),\n",
       "   ['any'],\n",
       "   Tree(Lemma('approach.n.02.coming'), ['comings']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('departure.n.01.going'), ['goings']),\n",
       "   ['.']],\n",
       "  [['You'],\n",
       "   Tree(Lemma('shoulder.v.02.shoulder'), ['shoulder']),\n",
       "   ['your'],\n",
       "   Tree(Lemma('room.n.02.way'), ['way']),\n",
       "   ['through'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bunch.n.01.cluster'), ['cluster']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('curious.a.02.curious'), ['curious']),\n",
       "   ['and'],\n",
       "   ['you'],\n",
       "   Tree(Lemma('barge.v.01.barge'), ['barge']),\n",
       "   ['up'],\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bull.n.05.cop'), ['cop']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('alternatively.r.01.instead'), ['Instead']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('answer.v.01.answer'), ['answering']),\n",
       "   ['you'],\n",
       "   [','],\n",
       "   ['he'],\n",
       "   Tree(Lemma('lodge.v.02.stick'), ['sticks']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('head.n.01.head'), ['head']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('shout.v.02.shout'), ['shouts']),\n",
       "   Tree(Lemma('upstairs.r.01.up_the_stairs'), ['up', 'the', 'stairs']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Hub'])]),\n",
       "   ['was'],\n",
       "   Tree(Lemma('sit.v.02.sit'), ['sitting']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('chair.n.01.chair'), ['chair']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('barricade.v.01.block'), ['blocked']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('anteroom.n.01.hall'), ['hall']),\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['If'],\n",
       "   ['these'],\n",
       "   Tree(Lemma('facility.n.01.facility'), ['facilities']),\n",
       "   Tree(Lemma('be.v.03.be'), ['are']),\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   Tree(Lemma('get.v.01.get'), ['getting']),\n",
       "   ['them'],\n",
       "   ['may'],\n",
       "   Tree(Lemma('cost.v.01.cost'), ['cost']),\n",
       "   Tree('more_than.r.00', ['more', 'than']),\n",
       "   ['you'],\n",
       "   Tree(Lemma('expect.v.01.expect'), ['expect']),\n",
       "   ['.']],\n",
       "  [['Every'],\n",
       "   Tree(Lemma('path.n.02.path'), ['path']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('back.a.01.back'), ['back']),\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('barn.n.01.barn'), ['barn']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('cover.v.02.cover'), ['covered']),\n",
       "   ['by'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('grape_arbor.n.01.grape_arbor'), ['grape-arbor']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['every'],\n",
       "   Tree(Lemma('yard.n.02.yard'), ['yard']),\n",
       "   Tree(Lemma('have.v.01.have'), ['had']),\n",
       "   ['its'],\n",
       "   Tree(Lemma('fruit_tree.n.01.fruit_tree'), ['fruit', 'trees']),\n",
       "   ['.']],\n",
       "  [['For'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('affair.n.03.occasion'), ['occasion']),\n",
       "   ['on'],\n",
       "   ['which'],\n",
       "   ['everyone'],\n",
       "   Tree(Lemma('already.r.01.already'), ['already']),\n",
       "   Tree(Lemma('know.v.04.know'), ['knows']),\n",
       "   ['everyone'],\n",
       "   Tree('else.s.00', ['else']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('host.n.01.host'), ['host']),\n",
       "   Tree('wish.v.2;1', ['wishes']),\n",
       "   ['them'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('meet.v.08.meet'), ['meet']),\n",
       "   Tree(Lemma('one.s.01.one'), ['one']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('a_few.s.01.a_few'), ['a', 'few']),\n",
       "   Tree(Lemma('esteemed.s.01.honored'), ['honored']),\n",
       "   Tree(Lemma('newcomer.n.02.newcomer'), ['newcomers']),\n",
       "   [','],\n",
       "   Tree(Lemma('then.r.02.then'), ['then']),\n",
       "   ['the'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('open_house.n.01.open_house'), ['open', 'house']),\n",
       "   [\"''\"],\n",
       "   Tree(Lemma('system.n.01.system'), ['system']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('advantageous.a.01.advantageous'), ['advantageous']),\n",
       "   ['because'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('esteemed.s.01.honored'), ['honored']),\n",
       "   Tree(Lemma('guest.n.01.guest'), ['guests']),\n",
       "   Tree(Lemma('be.v.01.be'), ['are']),\n",
       "   Tree(Lemma('fixed.s.01.fixed'), ['fixed']),\n",
       "   Tree(Lemma('connective.s.01.connective'), ['connective']),\n",
       "   Tree(Lemma('point.n.02.point'), ['points']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree('drifting.s.00', ['drifting']),\n",
       "   Tree(Lemma('guest.n.01.guest'), ['guests']),\n",
       "   Tree(Lemma('make.v.01.make'), ['make']),\n",
       "   ['and'],\n",
       "   Tree('break.v.18;10', ['break']),\n",
       "   Tree(Lemma('connection.n.01.connection'), ['connections']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['At'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['she'],\n",
       "   Tree(Lemma('turn.v.01.turn'), ['turned']),\n",
       "   Tree(Lemma('back.r.02.back'), ['back']),\n",
       "   [','],\n",
       "   ['her'],\n",
       "   Tree(Lemma('roman_nose.n.01.Roman_nose'), ['Roman', 'nose']),\n",
       "   Tree(Lemma('look.v.02.look'), ['looking']),\n",
       "   Tree(Lemma('very.r.01.very'), ['very']),\n",
       "   Tree(Lemma('long.a.02.long'), ['long']),\n",
       "   Tree(Lemma('now.r.01.now'), ['now']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('satirical.s.01.satiric'), ['satiric']),\n",
       "   ['.']],\n",
       "  [['As'],\n",
       "   ['she'],\n",
       "   Tree(Lemma('reach.v.01.reach'), ['reached']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('kitchen.n.01.kitchen'), ['kitchen']),\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('solution.n.02.answer'), ['answer']),\n",
       "   Tree(Lemma('show.v.01.present'), ['presented']),\n",
       "   ['itself'],\n",
       "   [';'],\n",
       "   ['if'],\n",
       "   ['she'],\n",
       "   Tree(Lemma('tell.v.02.tell'), ['told']),\n",
       "   ['anyone'],\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('opium.n.01.opium'), ['opium']),\n",
       "   ['it'],\n",
       "   ['must'],\n",
       "   Tree(Lemma('be.v.02.be'), ['be']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Lucien'])]),\n",
       "   [','],\n",
       "   ['her'],\n",
       "   Tree(Lemma('husband.n.01.husband'), ['husband']),\n",
       "   ['.']],\n",
       "  [['She'],\n",
       "   Tree(Lemma('hesitate.v.02.pause'), ['paused']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('kitchen.n.01.kitchen'), ['kitchen']),\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   Tree(Lemma('rest.v.02.catch_one's_breath'), ['caught']),\n",
       "   ['her'],\n",
       "   ['breath'],\n",
       "   [','],\n",
       "   Tree(Lemma('state.v.01.tell'), ['told']),\n",
       "   ['herself'],\n",
       "   Tree(Lemma('firm.r.01.firmly'), ['firmly']),\n",
       "   ['that'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('opium.n.01.opium'), ['opium']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('merely.r.01.only'), ['only']),\n",
       "   ['an'],\n",
       "   Tree(Lemma('attempt.n.01.attempt'), ['attempt']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('frighten.v.01.frighten'), ['frighten']),\n",
       "   ['her'],\n",
       "   ['and'],\n",
       "   Tree(Lemma('enter.v.01.go_into'), ['went', 'into']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('kitchen.n.01.kitchen'), ['kitchen']),\n",
       "   [','],\n",
       "   ['where'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Glendora'])]),\n",
       "   ['was'],\n",
       "   Tree(Lemma('eye.v.01.eye'), ['eyeing']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('chicken.n.01.chicken'), ['chickens']),\n",
       "   Tree(Lemma('dismally.r.01.dismally'), ['dismally']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Maude'])]),\n",
       "   ['was'],\n",
       "   Tree(Lemma('clean.v.01.clean'), ['cleaning']),\n",
       "   Tree(Lemma('lamp_chimney.n.01.lamp_chimney'), ['lamp', 'chimneys']),\n",
       "   ['.']],\n",
       "  [['What'],\n",
       "   Tree(Lemma('be.v.02.be'), ['was']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('old.a.02.old'), ['old']),\n",
       "   Tree(Lemma('sign.n.02.sign'), ['sign']),\n",
       "   [','],\n",
       "   Tree('supposed.s.00', ['supposed']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   Tree('painted.s.00', ['painted']),\n",
       "   ['over'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   Tree(Lemma('somewhere.r.01.somewhere'), ['somewhere']),\n",
       "   [','],\n",
       "   Tree(Lemma('abandon.v.04.abandon'), ['Abandon']),\n",
       "   Tree(Lemma('hope.n.02.hope'), ['hope']),\n",
       "   [','],\n",
       "   ['all'],\n",
       "   ['ye'],\n",
       "   ['who'],\n",
       "   Tree(Lemma('enter.v.01.enter'), ['enter']),\n",
       "   Tree(Lemma('here.r.03.here'), ['here']),\n",
       "   ['?']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Pamela', 'North'])]),\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   [','],\n",
       "   ['``'],\n",
       "   ['Hi'],\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   ['to'],\n",
       "   ['her'],\n",
       "   Tree(Lemma('cat.n.01.cat'), ['cats']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('add.v.02.add'), ['added']),\n",
       "   ['that'],\n",
       "   Tree('proper.s.02', ['proper']),\n",
       "   Tree(Lemma('cat.n.01.cat'), ['cats']),\n",
       "   Tree(Lemma('meet.v.09.meet'), ['met']),\n",
       "   ['their'],\n",
       "   Tree('human.n.00', ['humans']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   ['would'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   Tree(Lemma('all_right.s.01.all_right'), ['all', 'right']),\n",
       "   ['with'],\n",
       "   ['him'],\n",
       "   [','],\n",
       "   ['he'],\n",
       "   Tree(Lemma('decide.v.01.decide'), ['decided']),\n",
       "   [','],\n",
       "   ['if'],\n",
       "   ['his'],\n",
       "   Tree('investigation.n.2;1', ['investigation']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('fraud.n.01.fraud'), ['fraud']),\n",
       "   [','],\n",
       "   ['with'],\n",
       "   ['its'],\n",
       "   Tree(Lemma('probable.a.01.probable'), ['probable']),\n",
       "   Tree(Lemma('by-product.n.01.by-product'), ['by-product']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('murder.n.01.murder'), ['murder']),\n",
       "   [','],\n",
       "   Tree(Lemma('lead.v.01.lead'), ['led']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Garth'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   ['and'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Hogan'])]),\n",
       "   Tree(Lemma('wait.v.01.wait'), ['waited']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   [','],\n",
       "   ['one'],\n",
       "   ['to'],\n",
       "   ['either'],\n",
       "   Tree(Lemma('side.n.01.side'), ['side']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('resignedly.r.01.resignedly'), ['Resignedly']),\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Macklin'])]),\n",
       "   Tree(Lemma('turn.v.01.turn'), ['turned']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('back.a.01.back'), ['back']),\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('vastly.r.01.vastly'), ['Vastly']),\n",
       "   Tree(Lemma('alleviated.s.01.relieved'), ['relieved']),\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Summers'])]),\n",
       "   Tree(Lemma('nod.v.01.nod'), ['nodded']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('depart.v.03.start'), ['started']),\n",
       "   ['toward'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Jess'])]),\n",
       "   Tree(Lemma('stumble.v.01.stumble'), ['stumbled']),\n",
       "   ['through'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('climb.v.01.climb'), ['Climbing']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('stairs.n.01.steps'), ['steps']),\n",
       "   Tree(Lemma('steadily.r.01.steadily'), ['steadily']),\n",
       "   [','],\n",
       "   ['they'],\n",
       "   Tree(Lemma('reach.v.01.reach'), ['reached']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('peak.n.04.top'), ['top']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('head.v.01.head'), ['headed']),\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['I'],\n",
       "   Tree(Lemma('spin.v.01.spin'), ['spun']),\n",
       "   Tree(Lemma('about.r.06.about'), ['about']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('clatter.v.01.clatter'), ['clattered']),\n",
       "   ['through'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('living_room.n.01.front_room'), ['front', 'room']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['.']],\n",
       "  [['There'],\n",
       "   Tree(Lemma('be.v.05.be'), ['was']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('pat.n.01.tap'), ['tap']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Oliver'])]),\n",
       "   Tree(Lemma('enter.v.01.enter'), ['entered']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('word.n.02.word'), ['word']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Heiser'])]),\n",
       "   Tree(Lemma('wish.v.02.wish'), ['wished']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('meet.v.01.see'), ['see']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('captain.n.02.captain'), ['Captain']),\n",
       "   ['.']]],\n",
       " [4, 101, 135])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_word_data('door', 'n')\n",
    "sel.get_selected_sense_sents(sel.get_senses_for_curr_word())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FigGrd: door.n: 1- \"on the door\", doorway.n.1- \"through the door\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "01      125\n",
       "02       12\n",
       "03        6\n",
       "04        4\n",
       "05        1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('school', 'n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BldPers- school.n 1. institution, 2. building not sure if this is what we want?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07</th>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "00       31\n",
       "02       54\n",
       "03       27\n",
       "04        1\n",
       "07      278"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('begin', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07</th>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>08</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>09</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8;3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "02       35\n",
       "03       59\n",
       "06       11\n",
       "07      153\n",
       "08        6\n",
       "09        4\n",
       "10        2\n",
       "11        1\n",
       "8;3       1"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('start', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "01       52\n",
       "02       12\n",
       "04        3"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('finish', 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CmpCoer: begin.v, start.v, finish.v unsure about these WN senses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5;1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "00        4\n",
       "01      117\n",
       "03       21\n",
       "04        4\n",
       "05        1\n",
       "07        1\n",
       "5;1       1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('face', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "01       33\n",
       "02       23\n",
       "03       10"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('heart', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senses for word heart.n\n",
      "Number of sentences for sense Synset('heart.n.02') 23\n",
      "Number of sentences for sense Synset('heart.n.03') 8\n",
      "Number of sentences for sense Synset('kernel.n.03') 2\n",
      "Number of sentences for sense Synset('heart.n.01') 29\n",
      "Number of sentences for sense Synset('center.n.01') 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['The heart weighed 510 gm. , and at the outflow tracts the left and right ventricles measured 19 and 3 mm. , respectively .',\n",
       "  'Microscopically , sections from the posterior base of the left ventricle of the heart showed several large areas of replacement of muscle by fibrous tissue .',\n",
       "  'Shot near the heart , he turned to one side and plunged for a door to another room several feet away , three bullets following him .',\n",
       "  'It was nothing , though his heart was thumping wildly .',\n",
       "  'He stood very still , his heart thumping wildly .',\n",
       "  'My heart almost stopped beating .',\n",
       "  'Andy felt his heart thud heavily with relief .',\n",
       "  'Before midnight he speeded his heart , resumed normal breathing , ran down his check list , uncurled and sat up .',\n",
       "  \"The original electrocardiograph primarily indicates irregularities in the heartbeat , but today 's techniques allow exact measurements of the flow of blood through the aorta , dimensioning of the heart and its chambers , and a much more detailed study of each heartbeat .\",\n",
       "  'For many of these measurements the chest must be opened , but the blood vessels and the heart itself remain undisturbed .',\n",
       "  'One simple method of measuring the expansion of the heart is to tie a thin rubber tube , filled with mercury , around the heart and record the change in resistance as the tube is stretched .',\n",
       "  'One simple method of measuring the expansion of the heart is to tie a thin rubber tube , filled with mercury , around the heart and record the change in resistance as the tube is stretched .',\n",
       "  'Sonar can be used to measure the thickness of the heart by placing small crystal transducers at opposite sides of the heart or blood vessel and exciting one with some pulsed ultrasonic energy .',\n",
       "  'Sonar can be used to measure the thickness of the heart by placing small crystal transducers at opposite sides of the heart or blood vessel and exciting one with some pulsed ultrasonic energy .',\n",
       "  'In addition to the heart and aorta , successful measurements of liver and spleen have also been made by this technique .',\n",
       "  'A still more sophisticated system has been devised for determining the effective power of the heart itself .',\n",
       "  'It uses both an ultrasonic dimensioning arrangement of the heart and a catheter carrying a thermistor inserted into the bloodstream .',\n",
       "  \"It is also possible to utilize a pressure transducer , mounted at the end of a catheter which is inserted into the heart 's left ventricle , to indicate the blood pressure in the heart itself .\",\n",
       "  \"It is also possible to utilize a pressure transducer , mounted at the end of a catheter which is inserted into the heart 's left ventricle , to indicate the blood pressure in the heart itself .\",\n",
       "  'From this doctors can read heart rate , change in diameter , pressure , and effective heart power .',\n",
       "  'Sadie , like Beth March , suffered ill health - got rheumatic fever and had to be careful of her heart - but that never dampened her spirits .',\n",
       "  \"No signs of these , no gross hemorrhage of lungs , heart , brain or stomach '' .\",\n",
       "  'And then there was a numbing blow to the heart , and another gut flattening blow to the stomach .',\n",
       "  'Lublin was their heart .',\n",
       "  'Her optimism gave me heart .',\n",
       "  '`` They require , for existence , a brave spirit and a high heart , and where do you find these ?',\n",
       "  \"You have n't got the heart for baseball '' .\",\n",
       "  \"But what you have n't got is the heart to back up that talent with .\",\n",
       "  'The heart , Phil .',\n",
       "  \"You just have n't got the heart for pro-ball , and that 's it '' .\",\n",
       "  \"That 's what I mean by no heart for the game .\",\n",
       "  'Certainly not in Orchestra hall where he has played countless recitals , and where Thursday night he celebrated his 20th season with the Chicago Symphony orchestra , playing the Brahms Concerto with his own slashing , demon-ridden cadenza melting into the high , pale , pure and lovely song with which a violinist unlocks the heart of the music , or forever finds it closed .',\n",
       "  \"The material of the Porter film is simplicity itself ; much of it has continued to be used over the years and the heart of it - good guys and bad guys in the old West - pretty well dominated television toward the end of the 1950's .\",\n",
       "  \"Of the two cherished achievements the elderly Spahn 's hitless pitching probably reached the most hearts .\",\n",
       "  'Open your heart to Him and pray , Stephen , pray !',\n",
       "  'Back in Bavaria he had seen that gesture , and at that sight his heart had always died within him .',\n",
       "  'His heart suddenly opened to joy .',\n",
       "  'He thought : Only in my heart can I make the world hang together .',\n",
       "  'In his heart he had no desire to go to Palestine .',\n",
       "  \"Day by day , week by week , month by month , the betrayal gnawed at Andrei 's heart .\",\n",
       "  'To confess with a canvas chair as a prie-dieu , gouging at his heart until a rough and stupid hand bade him rise and go ?',\n",
       "  '`` The world is full of blokes who put their hearts into making the tragic scene .',\n",
       "  \"In our present era of Science and Angst , the heart has been downgraded , to use one of our popular retrogressive verbs '' .\",\n",
       "  '`` Last year your Tennessee Williams told our Dilys Powell , in a television program , that it is the task of the playwright to throw light into the dark corners of the human heart .',\n",
       "  'Like almost everybody else , he confused the heart , both as organ and as symbol , with the disturbed psyche , the deranged glands , and the jumpy central nervous system .',\n",
       "  \"I'm not pleading for the heart that leaps up when it beholds a rainbow in the sky , or for the heart that with rapture fills and dances with the daffodils .\",\n",
       "  \"I'm not pleading for the heart that leaps up when it beholds a rainbow in the sky , or for the heart that with rapture fills and dances with the daffodils .\",\n",
       "  \"The sentimental pure heart of Galahad is gone with the knightly years , but I still believe in the heart of the George Meredith character that was not made of the stuff that breaks '' .\",\n",
       "  \"The sentimental pure heart of Galahad is gone with the knightly years , but I still believe in the heart of the George Meredith character that was not made of the stuff that breaks '' .\",\n",
       "  \"`` We no longer have Tom Moore 's and Longfellow 's ' heart for any fate ' , either '' , I said .\",\n",
       "  \"`` The heart '' , I said finally , `` is now either in the throat or the mouth or the stomach or the shoes .\",\n",
       "  'In a similar vein , but writing from the opposite side , Thomas Taylor , a private in the 6 th Alabama Volunteers , in a letter to his wife , stated : `` You know that my heart is with you but I never could have been satisfied to have staid at home when my country is invaded by a thievin foe By a set of cowardly Skunks whose Motto is Booty .',\n",
       "  \"I looked unceasingly With my cold mind and with my burning heart '' .\",\n",
       "  \"He tells of his `` Jewish heart '' - not a Shylockian heart ; but a Jewish heart .\",\n",
       "  \"He tells of his `` Jewish heart '' - not a Shylockian heart ; but a Jewish heart .\",\n",
       "  \"He tells of his `` Jewish heart '' - not a Shylockian heart ; but a Jewish heart .\",\n",
       "  \"Would we gain by keeping alive his memory and besmirching today 's Roman Catholics by saying he had a Catholic heart ?\",\n",
       "  \"With all his heart he had loved the Navy and now he must act in accordance with the Navy 's implacable laws .\",\n",
       "  \"One did one 's best and if fortune frowned , an eighteen year old boy with murder in his heart sailed aboard one 's ship .\",\n",
       "  \"He can even be a mild voiced little town guy with big town ideas and level gray eyes and a heart even Houdini could n't figure out , how it is unlocked .\",\n",
       "  'And in a way the promise works out true , for whether he wants you or not , you go with him in your heart .',\n",
       "  'Homes and factories and schools and a big wide federal highway , instead of peaceful corn to rest your eyes on while you tried to rest your heart , while you tried not to look at the balloon and the bandstand and the uniforms and the flash of the instruments .',\n",
       "  \"On the contrary , even in the heart of `` the Bible belt '' itself , as can be attested by any one who is called to work there , the industrial and technological revolutions have long been under way , together with the corresponding changes in man 's picture of himself and his world .\",\n",
       "  'Raymond Vernon reports that residents of East St. Louis have been driving across the Mississippi , through the heart of downtown St. Louis and out to the western suburbs for major shopping , simply because parking is easier at the big branches than it is in the heart of town .',\n",
       "  'Raymond Vernon reports that residents of East St. Louis have been driving across the Mississippi , through the heart of downtown St. Louis and out to the western suburbs for major shopping , simply because parking is easier at the big branches than it is in the heart of town .',\n",
       "  \"They had let this black hole of death in Warsaw 's heart exist without a cry of protest .\"],\n",
       " [[['The'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   Tree(Lemma('weigh.v.01.weigh'), ['weighed']),\n",
       "   ['510'],\n",
       "   Tree(Lemma('gram.n.01.gm'), ['gm.']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('escape.n.07.outflow'), ['outflow']),\n",
       "   Tree(Lemma('tract.n.02.tract'), ['tracts']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('left_ventricle.n.01.left_ventricle'), ['left']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('right_ventricle.n.01.right_ventricle'), ['right', 'ventricles']),\n",
       "   Tree(Lemma('measure.v.03.measure'), ['measured']),\n",
       "   Tree(Lemma('nineteen.s.01.19'), ['19']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('three.s.01.3'), ['3']),\n",
       "   Tree(Lemma('millimeter.n.01.mm'), ['mm.']),\n",
       "   [','],\n",
       "   Tree(Lemma('respectively.r.01.respectively'), ['respectively']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('microscopically.r.01.microscopically'), ['Microscopically']),\n",
       "   [','],\n",
       "   Tree(Lemma('section.n.02.section'), ['sections']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('posterior.a.01.posterior'), ['posterior']),\n",
       "   Tree(Lemma('base.n.05.base'), ['base']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('left_ventricle.n.01.left_ventricle'), ['left', 'ventricle']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   Tree(Lemma('show.v.01.show'), ['showed']),\n",
       "   Tree('several.s.01', ['several']),\n",
       "   Tree(Lemma('large.a.01.large'), ['large']),\n",
       "   Tree(Lemma('area.n.03.area'), ['areas']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('substitution.n.01.replacement'), ['replacement']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('muscle.n.01.muscle'), ['muscle']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('fibrous_tissue.n.01.fibrous_tissue'), ['fibrous', 'tissue']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('shoot.v.01.shoot'), ['Shot']),\n",
       "   ['near'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   [','],\n",
       "   ['he'],\n",
       "   Tree(Lemma('turn.v.01.turn'), ['turned']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('one.s.01.one'), ['one']),\n",
       "   Tree(Lemma('side.n.03.side'), ['side']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('dive.v.01.plunge'), ['plunged']),\n",
       "   ['for'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('doorway.n.01.door'), ['door']),\n",
       "   ['to'],\n",
       "   ['another'],\n",
       "   Tree(Lemma('room.n.01.room'), ['room']),\n",
       "   Tree('several.s.01', ['several']),\n",
       "   Tree(Lemma('foot.n.02.foot'), ['feet']),\n",
       "   Tree(Lemma('away.r.02.away'), ['away']),\n",
       "   [','],\n",
       "   Tree(Lemma('three.s.01.three'), ['three']),\n",
       "   Tree(Lemma('bullet.n.01.bullet'), ['bullets']),\n",
       "   Tree(Lemma('follow.v.01.follow'), ['following']),\n",
       "   ['him'],\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('nothing.n.01.nothing'), ['nothing']),\n",
       "   [','],\n",
       "   ['though'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('beat.v.04.thump'), ['thumping']),\n",
       "   Tree(Lemma('wildly.r.01.wildly'), ['wildly']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('stand.v.01.stand'), ['stood']),\n",
       "   Tree(Lemma('very.r.01.very'), ['very']),\n",
       "   Tree(Lemma('inactive.s.10.still'), ['still']),\n",
       "   [','],\n",
       "   ['his'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   Tree(Lemma('beat.v.04.thump'), ['thumping']),\n",
       "   Tree(Lemma('wildly.r.01.wildly'), ['wildly']),\n",
       "   ['.']],\n",
       "  [['My'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   Tree(Lemma('about.r.07.almost'), ['almost']),\n",
       "   Tree(Lemma('stop.v.01.stop'), ['stopped']),\n",
       "   Tree(Lemma('beat.v.04.beat'), ['beating']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Andy'])]),\n",
       "   Tree(Lemma('feel.v.03.feel'), ['felt']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   Tree(Lemma('thud.v.01.thud'), ['thud']),\n",
       "   Tree(Lemma('heavily.r.01.heavily'), ['heavily']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('relief.n.01.relief'), ['relief']),\n",
       "   ['.']],\n",
       "  [['Before'],\n",
       "   Tree(Lemma('midnight.n.01.midnight'), ['midnight']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('accelerate.v.01.speed'), ['speeded']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   [','],\n",
       "   Tree(Lemma('resume.v.01.resume'), ['resumed']),\n",
       "   Tree(Lemma('normal.a.01.normal'), ['normal']),\n",
       "   Tree(Lemma('breathing.n.01.breathing'), ['breathing']),\n",
       "   [','],\n",
       "   Tree(Lemma('scan.v.02.run_down'), ['ran', 'down']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('checklist.n.01.checklist'), ['check', 'list']),\n",
       "   [','],\n",
       "   Tree(Lemma('uncurl.v.01.uncurl'), ['uncurled']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('stay_up.v.01.sit_up'), ['sat', 'up']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('original.s.01.original'), ['original']),\n",
       "   Tree(Lemma('cardiograph.n.01.electrocardiograph'), ['electrocardiograph']),\n",
       "   Tree(Lemma('chiefly.r.01.primarily'), ['primarily']),\n",
       "   Tree(Lemma('bespeak.v.01.indicate'), ['indicates']),\n",
       "   Tree(Lemma('irregularity.n.02.irregularity'), ['irregularities']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('pulse.n.02.heartbeat'), ['heartbeat']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   Tree(Lemma('today.n.01.today'), ['today']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('technique.n.01.technique'), ['techniques']),\n",
       "   Tree(Lemma('leave.v.06.allow'), ['allow']),\n",
       "   Tree(Lemma('accurate.s.02.exact'), ['exact']),\n",
       "   Tree(Lemma('measurement.n.01.measurement'), ['measurements']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('flow.n.02.flow'), ['flow']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('blood.n.01.blood'), ['blood']),\n",
       "   ['through'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('aorta.n.01.aorta'), ['aorta']),\n",
       "   [','],\n",
       "   Tree(Lemma('dimensioning.s.01.dimensioning'), ['dimensioning']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['and'],\n",
       "   ['its'],\n",
       "   Tree(Lemma('chamber.n.02.chamber'), ['chambers']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('much.r.01.much'), ['much']),\n",
       "   Tree(Lemma('more.r.01.more'), ['more']),\n",
       "   Tree(Lemma('detailed.s.01.detailed'), ['detailed']),\n",
       "   Tree(Lemma('survey.n.01.study'), ['study']),\n",
       "   ['of'],\n",
       "   ['each'],\n",
       "   Tree(Lemma('pulse.n.02.heartbeat'), ['heartbeat']),\n",
       "   ['.']],\n",
       "  [['For'],\n",
       "   ['many', 'of'],\n",
       "   ['these'],\n",
       "   Tree(Lemma('measurement.n.01.measurement'), ['measurements']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('thorax.n.02.chest'), ['chest']),\n",
       "   ['must'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('blood_vessel.n.01.blood_vessel'), ['blood', 'vessels']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['itself'],\n",
       "   Tree(Lemma('stay.v.01.remain'), ['remain']),\n",
       "   Tree('undisturbed.a.00', ['undisturbed']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('one.s.01.one'), ['One']),\n",
       "   Tree(Lemma('simple.a.01.simple'), ['simple']),\n",
       "   Tree(Lemma('method.n.01.method'), ['method']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('measure.v.01.measure'), ['measuring']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('expansion.n.01.expansion'), ['expansion']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('tie.v.05.tie'), ['tie']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('thin.a.01.thin'), ['thin']),\n",
       "   Tree(Lemma('rubber.n.01.rubber'), ['rubber']),\n",
       "   Tree(Lemma('tube.n.01.tube'), ['tube']),\n",
       "   [','],\n",
       "   Tree(Lemma('occupy.v.03.fill'), ['filled']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('mercury.n.01.mercury'), ['mercury']),\n",
       "   [','],\n",
       "   ['around'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('record.v.01.record'), ['record']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('change.n.02.change'), ['change']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('resistance.n.02.resistance'), ['resistance']),\n",
       "   ['as'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('tube.n.01.tube'), ['tube']),\n",
       "   ['is'],\n",
       "   Tree(Lemma('stretch.v.07.stretch'), ['stretched']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('one.s.01.one'), ['One']),\n",
       "   Tree(Lemma('simple.a.01.simple'), ['simple']),\n",
       "   Tree(Lemma('method.n.01.method'), ['method']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('measure.v.01.measure'), ['measuring']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('expansion.n.01.expansion'), ['expansion']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('tie.v.05.tie'), ['tie']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('thin.a.01.thin'), ['thin']),\n",
       "   Tree(Lemma('rubber.n.01.rubber'), ['rubber']),\n",
       "   Tree(Lemma('tube.n.01.tube'), ['tube']),\n",
       "   [','],\n",
       "   Tree(Lemma('occupy.v.03.fill'), ['filled']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('mercury.n.01.mercury'), ['mercury']),\n",
       "   [','],\n",
       "   ['around'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('record.v.01.record'), ['record']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('change.n.02.change'), ['change']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('resistance.n.02.resistance'), ['resistance']),\n",
       "   ['as'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('tube.n.01.tube'), ['tube']),\n",
       "   ['is'],\n",
       "   Tree(Lemma('stretch.v.07.stretch'), ['stretched']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('sonar.n.01.sonar'), ['Sonar']),\n",
       "   ['can'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('use.v.01.use'), ['used']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('measure.v.01.measure'), ['measure']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('thickness.n.01.thickness'), ['thickness']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('put.v.01.place'), ['placing']),\n",
       "   Tree(Lemma('small.a.01.small'), ['small']),\n",
       "   Tree(Lemma('crystal.n.02.crystal'), ['crystal']),\n",
       "   Tree(Lemma('transducer.n.01.transducer'), ['transducers']),\n",
       "   ['at'],\n",
       "   Tree(Lemma('opposite.s.01.opposite'), ['opposite']),\n",
       "   Tree(Lemma('side.n.01.side'), ['sides']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('blood_vessel.n.01.blood_vessel'), ['blood', 'vessel']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('stimulate.v.01.excite'), ['exciting']),\n",
       "   ['one'],\n",
       "   ['with'],\n",
       "   ['some'],\n",
       "   Tree('pulsed.s.00', ['pulsed']),\n",
       "   Tree(Lemma('supersonic.s.02.ultrasonic'), ['ultrasonic']),\n",
       "   Tree(Lemma('energy.n.01.energy'), ['energy']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('sonar.n.01.sonar'), ['Sonar']),\n",
       "   ['can'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('use.v.01.use'), ['used']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('measure.v.01.measure'), ['measure']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('thickness.n.01.thickness'), ['thickness']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('put.v.01.place'), ['placing']),\n",
       "   Tree(Lemma('small.a.01.small'), ['small']),\n",
       "   Tree(Lemma('crystal.n.02.crystal'), ['crystal']),\n",
       "   Tree(Lemma('transducer.n.01.transducer'), ['transducers']),\n",
       "   ['at'],\n",
       "   Tree(Lemma('opposite.s.01.opposite'), ['opposite']),\n",
       "   Tree(Lemma('side.n.01.side'), ['sides']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('blood_vessel.n.01.blood_vessel'), ['blood', 'vessel']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('stimulate.v.01.excite'), ['exciting']),\n",
       "   ['one'],\n",
       "   ['with'],\n",
       "   ['some'],\n",
       "   Tree('pulsed.s.00', ['pulsed']),\n",
       "   Tree(Lemma('supersonic.s.02.ultrasonic'), ['ultrasonic']),\n",
       "   Tree(Lemma('energy.n.01.energy'), ['energy']),\n",
       "   ['.']],\n",
       "  [Tree('in_addition.r.00', ['In', 'addition']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('aorta.n.01.aorta'), ['aorta']),\n",
       "   [','],\n",
       "   Tree(Lemma('successful.a.01.successful'), ['successful']),\n",
       "   Tree(Lemma('measurement.n.01.measurement'), ['measurements']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('liver.n.01.liver'), ['liver']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('spleen.n.01.spleen'), ['spleen']),\n",
       "   ['have'],\n",
       "   Tree(Lemma('besides.r.02.also'), ['also']),\n",
       "   ['been'],\n",
       "   Tree(Lemma('make.v.01.make'), ['made']),\n",
       "   ['by'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('technique.n.01.technique'), ['technique']),\n",
       "   ['.']],\n",
       "  [['A'],\n",
       "   Tree(Lemma('even.r.03.still'), ['still']),\n",
       "   Tree(Lemma('more.r.01.more'), ['more']),\n",
       "   Tree(Lemma('advanced.s.05.sophisticated'), ['sophisticated']),\n",
       "   Tree(Lemma('system.n.01.system'), ['system']),\n",
       "   ['has'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('invent.v.01.devise'), ['devised']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('determine.v.01.determine'), ['determining']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('effective.a.01.effective'), ['effective']),\n",
       "   Tree(Lemma('might.n.01.power'), ['power']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['itself'],\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   Tree(Lemma('use.v.01.use'), ['uses']),\n",
       "   ['both'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('supersonic.s.02.ultrasonic'), ['ultrasonic']),\n",
       "   Tree(Lemma('dimensioning.s.01.dimensioning'), ['dimensioning']),\n",
       "   Tree(Lemma('arrangement.n.02.arrangement'), ['arrangement']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['and'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('catheter.n.01.catheter'), ['catheter']),\n",
       "   Tree(Lemma('hold.v.11.carry'), ['carrying']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('thermistor.n.01.thermistor'), ['thermistor']),\n",
       "   Tree(Lemma('insert.v.02.insert'), ['inserted']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bloodstream.n.01.bloodstream'), ['bloodstream']),\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('besides.r.02.also'), ['also']),\n",
       "   Tree(Lemma('possible.a.01.possible'), ['possible']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('use.v.01.utilize'), ['utilize']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('pressure.n.01.pressure'), ['pressure']),\n",
       "   Tree(Lemma('transducer.n.01.transducer'), ['transducer']),\n",
       "   [','],\n",
       "   Tree(Lemma('mounted.s.01.mounted'), ['mounted']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('end.n.01.end'), ['end']),\n",
       "   ['of'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('catheter.n.01.catheter'), ['catheter']),\n",
       "   ['which'],\n",
       "   ['is'],\n",
       "   Tree(Lemma('insert.v.02.insert'), ['inserted']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('left_ventricle.n.01.left_ventricle'), ['left', 'ventricle']),\n",
       "   [','],\n",
       "   ['to'],\n",
       "   Tree(Lemma('bespeak.v.01.indicate'), ['indicate']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('blood_pressure.n.01.blood_pressure'), ['blood', 'pressure']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['itself'],\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('besides.r.02.also'), ['also']),\n",
       "   Tree(Lemma('possible.a.01.possible'), ['possible']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('use.v.01.utilize'), ['utilize']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('pressure.n.01.pressure'), ['pressure']),\n",
       "   Tree(Lemma('transducer.n.01.transducer'), ['transducer']),\n",
       "   [','],\n",
       "   Tree(Lemma('mounted.s.01.mounted'), ['mounted']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('end.n.01.end'), ['end']),\n",
       "   ['of'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('catheter.n.01.catheter'), ['catheter']),\n",
       "   ['which'],\n",
       "   ['is'],\n",
       "   Tree(Lemma('insert.v.02.insert'), ['inserted']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('left_ventricle.n.01.left_ventricle'), ['left', 'ventricle']),\n",
       "   [','],\n",
       "   ['to'],\n",
       "   Tree(Lemma('bespeak.v.01.indicate'), ['indicate']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('blood_pressure.n.01.blood_pressure'), ['blood', 'pressure']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['itself'],\n",
       "   ['.']],\n",
       "  [['From'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('doctor.n.01.doctor'), ['doctors']),\n",
       "   ['can'],\n",
       "   Tree(Lemma('read.v.08.read'), ['read']),\n",
       "   Tree(Lemma('pulse.n.03.heart_rate'), ['heart', 'rate']),\n",
       "   [','],\n",
       "   Tree(Lemma('change.n.02.change'), ['change']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('diameter.n.01.diameter'), ['diameter']),\n",
       "   [','],\n",
       "   Tree(Lemma('pressure.n.01.pressure'), ['pressure']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('effective.a.01.effective'), ['effective']),\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   Tree(Lemma('might.n.01.power'), ['power']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Sadie'])]),\n",
       "   [','],\n",
       "   ['like'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Beth', 'March'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('suffer.v.02.suffer'), ['suffered']),\n",
       "   Tree(Lemma('ill_health.n.01.ill_health'), ['ill', 'health']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('contract.v.04.get'), ['got']),\n",
       "   Tree(Lemma('rheumatic_fever.n.01.rheumatic_fever'), ['rheumatic', 'fever']),\n",
       "   ['and'],\n",
       "   ['had'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   Tree(Lemma('careful.s.02.careful'), ['careful']),\n",
       "   ['of'],\n",
       "   ['her'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   ['-'],\n",
       "   ['but'],\n",
       "   ['that'],\n",
       "   Tree(Lemma('never.r.01.never'), ['never']),\n",
       "   Tree(Lemma('stifle.v.02.dampen'), ['dampened']),\n",
       "   ['her'],\n",
       "   Tree(Lemma('emotional_state.n.01.spirit'), ['spirits']),\n",
       "   ['.']],\n",
       "  [['No'],\n",
       "   Tree(Lemma('sign.n.06.sign'), ['signs']),\n",
       "   ['of'],\n",
       "   ['these'],\n",
       "   [','],\n",
       "   ['no'],\n",
       "   Tree('gross.s.00', ['gross']),\n",
       "   Tree(Lemma('bleeding.n.01.hemorrhage'), ['hemorrhage']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('lung.n.01.lung'), ['lungs']),\n",
       "   [','],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   [','],\n",
       "   Tree(Lemma('brain.n.01.brain'), ['brain']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('stomach.n.01.stomach'), ['stomach']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [Tree(Lemma('then.r.01.and_then'), ['And', 'then']),\n",
       "   ['there'],\n",
       "   ['was'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('numbing.s.01.numbing'), ['numbing']),\n",
       "   Tree(Lemma('blow.n.01.blow'), ['blow']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.02.heart'), ['heart']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['another'],\n",
       "   Tree(Lemma('intestine.n.01.gut'), ['gut']),\n",
       "   Tree(Lemma('flatten.v.01.flatten'), ['flattening']),\n",
       "   Tree(Lemma('blow.n.01.blow'), ['blow']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('stomach.n.01.stomach'), ['stomach']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('location.n.01.location'), [Tree('NE', ['Lublin'])]),\n",
       "   Tree(Lemma('constitute.v.01.be'), ['was']),\n",
       "   ['their'],\n",
       "   Tree(Lemma('heart.n.03.heart'), ['heart']),\n",
       "   ['.']],\n",
       "  [['Her'],\n",
       "   Tree(Lemma('optimism.n.01.optimism'), ['optimism']),\n",
       "   Tree(Lemma('give.v.01.give'), ['gave']),\n",
       "   ['me'],\n",
       "   Tree(Lemma('heart.n.03.heart'), ['heart']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   ['They'],\n",
       "   Tree(Lemma('necessitate.v.01.require'), ['require']),\n",
       "   [','],\n",
       "   ['for'],\n",
       "   Tree(Lemma('being.n.01.existence'), ['existence']),\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree(Lemma('brave.a.01.brave'), ['brave']),\n",
       "   Tree(Lemma('spirit.n.03.spirit'), ['spirit']),\n",
       "   ['and'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('high.s.05.high'), ['high']),\n",
       "   Tree(Lemma('heart.n.03.heart'), ['heart']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['where'],\n",
       "   ['do'],\n",
       "   ['you'],\n",
       "   Tree(Lemma('find.v.01.find'), ['find']),\n",
       "   ['these'],\n",
       "   ['?']],\n",
       "  [['You'],\n",
       "   Tree(Lemma('have.v.01.have_got'), ['have']),\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   ['got'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.03.heart'), ['heart']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('baseball.n.01.baseball'), ['baseball']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['But'],\n",
       "   ['what'],\n",
       "   ['you'],\n",
       "   Tree(Lemma('have.v.01.have_got'), ['have']),\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   ['got'],\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.03.heart'), ['heart']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('support.v.01.back_up'), ['back', 'up']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('endowment.n.01.talent'), ['talent']),\n",
       "   ['with'],\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('heart.n.03.heart'), ['heart']),\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Phil'])]),\n",
       "   ['.']],\n",
       "  [['You'],\n",
       "   Tree(Lemma('just.r.04.just'), ['just']),\n",
       "   Tree(Lemma('have.v.01.have_got'), ['have']),\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   ['got'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.03.heart'), ['heart']),\n",
       "   ['for'],\n",
       "   ['pro-ball'],\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['that'],\n",
       "   [\"'s\"],\n",
       "   ['it'],\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['That'],\n",
       "   [\"'s\"],\n",
       "   ['what'],\n",
       "   ['I'],\n",
       "   Tree(Lemma('mean.v.01.mean'), ['mean']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('no.a.01.no'), ['no']),\n",
       "   Tree(Lemma('heart.n.03.heart'), ['heart']),\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('game.n.01.game'), ['game']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('surely.r.01.certainly'), ['Certainly']),\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Orchestra', 'hall'])]),\n",
       "   ['where'],\n",
       "   ['he'],\n",
       "   ['has'],\n",
       "   Tree(Lemma('play.v.03.play'), ['played']),\n",
       "   Tree(Lemma('countless.s.01.countless'), ['countless']),\n",
       "   Tree(Lemma('recital.n.02.recital'), ['recitals']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['where'],\n",
       "   Tree(Lemma('thursday.n.01.Thursday'), ['Thursday']),\n",
       "   Tree(Lemma('night.n.01.night'), ['night']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('lionize.v.01.celebrate'), ['celebrated']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('twentieth.s.01.20th'), ['20th']),\n",
       "   Tree(Lemma('season.n.01.season'), ['season']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Chicago', 'Symphony', 'orchestra'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('play.v.06.play'), ['playing']),\n",
       "   ['the'],\n",
       "   Tree('NE', ['Brahms', 'Concerto']),\n",
       "   ['with'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('own.s.01.own'), ['own']),\n",
       "   Tree(Lemma('slashing.s.01.slashing'), ['slashing']),\n",
       "   [','],\n",
       "   Tree(Lemma('demon-ridden.s.01.demon-ridden'), ['demon-ridden']),\n",
       "   Tree(Lemma('cadenza.n.01.cadenza'), ['cadenza']),\n",
       "   Tree(Lemma('mellow.v.02.melt'), ['melting']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('high.a.04.high'), ['high']),\n",
       "   [','],\n",
       "   Tree(Lemma('pale.s.02.pale'), ['pale']),\n",
       "   [','],\n",
       "   Tree(Lemma('pure.s.04.pure'), ['pure']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('lovely.s.01.lovely'), ['lovely']),\n",
       "   Tree(Lemma('song.n.01.song'), ['song']),\n",
       "   ['with'],\n",
       "   ['which'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('violinist.n.01.violinist'), ['violinist']),\n",
       "   Tree(Lemma('unlock.v.03.unlock'), ['unlocks']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('kernel.n.03.heart'), ['heart']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('music.n.01.music'), ['music']),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   Tree(Lemma('forever.r.02.forever'), ['forever']),\n",
       "   Tree(Lemma('find.v.05.find'), ['finds']),\n",
       "   ['it'],\n",
       "   Tree(Lemma('closed.a.01.closed'), ['closed']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('material.n.02.material'), ['material']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Porter'])]),\n",
       "   Tree(Lemma('movie.n.01.film'), ['film']),\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   Tree(Lemma('simplicity.n.01.simplicity'), ['simplicity']),\n",
       "   ['itself'],\n",
       "   [';'],\n",
       "   Tree(Lemma('much.a.01.much'), ['much']),\n",
       "   ['of', 'it'],\n",
       "   ['has'],\n",
       "   Tree(Lemma('continue.v.01.continue'), ['continued']),\n",
       "   ['to'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('use.v.01.use'), ['used']),\n",
       "   ['over'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('year.n.01.year'), ['years']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('kernel.n.03.heart'), ['heart']),\n",
       "   ['of', 'it'],\n",
       "   ['-'],\n",
       "   Tree(Lemma('good_guy.n.01.good_guy'), ['good', 'guys']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('bad_guy.n.01.bad_guy'), ['bad', 'guys']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('old.a.02.old'), ['old']),\n",
       "   Tree(Lemma('west.n.03.West'), ['West']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('reasonably.r.01.pretty'), ['pretty']),\n",
       "   Tree(Lemma('well.r.07.well'), ['well']),\n",
       "   Tree(Lemma('predominate.v.01.dominate'), ['dominated']),\n",
       "   Tree(Lemma('television.n.01.television'), ['television']),\n",
       "   ['toward'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('end.n.02.end'), ['end']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   [\"1950's\"],\n",
       "   ['.']],\n",
       "  [['Of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('two.s.01.two'), ['two']),\n",
       "   Tree(Lemma('cherished.s.01.cherished'), ['cherished']),\n",
       "   Tree(Lemma('accomplishment.n.01.achievement'), ['achievements']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('aged.s.01.elderly'), ['elderly']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Spahn'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('hitless.s.01.hitless'), ['hitless']),\n",
       "   Tree(Lemma('pitching.n.01.pitching'), ['pitching']),\n",
       "   Tree(Lemma('probably.r.01.probably'), ['probably']),\n",
       "   Tree(Lemma('reach.v.04.reach'), ['reached']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('most.a.01.most'), ['most']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['hearts']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('open.v.03.open'), ['Open']),\n",
       "   ['your'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['to'],\n",
       "   ['Him'],\n",
       "   ['and'],\n",
       "   Tree(Lemma('pray.v.01.pray'), ['pray']),\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Stephen'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('pray.v.01.pray'), ['pray']),\n",
       "   ['!']],\n",
       "  [Tree(Lemma('back.r.01.back'), ['Back']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('bavaria.n.01.Bavaria'), ['Bavaria']),\n",
       "   ['he'],\n",
       "   ['had'],\n",
       "   Tree(Lemma('see.v.01.see'), ['seen']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('gesture.n.01.gesture'), ['gesture']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['at'],\n",
       "   ['that'],\n",
       "   Tree(Lemma('sight.n.03.sight'), ['sight']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['had'],\n",
       "   Tree(Lemma('always.r.01.always'), ['always']),\n",
       "   Tree(Lemma('die.v.01.die'), ['died']),\n",
       "   ['within'],\n",
       "   ['him'],\n",
       "   ['.']],\n",
       "  [['His'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   Tree(Lemma('abruptly.r.01.suddenly'), ['suddenly']),\n",
       "   Tree(Lemma('open.v.01.open'), ['opened']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('joy.n.01.joy'), ['joy']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('think.v.03.think'), ['thought']),\n",
       "   [':'],\n",
       "   Tree(Lemma('entirely.r.02.only'), ['Only']),\n",
       "   ['in'],\n",
       "   ['my'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['can'],\n",
       "   ['I'],\n",
       "   Tree(Lemma('induce.v.02.make'), ['make']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('universe.n.01.world'), ['world']),\n",
       "   Tree(Lemma('hang_together.v.01.hang_together'), ['hang', 'together']),\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('experience.v.03.have'), ['had']),\n",
       "   ['no'],\n",
       "   Tree(Lemma('desire.n.01.desire'), ['desire']),\n",
       "   ['to'],\n",
       "   Tree('go_to.v.00', ['go', 'to']),\n",
       "   Tree(Lemma('palestine.n.01.Palestine'), ['Palestine']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('day_by_day.r.01.day_by_day'), ['Day', 'by', 'day']),\n",
       "   [','],\n",
       "   Tree(Lemma('week_by_week.r.01.week_by_week'), ['week', 'by', 'week']),\n",
       "   [','],\n",
       "   Tree(Lemma('month_by_month.r.01.month_by_month'), ['month', 'by', 'month']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('treachery.n.02.betrayal'), ['betrayal']),\n",
       "   Tree(Lemma('erode.v.01.gnaw_at'), ['gnawed', 'at']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Andrei'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['.']],\n",
       "  [['To'],\n",
       "   Tree(Lemma('confess.v.01.confess'), ['confess']),\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('canvas.n.01.canvas'), ['canvas']),\n",
       "   Tree(Lemma('chair.n.01.chair'), ['chair']),\n",
       "   ['as'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('prie-dieu.n.01.prie-dieu'), ['prie-dieu']),\n",
       "   [','],\n",
       "   Tree(Lemma('gouge.v.01.gouge'), ['gouging']),\n",
       "   ['at'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['until'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('rough.a.01.rough'), ['rough']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('stupid.a.01.stupid'), ['stupid']),\n",
       "   Tree(Lemma('hand.n.01.hand'), ['hand']),\n",
       "   Tree(Lemma('invite.v.04.bid'), ['bade']),\n",
       "   ['him'],\n",
       "   Tree(Lemma('arise.v.03.rise'), ['rise']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('go.v.03.go'), ['go']),\n",
       "   ['?']],\n",
       "  [['``'],\n",
       "   ['The'],\n",
       "   Tree('world.n.00', ['world']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('full.a.01.full'), ['full']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('chap.n.01.bloke'), ['blokes']),\n",
       "   ['who'],\n",
       "   Tree(Lemma('put.v.02.put'), ['put']),\n",
       "   ['their'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['hearts']),\n",
       "   ['into'],\n",
       "   Tree(Lemma('cause.v.01.make'), ['making']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('tragic.a.02.tragic'), ['tragic']),\n",
       "   Tree(Lemma('picture.n.04.scene'), ['scene']),\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   ['our'],\n",
       "   Tree(Lemma('present.a.01.present'), ['present']),\n",
       "   Tree(Lemma('era.n.01.era'), ['era']),\n",
       "   ['of'],\n",
       "   Tree('science.n.00', ['Science']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('angst.n.01.angst'), ['Angst']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['has'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('downgrade.v.01.downgrade'), ['downgraded']),\n",
       "   [','],\n",
       "   ['to'],\n",
       "   Tree(Lemma('use.v.01.use'), ['use']),\n",
       "   ['one'],\n",
       "   ['of'],\n",
       "   ['our'],\n",
       "   Tree(Lemma('popular.a.01.popular'), ['popular']),\n",
       "   Tree(Lemma('retrograde.s.03.retrogressive'), ['retrogressive']),\n",
       "   Tree(Lemma('verb.n.02.verb'), ['verbs']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   Tree(Lemma('last.s.01.last'), ['Last']),\n",
       "   Tree(Lemma('year.n.01.year'), ['year']),\n",
       "   ['your'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Tennessee', 'Williams'])]),\n",
       "   Tree(Lemma('state.v.01.tell'), ['told']),\n",
       "   ['our'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Dilys', 'Powell'])]),\n",
       "   [','],\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('television_program.n.01.television_program'), ['television', 'program']),\n",
       "   [','],\n",
       "   ['that'],\n",
       "   ['it'],\n",
       "   ['is'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('job.n.02.task'), ['task']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('dramatist.n.01.playwright'), ['playwright']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('shed.v.01.throw'), ['throw']),\n",
       "   Tree(Lemma('light.n.10.light'), ['light']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('dark.a.01.dark'), ['dark']),\n",
       "   Tree(Lemma('corner.n.01.corner'), ['corners']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('human.a.01.human'), ['human']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['.']],\n",
       "  [['Like'],\n",
       "   Tree(Lemma('about.r.07.almost'), ['almost']),\n",
       "   ['everybody'],\n",
       "   Tree('else.r.00', ['else']),\n",
       "   [','],\n",
       "   ['he'],\n",
       "   Tree(Lemma('confuse.v.01.confuse'), ['confused']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   [','],\n",
       "   ['both'],\n",
       "   ['as'],\n",
       "   Tree(Lemma('organ.n.01.organ'), ['organ']),\n",
       "   ['and'],\n",
       "   ['as'],\n",
       "   Tree(Lemma('symbol.n.01.symbol'), ['symbol']),\n",
       "   [','],\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('disturbed.s.03.disturbed'), ['disturbed']),\n",
       "   Tree(Lemma('soul.n.01.psyche'), ['psyche']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('crazed.s.01.deranged'), ['deranged']),\n",
       "   Tree(Lemma('gland.n.01.gland'), ['glands']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('edgy.s.01.jumpy'), ['jumpy']),\n",
       "   Tree(Lemma('central_nervous_system.n.01.central_nervous_system'), ['central', 'nervous', 'system']),\n",
       "   ['.']],\n",
       "  [[\"I'm\"],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('plead.v.01.plead'), ['pleading']),\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('jump.v.01.leap'), ['leaps']),\n",
       "   ['up'],\n",
       "   ['when'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('behold.v.01.behold'), ['beholds']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('rainbow.n.01.rainbow'), ['rainbow']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('sky.n.01.sky'), ['sky']),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['that'],\n",
       "   ['with'],\n",
       "   Tree(Lemma('ecstasy.n.01.rapture'), ['rapture']),\n",
       "   Tree(Lemma('fill.v.02.fill'), ['fills']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('dance.v.01.dance'), ['dances']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('daffodil.n.01.daffodil'), ['daffodils']),\n",
       "   ['.']],\n",
       "  [[\"I'm\"],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('plead.v.01.plead'), ['pleading']),\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('jump.v.01.leap'), ['leaps']),\n",
       "   ['up'],\n",
       "   ['when'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('behold.v.01.behold'), ['beholds']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('rainbow.n.01.rainbow'), ['rainbow']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('sky.n.01.sky'), ['sky']),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['that'],\n",
       "   ['with'],\n",
       "   Tree(Lemma('ecstasy.n.01.rapture'), ['rapture']),\n",
       "   Tree(Lemma('fill.v.02.fill'), ['fills']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('dance.v.01.dance'), ['dances']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('daffodil.n.01.daffodil'), ['daffodils']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('sentimental.s.01.sentimental'), ['sentimental']),\n",
       "   Tree(Lemma('pure.a.01.pure'), ['pure']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Galahad'])]),\n",
       "   ['is'],\n",
       "   Tree(Lemma('go.v.09.go'), ['gone']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('chivalric.s.01.knightly'), ['knightly']),\n",
       "   Tree(Lemma('year.n.01.year'), ['years']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   ['I'],\n",
       "   Tree(Lemma('still.r.01.still'), ['still']),\n",
       "   Tree(Lemma('believe_in.v.01.believe_in'), ['believe', 'in']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['George', 'Meredith'])]),\n",
       "   Tree(Lemma('fictional_character.n.01.character'), ['character']),\n",
       "   ['that'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('form.v.02.make'), ['made']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('material.n.01.stuff'), ['stuff']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('breakage.n.03.break'), ['breaks']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('sentimental.s.01.sentimental'), ['sentimental']),\n",
       "   Tree(Lemma('pure.a.01.pure'), ['pure']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Galahad'])]),\n",
       "   ['is'],\n",
       "   Tree(Lemma('go.v.09.go'), ['gone']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('chivalric.s.01.knightly'), ['knightly']),\n",
       "   Tree(Lemma('year.n.01.year'), ['years']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   ['I'],\n",
       "   Tree(Lemma('still.r.01.still'), ['still']),\n",
       "   Tree(Lemma('believe_in.v.01.believe_in'), ['believe', 'in']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['George', 'Meredith'])]),\n",
       "   Tree(Lemma('fictional_character.n.01.character'), ['character']),\n",
       "   ['that'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('form.v.02.make'), ['made']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('material.n.01.stuff'), ['stuff']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('breakage.n.03.break'), ['breaks']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   ['We'],\n",
       "   Tree(Lemma('no_longer.r.01.no_longer'), ['no', 'longer']),\n",
       "   Tree(Lemma('have.v.02.have'), ['have']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Tom', 'Moore'])]),\n",
       "   [\"'s\"],\n",
       "   ['and'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Longfellow'])]),\n",
       "   [\"'s\"],\n",
       "   [\"'\"],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['for'],\n",
       "   ['any'],\n",
       "   Tree(Lemma('destiny.n.01.fate'), ['fate']),\n",
       "   [\"'\"],\n",
       "   [','],\n",
       "   Tree(Lemma('either.r.01.either'), ['either']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   ['I'],\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   ['The'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   ['I'],\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   Tree(Lemma('finally.r.01.finally'), ['finally']),\n",
       "   [','],\n",
       "   ['``'],\n",
       "   Tree(Lemma('be.v.03.be'), ['is']),\n",
       "   Tree(Lemma('nowadays.r.01.now'), ['now']),\n",
       "   ['either'],\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('throat.n.01.throat'), ['throat']),\n",
       "   ['or'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('mouth.n.01.mouth'), ['mouth']),\n",
       "   ['or'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('stomach.n.01.stomach'), ['stomach']),\n",
       "   ['or'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('shoe.n.01.shoe'), ['shoes']),\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('alike.a.01.similar'), ['similar']),\n",
       "   Tree(Lemma('vein.n.02.vein'), ['vein']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   Tree(Lemma('write.v.02.write'), ['writing']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('opposite.a.02.opposite'), ['opposite']),\n",
       "   Tree(Lemma('side.n.02.side'), ['side']),\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Thomas', 'Taylor'])]),\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree(Lemma('private.n.01.private'), ['private']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('sixth.s.01.6th'), ['6', 'th']),\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Alabama', 'Volunteers'])]),\n",
       "   [','],\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('letter.n.01.letter'), ['letter']),\n",
       "   ['to'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('wife.n.01.wife'), ['wife']),\n",
       "   [','],\n",
       "   Tree(Lemma('state.v.01.state'), ['stated']),\n",
       "   [':'],\n",
       "   ['``'],\n",
       "   ['You'],\n",
       "   Tree(Lemma('know.v.01.know'), ['know']),\n",
       "   ['that'],\n",
       "   ['my'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   Tree(Lemma('be.v.03.be'), ['is']),\n",
       "   ['with'],\n",
       "   ['you'],\n",
       "   ['but'],\n",
       "   ['I'],\n",
       "   Tree(Lemma('never.r.01.never'), ['never']),\n",
       "   ['could'],\n",
       "   ['have'],\n",
       "   Tree(Lemma('be.v.01.be'), ['been']),\n",
       "   Tree(Lemma('satisfied.s.01.satisfied'), ['satisfied']),\n",
       "   ['to'],\n",
       "   ['have'],\n",
       "   Tree(Lemma('stay.v.05.stay'), ['staid']),\n",
       "   ['at'],\n",
       "   Tree(Lemma('home.r.01.home'), ['home']),\n",
       "   ['when'],\n",
       "   ['my'],\n",
       "   Tree(Lemma('country.n.02.country'), ['country']),\n",
       "   ['is'],\n",
       "   Tree(Lemma('invade.v.01.invade'), ['invaded']),\n",
       "   ['by'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('thieving.s.01.thieving'), ['thievin']),\n",
       "   Tree(Lemma('foe.n.02.foe'), ['foe']),\n",
       "   ['By'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('set.n.05.set'), ['set']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('cowardly.a.01.cowardly'), ['cowardly']),\n",
       "   Tree(Lemma('rotter.n.01.skunk'), ['Skunks']),\n",
       "   ['whose'],\n",
       "   Tree(Lemma('motto.n.01.motto'), ['Motto']),\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   Tree(Lemma('loot.n.01.booty'), ['Booty']),\n",
       "   ['.']],\n",
       "  [['I'],\n",
       "   Tree(Lemma('search.v.02.look'), ['looked']),\n",
       "   Tree(Lemma('endlessly.r.02.unceasingly'), ['unceasingly']),\n",
       "   ['With'],\n",
       "   ['my'],\n",
       "   Tree(Lemma('cold.a.02.cold'), ['cold']),\n",
       "   Tree(Lemma('mind.n.01.mind'), ['mind']),\n",
       "   ['and'],\n",
       "   ['with'],\n",
       "   ['my'],\n",
       "   Tree('burning.s.00', ['burning']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('state.v.01.tell'), ['tells']),\n",
       "   ['of'],\n",
       "   ['his'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('jewish.a.01.Jewish'), ['Jewish']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   [\"''\"],\n",
       "   ['-'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   ['a'],\n",
       "   Tree('NE', ['Shylockian']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   [';'],\n",
       "   ['but'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('jewish.a.01.Jewish'), ['Jewish']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('state.v.01.tell'), ['tells']),\n",
       "   ['of'],\n",
       "   ['his'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('jewish.a.01.Jewish'), ['Jewish']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   [\"''\"],\n",
       "   ['-'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   ['a'],\n",
       "   Tree('NE', ['Shylockian']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   [';'],\n",
       "   ['but'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('jewish.a.01.Jewish'), ['Jewish']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('state.v.01.tell'), ['tells']),\n",
       "   ['of'],\n",
       "   ['his'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('jewish.a.01.Jewish'), ['Jewish']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   [\"''\"],\n",
       "   ['-'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   ['a'],\n",
       "   Tree('NE', ['Shylockian']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   [';'],\n",
       "   ['but'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('jewish.a.01.Jewish'), ['Jewish']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['.']],\n",
       "  [['Would'],\n",
       "   ['we'],\n",
       "   Tree(Lemma('profit.v.01.gain'), ['gain']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('keep.v.01.keep'), ['keeping']),\n",
       "   Tree(Lemma('alive.a.01.alive'), ['alive']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('memory.n.01.memory'), ['memory']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('defame.v.01.besmirch'), ['besmirching']),\n",
       "   Tree(Lemma('today.n.01.today'), ['today']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('roman_catholic.n.01.Roman_Catholic'), ['Roman', 'Catholics']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('state.v.01.say'), ['saying']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('have.v.01.have'), ['had']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('catholic.a.01.Catholic'), ['Catholic']),\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['?']],\n",
       "  [['With'],\n",
       "   ['all'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['he'],\n",
       "   ['had'],\n",
       "   Tree(Lemma('love.v.01.love'), ['loved']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('navy.n.01.navy'), ['Navy']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('now.r.01.now'), ['now']),\n",
       "   ['he'],\n",
       "   Tree('must.v.00', ['must']),\n",
       "   Tree(Lemma('act.v.01.act'), ['act']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('accord.n.02.accordance'), ['accordance']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('navy.n.01.navy'), ['Navy']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('implacable.a.01.implacable'), ['implacable']),\n",
       "   Tree(Lemma('law.n.01.law'), ['laws']),\n",
       "   ['.']],\n",
       "  [['One'],\n",
       "   Tree(Lemma('perform.v.01.do'), ['did']),\n",
       "   ['one'],\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('best.n.01.best'), ['best']),\n",
       "   ['and'],\n",
       "   ['if'],\n",
       "   Tree(Lemma('luck.n.02.fortune'), ['fortune']),\n",
       "   ['frowned'],\n",
       "   [','],\n",
       "   ['an'],\n",
       "   Tree(Lemma('eighteen.s.01.eighteen'), ['eighteen']),\n",
       "   Tree(Lemma('year.n.01.year'), ['year']),\n",
       "   Tree(Lemma('old.a.01.old'), ['old']),\n",
       "   Tree(Lemma('male_child.n.01.boy'), ['boy']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('murder.n.01.murder'), ['murder']),\n",
       "   ['in'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   Tree(Lemma('sail.v.03.sail'), ['sailed']),\n",
       "   ['aboard'],\n",
       "   ['one'],\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('ship.n.01.ship'), ['ship']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   ['can'],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   Tree(Lemma('be.v.02.be'), ['be']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('mild.a.01.mild'), ['mild']),\n",
       "   Tree(Lemma('voiced.a.01.voiced'), ['voiced']),\n",
       "   Tree(Lemma('small.a.01.little'), ['little']),\n",
       "   Tree(Lemma('town.n.01.town'), ['town']),\n",
       "   Tree(Lemma('guy.n.01.guy'), ['guy']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('large.a.01.big'), ['big']),\n",
       "   Tree(Lemma('town.n.01.town'), ['town']),\n",
       "   Tree(Lemma('idea.n.01.idea'), ['ideas']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('level.s.02.level'), ['level']),\n",
       "   Tree(Lemma('grey.s.01.gray'), ['gray']),\n",
       "   Tree(Lemma('eye.n.01.eye'), ['eyes']),\n",
       "   ['and'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Houdini'])]),\n",
       "   ['could'],\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   Tree(Lemma('solve.v.01.figure_out'), ['figure', 'out']),\n",
       "   [','],\n",
       "   ['how'],\n",
       "   ['it'],\n",
       "   ['is'],\n",
       "   Tree(Lemma('unlock.v.01.unlock'), ['unlocked']),\n",
       "   ['.']],\n",
       "  [['And'],\n",
       "   Tree('in_a_way.r.00', ['in', 'a', 'way']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('promise.n.01.promise'), ['promise']),\n",
       "   Tree(Lemma('work_out.v.02.work_out'), ['works', 'out']),\n",
       "   Tree(Lemma('true.a.01.true'), ['true']),\n",
       "   [','],\n",
       "   ['for'],\n",
       "   ['whether'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('desire.v.01.want'), ['wants']),\n",
       "   ['you'],\n",
       "   ['or'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   [','],\n",
       "   ['you'],\n",
       "   Tree(Lemma('travel.v.01.go'), ['go']),\n",
       "   ['with'],\n",
       "   ['him'],\n",
       "   ['in'],\n",
       "   ['your'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('dwelling.n.01.home'), ['Homes']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('factory.n.01.factory'), ['factories']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('school.n.02.school'), ['schools']),\n",
       "   ['and'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('large.a.01.big'), ['big']),\n",
       "   Tree(Lemma('wide.a.01.wide'), ['wide']),\n",
       "   Tree(Lemma('federal.s.01.federal'), ['federal']),\n",
       "   Tree(Lemma('highway.n.01.highway'), ['highway']),\n",
       "   [','],\n",
       "   ['instead'],\n",
       "   ['of'],\n",
       "   Tree(Lemma('peaceful.a.01.peaceful'), ['peaceful']),\n",
       "   Tree(Lemma('corn.n.01.corn'), ['corn']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('rest.v.03.rest'), ['rest']),\n",
       "   ['your'],\n",
       "   Tree(Lemma('eye.n.01.eye'), ['eyes']),\n",
       "   ['on'],\n",
       "   ['while'],\n",
       "   ['you'],\n",
       "   Tree(Lemma('try.v.01.try'), ['tried']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('rest.v.03.rest'), ['rest']),\n",
       "   ['your'],\n",
       "   Tree(Lemma('heart.n.01.heart'), ['heart']),\n",
       "   [','],\n",
       "   ['while'],\n",
       "   ['you'],\n",
       "   Tree(Lemma('try.v.01.try'), ['tried']),\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('look.v.01.look'), ['look']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('balloon.n.01.balloon'), ['balloon']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bandstand.n.01.bandstand'), ['bandstand']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('uniform.n.01.uniform'), ['uniforms']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('flash.n.02.flash'), ['flash']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('instrument.n.01.instrument'), ['instruments']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('contrarily.r.02.on_the_contrary'), ['On', 'the', 'contrary']),\n",
       "   [','],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('center.n.01.heart'), ['heart']),\n",
       "   ['of'],\n",
       "   ['``'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bible_belt.n.01.Bible_Belt'), ['Bible', 'belt']),\n",
       "   [\"''\"],\n",
       "   ['itself'],\n",
       "   [','],\n",
       "   ['as'],\n",
       "   ['can'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('attest.v.02.attest'), ['attested']),\n",
       "   ['by'],\n",
       "   ['any'],\n",
       "   ['one'],\n",
       "   ['who'],\n",
       "   ['is'],\n",
       "   Tree(Lemma('call.v.05.call'), ['called']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('work.v.02.work'), ['work']),\n",
       "   ['there'],\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('industrial_revolution.n.01.Industrial_Revolution'), ['industrial']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('industrial_revolution.n.01.technological_revolution'), ['technological', 'revolutions']),\n",
       "   ['have'],\n",
       "   Tree(Lemma('long.r.01.long'), ['long']),\n",
       "   Tree(Lemma('be.v.01.be'), ['been']),\n",
       "   Tree(Lemma('afoot.s.02.underway'), ['under', 'way']),\n",
       "   [','],\n",
       "   Tree(Lemma('together.r.04.together'), ['together']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('corresponding.s.01.corresponding'), ['corresponding']),\n",
       "   Tree(Lemma('change.n.02.change'), ['changes']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('man.n.03.man'), ['man']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('mental_picture.n.01.picture'), ['picture']),\n",
       "   ['of'],\n",
       "   ['himself'],\n",
       "   ['and'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('world.n.03.world'), ['world']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Raymond', 'Vernon'])]),\n",
       "   Tree(Lemma('report.n.02.report'), ['reports']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('resident.n.01.resident'), ['residents']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['East', 'St.', 'Louis'])]),\n",
       "   ['have'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('drive.v.02.drive'), ['driving']),\n",
       "   ['across'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('mississippi.n.01.Mississippi'), ['Mississippi']),\n",
       "   [','],\n",
       "   ['through'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('center.n.01.heart'), ['heart']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('downtown.a.01.downtown'), ['downtown']),\n",
       "   Tree(Lemma('saint_louis.n.02.St._Louis'), ['St.', 'Louis']),\n",
       "   ['and'],\n",
       "   Tree('out.r.00', ['out']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree('western.s.00', ['western']),\n",
       "   Tree(Lemma('suburb.n.01.suburb'), ['suburbs']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('major.a.01.major'), ['major']),\n",
       "   Tree(Lemma('shopping.n.01.shopping'), ['shopping']),\n",
       "   [','],\n",
       "   Tree(Lemma('merely.r.01.simply'), ['simply']),\n",
       "   ['because'],\n",
       "   Tree(Lemma('parking.n.02.parking'), ['parking']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('easy.a.01.easy'), ['easier']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('large.a.01.big'), ['big']),\n",
       "   Tree(Lemma('branch.n.01.branch'), ['branches']),\n",
       "   ['than'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('center.n.01.heart'), ['heart']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('town.n.01.town'), ['town']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Raymond', 'Vernon'])]),\n",
       "   Tree(Lemma('report.n.02.report'), ['reports']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('resident.n.01.resident'), ['residents']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['East', 'St.', 'Louis'])]),\n",
       "   ['have'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('drive.v.02.drive'), ['driving']),\n",
       "   ['across'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('mississippi.n.01.Mississippi'), ['Mississippi']),\n",
       "   [','],\n",
       "   ['through'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('center.n.01.heart'), ['heart']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('downtown.a.01.downtown'), ['downtown']),\n",
       "   Tree(Lemma('saint_louis.n.02.St._Louis'), ['St.', 'Louis']),\n",
       "   ['and'],\n",
       "   Tree('out.r.00', ['out']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree('western.s.00', ['western']),\n",
       "   Tree(Lemma('suburb.n.01.suburb'), ['suburbs']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('major.a.01.major'), ['major']),\n",
       "   Tree(Lemma('shopping.n.01.shopping'), ['shopping']),\n",
       "   [','],\n",
       "   Tree(Lemma('merely.r.01.simply'), ['simply']),\n",
       "   ['because'],\n",
       "   Tree(Lemma('parking.n.02.parking'), ['parking']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('easy.a.01.easy'), ['easier']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('large.a.01.big'), ['big']),\n",
       "   Tree(Lemma('branch.n.01.branch'), ['branches']),\n",
       "   ['than'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('center.n.01.heart'), ['heart']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('town.n.01.town'), ['town']),\n",
       "   ['.']],\n",
       "  [['They'],\n",
       "   ['had'],\n",
       "   Tree(Lemma('let.v.01.let'), ['let']),\n",
       "   ['this'],\n",
       "   Tree(Lemma('black_hole.n.01.black_hole'), ['black', 'hole']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('death.n.03.death'), ['death']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('warszawa.n.01.Warsaw'), ['Warsaw']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('center.n.01.heart'), ['heart']),\n",
       "   Tree(Lemma('exist.v.01.exist'), ['exist']),\n",
       "   ['without'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('cry.n.02.cry'), ['cry']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('protest.n.01.protest'), ['protest']),\n",
       "   ['.']]],\n",
       " [23, 31, 33, 62, 66])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_word_data('heart', 'n')\n",
    "sel.get_selected_sense_sents(sel.get_senses_for_curr_word())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BdyObj: heart.n: 1- metaphorical, 2- organ, face.n: 1- body part, 3- appearance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Homonymous Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "01       52\n",
       "02       25\n",
       "03        4"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('table', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "01       21\n",
       "02       16\n",
       "03        2"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('plane', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "01       66\n",
       "02       79\n",
       "03        6\n",
       "06        1\n",
       "07        1"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('foot', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senses for word degree.n\n",
      "Number of sentences for sense Synset('degree.n.05') 6\n",
      "Number of sentences for sense Synset('degree.n.02') 17\n",
      "Number of sentences for sense Synset('degree.n.01') 23\n",
      "Number of sentences for sense Synset('academic_degree.n.01') 13\n",
      "Number of sentences for sense Synset('degree.n.04') 7\n",
      "Number of sentences for sense Synset('degree.n.06') 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['We can do this through the characteristic values and vectors of T in certain special cases , i.e. , when the minimal polynomial for T factors over the scalar field F into a product of distinct monic polynomials of degree 1 .',\n",
       "  'Second , even if the characteristic polynomial factors completely over F into a product of polynomials of degree 1 , there may not be enough characteristic vectors for T to span the space V ; this is clearly a deficiency in T .',\n",
       "  'The theorem which we prove is more general than what we have described , since it works with the primary decomposition of the minimal polynomial , whether or not the primes which enter are all of first degree .',\n",
       "  'The reader will find it helpful to think of the special case when the primes are of degree 1 , and even more particularly , to think of the proof of Theorem 10 , a special case of this theorem .',\n",
       "  'In the notation of the proof of Theorem 12 , let us take a look at the special case in which the minimal polynomial for T is a product of first degree polynomials , i.e. , the case in which each * * f is of the form * * f .',\n",
       "  'A function g such that * * f , i.e. , * * f , must be a polynomial function of degree * * f or less : * * f .',\n",
       "  'From the technical standpoint , records differ from live music to the degree that they fail to convey the true color , texture , complexity , range , intensity , pulse , and pitch of the original .',\n",
       "  'The degree of circumstance , the ratio of memory to forgetfulness , determines whether a dream will be a recognized , fulfilled prevision , or the vaguely , effective source of the weird deja vu feeling .',\n",
       "  'Contrary to these expectations we have found it impossible to obtain the degree of reproducibility one would wish , even with extensive efforts to prepare especially pure reagents .',\n",
       "  'Microscopic studies of the gastrocnemius , pectoralis major , transversus abdominis , biceps brachii , and diaphragm showed atrophy as well as varying degrees of injury ranging from swelling and vacuolization to focal necrosis of the muscle fibers .',\n",
       "  \"Furthermore , conditioned reactions are fundamentally altered when the hypothalamic sympathetic reactivity is augmented beyond a critical level , and several types of behavioral changes probably related to the degree of central autonomic `` tuning '' are observed .\",\n",
       "  'In our attempt to interpret the emotions in their physiological and pathological range , we emphasized the importance of the degree of activity of the parasympathetic and sympathetic divisions of the hypothalamic system and their influence on the inhibitory and excitatory systems , respectively .',\n",
       "  'The general intellectual outlook which had appeared in the eleventh century was now consolidated to a significant degree .',\n",
       "  'Those modern scholars who urge that we must keep in mind the fundamental continuity of Aegean development from earliest times - granted occasional irruptions of peoples and ideas from outside - are correct ; but all too many observers have been misled by this fact into minimizing the degree of change which took place in the early first millennium .',\n",
       "  'It appeared from the limited information available that the aerated lagoon might offer a satisfactory means of increasing the capacity of existing oxidation ponds as well as providing the same degree of treatment in a smaller volume .',\n",
       "  'For a moment she thought of answering with the truth but she knew there were men who shied away from virginity , who demanded some degree of education in body as well as mind .',\n",
       "  \"Since the magnitude of the plan made secrecy impossible , once the wheels had began to turn , persons controlling German industries , social institutions , and armed forces became , through their anti-Semitism or their tolerance of it , conscious accomplices of Hitler 's crimes ; whether in the last degree or a lesser one was a matter to be determined individually .\",\n",
       "  'Practically all of these practical skills are of such a nature that a degree of mastery can be obtained in high school sufficient to enable the youth to get a job at once on the basis of the skill .',\n",
       "  'Of course , it can be argued that an ability to write English correctly and with some degree of elegance is a marketable skill .',\n",
       "  'Today many college bound students try to take a course in personal typing , as they feel a certain degree of mastery of this skill is almost essential for one who proposes to do academic work in college and a professional school .',\n",
       "  'We feel the quality of these powers initially as in some degree wholesome or threatening .',\n",
       "  'The actual mean of 1.07 being about halfway between 0 of complete correlation and 2.0 of no correlation , it is evident that there is a pretty fair degree of similarity in the behavior even of particular individual items of meaning as regards long-term stem displacement .',\n",
       "  'He has announced results on Hokan , Penutian , Uto-Aztecan , and almost all other American families and phyla , and has diagrammed their degree of interrelation ; but he has not worked out by lexicostatistics one comprehensively complete classification of even a single family other than Salish .',\n",
       "  \"Because of this , only those with truly fine equipment will be able to appreciate the exact degree of the engineers ' triumph .\",\n",
       "  \"The `` moving '' picture of the train or the wave coming at the audience is , to be sure , more intense than a still picture of the same subject , but the difference is really one of degree ; the cinematic element of time is merely used to increase the realism of an object which would still be reasonably realistic in a still photo .\",\n",
       "  'It is curious that even centuries of repetition of the yearly cycle did not induce a sufficient degree of confidence to allow people to abandon the ceremonies of the winter solstice .',\n",
       "  '( 2 ) In the critical micelle region , there is a rapid agglomeration or polymerization to give the micelles , which have a degree of polymerization averaging around 60 - 80 .',\n",
       "  'Lung type 3 , ( fig. 3 ) is to some degree a composite of types 1 , and 2 , .',\n",
       "  \"Also , interlobular air drifts may be all but nonexistent in the cow ; probably occur in the horse much as in the human being ; and , in contrast are present to a relatively immense degree on a segmental basis in the dog where lobules are absent ( Van Allen and Lindskog , ' 31 ) .\",\n",
       "  'The value-system of a community or society is always correlated with , and to a degree dependent upon , a more or less shared system of religious beliefs and convictions .',\n",
       "  'Both parties and the Ministry of the Interior were busily at work after the elections trying to unearth the political affiliations of the successful candidates and , thereby , give the elections a confidential but known degree of national political significance .',\n",
       "  \"`` Dearly beloved '' , he preached , `` unless you repent of your sins in a measure , and become converted to a degree , you will , I regret to say , be damned to a more or less extent '' .\",\n",
       "  'It is true , that nothing has been found comparable with electricity by communication ; but the phenomena observed had such a degree of analogy to those depending on electrical distribution that one could not find the slightest difference .',\n",
       "  'The continuation and expansion of the shooting development program will assure to some degree that national and community leaders will be made aware of the ever growing need for shooting facilities and activities for hunting and shooting in answer to public demand .',\n",
       "  'Soil type , drainage , or degree of slope can make the difference between good crops and poor ones .',\n",
       "  'This means that such factors as the health of the parents , particularly the mother , their ability to provide their children with the necessities of life , the degree of population density of a country and the shortage of housing facilities may legitimately be taken into consideration in determining the number of offspring .',\n",
       "  'Many of them sincerely believe that the use of liquor in any form or in any degree is intrinsically evil and sinful .',\n",
       "  \"After only eighteen years of non-interference , there were already indications of melioration , though `` in a slight degree '' , to be sure .\",\n",
       "  'What the American people will do turns in large degree on their leadership .',\n",
       "  'The increase stems largely from the growing complexity of and higher degree of maintenance required for newer weapons and equipment .',\n",
       "  'It would have been desirable for the two communities to have differed only in respect to the variable being investigated : the degree of structure in teaching method .',\n",
       "  'There is much research evidence to validate the use of the instrument in differentiating individuals who are likely to manifest anxiety in varying degrees .',\n",
       "  'When helped by a high degree of structure in lesson presentation , then , and only then , does such a child attain unusual success .',\n",
       "  'The difficulty of analysis of any subsystem in the phonology is an inverse function of the size - smaller systems are more troublesome - for any given degree of morphophonemic complexity .',\n",
       "  'An elephant or a fox or a swan or a cocopalm or a banana possess in unusually high degree this quality of obvious , common-sense , indubitable identity , as do an eye or tooth or nail .',\n",
       "  'The enormity of what Conrad had told him made it impossible for Gilborn to accept , with any degree of realism , the actuality of it .',\n",
       "  'Dr. Clark holds an earned Doctor of Education degree from the University of Oklahoma .',\n",
       "  'He also received a Master of Science degree from Texas A+I College and a Bachelor of Science degree from Southwestern State College , Weatherford , Okla. .',\n",
       "  'He also received a Master of Science degree from Texas A+I College and a Bachelor of Science degree from Southwestern State College , Weatherford , Okla. .',\n",
       "  \"In all `` degree '' courses in interior design a number of `` academic '' or `` general studies '' courses are included .\",\n",
       "  'For proper accreditation of schools , teachers in any course must have a degree at least one level above that for which the student is a candidate .',\n",
       "  'Indeed , it has only been a matter of the last few years that reputable schools of art have granted degrees at all .',\n",
       "  'The basic problem involved is that a college setting up a graduate school must have an entirely separate faculty for the advanced degree .',\n",
       "  'Most professors in the course must , naturally , again have a higher degree than the course offers .',\n",
       "  'One solution is the acquisition of degrees in education but it is a poor substitute .',\n",
       "  'Independent art schools granting degrees must , naturally , follow this with academic accreditation by the appropriate regional group .',\n",
       "  'He completed his training in pharmacy also , taking his degree with high honors in 1797 , and in 1799 was awarded the degree of Doctor of Philosophy along with a prize for an essay in medicine .',\n",
       "  'He completed his training in pharmacy also , taking his degree with high honors in 1797 , and in 1799 was awarded the degree of Doctor of Philosophy along with a prize for an essay in medicine .',\n",
       "  'On December 9 , 1862 , Sergeant Edwin H. Fay , an unusual Louisianan who held A. B. and M. A. degrees from Harvard University and who before the war was headmaster of a private school for boys in Louisiana , wrote his wife :',\n",
       "  'Check the elevation of the ground , degree and direction of slopes , drainage , rock outcrops , topsoil types and quality , as well as subsoil .',\n",
       "  'The result of the observations is ( in ` K ) **f where the phase angle , |qt , is measured in degrees from new moon and the probable errors include absolute as well as relative errors .',\n",
       "  \"The transducer itself moves the beam in a sector scan , just like a radar antenna , while the entire transducer structure is moved over a 90 - degree arc in front of the eye to `` look into '' all corners .\",\n",
       "  'The total picture is only seen by the camera which integrates the many sector scans over the entire 90 - degree rotation period .',\n",
       "  \"Within about an hour with the help of reports from seismic stations in Alaska , Arizona and California , the quake 's epicenter was placed at 51 degrees North latitude and 158 degrees East longitude .\",\n",
       "  \"Within about an hour with the help of reports from seismic stations in Alaska , Arizona and California , the quake 's epicenter was placed at 51 degrees North latitude and 158 degrees East longitude .\",\n",
       "  'The valley was only a few hundred yards wide with just about room enough for a properly performed hundred-and-eighty degree turn .',\n",
       "  'Despite the 45 - degree weather the game was clicked off in 1 : 48 , thanks to only three bases on balls and some good infield play .'],\n",
       " [[['We'],\n",
       "   ['can'],\n",
       "   Tree(Lemma('make.v.01.do'), ['do']),\n",
       "   ['this'],\n",
       "   ['through'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('characteristic.a.01.characteristic'), ['characteristic']),\n",
       "   Tree(Lemma('value.n.01.value'), ['values']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('vector.n.01.vector'), ['vectors']),\n",
       "   ['of'],\n",
       "   ['T'],\n",
       "   ['in'],\n",
       "   Tree(Lemma('certain.s.01.certain'), ['certain']),\n",
       "   Tree(Lemma('particular.s.01.special'), ['special']),\n",
       "   Tree(Lemma('event.n.02.case'), ['cases']),\n",
       "   [','],\n",
       "   Tree(Lemma('i.e..r.01.i.e.'), ['i.e.']),\n",
       "   [','],\n",
       "   ['when'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('minimal.a.01.minimal'), ['minimal']),\n",
       "   Tree(Lemma('polynomial.n.01.polynomial'), ['polynomial']),\n",
       "   ['for'],\n",
       "   ['T'],\n",
       "   Tree(Lemma('factor.v.01.factor'), ['factors']),\n",
       "   ['over'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('scalar_field.n.01.scalar_field'), ['scalar', 'field']),\n",
       "   ['F'],\n",
       "   ['into'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('product.n.03.product'), ['product']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('distinct.s.01.distinct'), ['distinct']),\n",
       "   Tree(Lemma('monic_polynomial.n.01.monic_polynomial'), ['monic', 'polynomials']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('degree.n.05.degree'), ['degree']),\n",
       "   Tree(Lemma('one.n.01.1'), ['1']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('second.r.01.second'), ['Second']),\n",
       "   [','],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   ['if'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('characteristic.a.01.characteristic'), ['characteristic']),\n",
       "   Tree(Lemma('polynomial.n.01.polynomial'), ['polynomial']),\n",
       "   Tree(Lemma('factor.v.01.factor'), ['factors']),\n",
       "   Tree(Lemma('completely.r.02.completely'), ['completely']),\n",
       "   ['over'],\n",
       "   ['F'],\n",
       "   ['into'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('product.n.03.product'), ['product']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('polynomial.n.01.polynomial'), ['polynomials']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('degree.n.05.degree'), ['degree']),\n",
       "   Tree(Lemma('one.n.01.1'), ['1']),\n",
       "   [','],\n",
       "   ['there'],\n",
       "   ['may'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('exist.v.01.be'), ['be']),\n",
       "   Tree(Lemma('adequate.s.02.enough'), ['enough']),\n",
       "   Tree(Lemma('characteristic.a.01.characteristic'), ['characteristic']),\n",
       "   Tree(Lemma('vector.n.01.vector'), ['vectors']),\n",
       "   ['for'],\n",
       "   ['T'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('cross.v.05.span'), ['span']),\n",
       "   ['the'],\n",
       "   Tree('space.n.00', ['space']),\n",
       "   ['V'],\n",
       "   [';'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('constitute.v.01.be'), ['is']),\n",
       "   Tree(Lemma('clearly.r.01.clearly'), ['clearly']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('lack.n.01.deficiency'), ['deficiency']),\n",
       "   ['in'],\n",
       "   ['T'],\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('theorem.n.01.theorem'), ['theorem']),\n",
       "   ['which'],\n",
       "   ['we'],\n",
       "   Tree(Lemma('prove.v.04.prove'), ['prove']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('more.a.01.more'), ['more']),\n",
       "   Tree(Lemma('general.a.01.general'), ['general']),\n",
       "   ['than'],\n",
       "   ['what'],\n",
       "   ['we'],\n",
       "   ['have'],\n",
       "   Tree(Lemma('describe.v.01.describe'), ['described']),\n",
       "   [','],\n",
       "   ['since'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('function.v.01.work'), ['works']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('primary.a.01.primary'), ['primary']),\n",
       "   Tree(Lemma('decomposition.n.01.decomposition'), ['decomposition']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('minimal.a.01.minimal'), ['minimal']),\n",
       "   Tree(Lemma('polynomial.n.01.polynomial'), ['polynomial']),\n",
       "   [','],\n",
       "   ['whether'],\n",
       "   ['or'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('prime.n.01.prime'), ['primes']),\n",
       "   ['which'],\n",
       "   Tree(Lemma('enter.v.01.enter'), ['enter']),\n",
       "   Tree(Lemma('be.v.01.be'), ['are']),\n",
       "   Tree(Lemma('all.a.01.all'), ['all']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('first.s.02.first'), ['first']),\n",
       "   Tree(Lemma('degree.n.05.degree'), ['degree']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('reader.n.01.reader'), ['reader']),\n",
       "   ['will'],\n",
       "   Tree(Lemma('find.v.05.find'), ['find']),\n",
       "   ['it'],\n",
       "   Tree(Lemma('helpful.a.01.helpful'), ['helpful']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('remember.v.02.think_of'), ['think', 'of']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('particular.s.01.special'), ['special']),\n",
       "   Tree(Lemma('case.n.01.case'), ['case']),\n",
       "   ['when'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('prime.n.01.prime'), ['primes']),\n",
       "   Tree(Lemma('be.v.01.be'), ['are']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('degree.n.05.degree'), ['degree']),\n",
       "   Tree(Lemma('one.n.01.1'), ['1']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   Tree(Lemma('more.a.01.more'), ['more']),\n",
       "   Tree(Lemma('particularly.r.01.particularly'), ['particularly']),\n",
       "   [','],\n",
       "   ['to'],\n",
       "   Tree(Lemma('remember.v.02.think_of'), ['think', 'of']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('proof.n.02.proof'), ['proof']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('theorem.n.01.theorem'), ['Theorem']),\n",
       "   ['10'],\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree(Lemma('particular.s.01.special'), ['special']),\n",
       "   Tree(Lemma('case.n.01.case'), ['case']),\n",
       "   ['of'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('theorem.n.01.theorem'), ['theorem']),\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('notation.n.01.notation'), ['notation']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('proof.n.02.proof'), ['proof']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('theorem.n.01.theorem'), ['Theorem']),\n",
       "   ['12'],\n",
       "   [','],\n",
       "   Tree(Lemma('let.v.01.let'), ['let']),\n",
       "   ['us'],\n",
       "   Tree(Lemma('take_a_look.v.01.take_a_look'), ['take', 'a', 'look']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('particular.s.01.special'), ['special']),\n",
       "   Tree(Lemma('case.n.01.case'), ['case']),\n",
       "   ['in'],\n",
       "   ['which'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('minimal.a.01.minimal'), ['minimal']),\n",
       "   Tree(Lemma('polynomial.n.01.polynomial'), ['polynomial']),\n",
       "   ['for'],\n",
       "   ['T'],\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('product.n.03.product'), ['product']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('first.s.02.first'), ['first']),\n",
       "   Tree(Lemma('degree.n.05.degree'), ['degree']),\n",
       "   Tree(Lemma('polynomial.n.01.polynomial'), ['polynomials']),\n",
       "   [','],\n",
       "   Tree(Lemma('i.e..r.01.i.e.'), ['i.e.']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('case.n.01.case'), ['case']),\n",
       "   ['in'],\n",
       "   ['which'],\n",
       "   Tree('each.s.01', ['each']),\n",
       "   ['*'],\n",
       "   ['*'],\n",
       "   ['f'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('kind.n.01.form'), ['form']),\n",
       "   ['*'],\n",
       "   ['*'],\n",
       "   ['f'],\n",
       "   ['.']],\n",
       "  [['A'],\n",
       "   Tree(Lemma('function.n.01.function'), ['function']),\n",
       "   ['g'],\n",
       "   Tree('such_that.s.00', ['such', 'that']),\n",
       "   ['*'],\n",
       "   ['*'],\n",
       "   ['f'],\n",
       "   [','],\n",
       "   Tree(Lemma('i.e..r.01.i.e.'), ['i.e.']),\n",
       "   [','],\n",
       "   ['*'],\n",
       "   ['*'],\n",
       "   ['f'],\n",
       "   [','],\n",
       "   ['must'],\n",
       "   Tree(Lemma('be.v.02.be'), ['be']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('polynomial.n.01.polynomial'), ['polynomial']),\n",
       "   Tree(Lemma('function.n.01.function'), ['function']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('degree.n.05.degree'), ['degree']),\n",
       "   ['*'],\n",
       "   ['*'],\n",
       "   ['f'],\n",
       "   ['or'],\n",
       "   Tree(Lemma('less.a.01.less'), ['less']),\n",
       "   [':'],\n",
       "   ['*'],\n",
       "   ['*'],\n",
       "   ['f'],\n",
       "   ['.']],\n",
       "  [['From'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('technical.a.01.technical'), ['technical']),\n",
       "   Tree(Lemma('point_of_view.n.01.standpoint'), ['standpoint']),\n",
       "   [','],\n",
       "   Tree(Lemma('phonograph_record.n.01.record'), ['records']),\n",
       "   Tree(Lemma('differ.v.01.differ'), ['differ']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('live.a.01.live'), ['live']),\n",
       "   Tree(Lemma('music.n.01.music'), ['music']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['that'],\n",
       "   ['they'],\n",
       "   Tree(Lemma('fail.v.01.fail'), ['fail']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('convey.v.01.convey'), ['convey']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('true.a.01.true'), ['true']),\n",
       "   Tree(Lemma('color.n.03.color'), ['color']),\n",
       "   [','],\n",
       "   Tree(Lemma('texture.n.03.texture'), ['texture']),\n",
       "   [','],\n",
       "   Tree(Lemma('complexity.n.01.complexity'), ['complexity']),\n",
       "   [','],\n",
       "   Tree(Lemma('scope.n.01.range'), ['range']),\n",
       "   [','],\n",
       "   Tree(Lemma('intensity.n.02.intensity'), ['intensity']),\n",
       "   [','],\n",
       "   Tree(Lemma('pulsation.n.01.pulse'), ['pulse']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('pitch.n.01.pitch'), ['pitch']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('master.n.06.original'), ['original']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('circumstance.n.01.circumstance'), ['circumstance']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('ratio.n.01.ratio'), ['ratio']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('memory.n.02.memory'), ['memory']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('forgetfulness.n.01.forgetfulness'), ['forgetfulness']),\n",
       "   [','],\n",
       "   Tree(Lemma('determine.v.02.determine'), ['determines']),\n",
       "   ['whether'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('dream.n.01.dream'), ['dream']),\n",
       "   ['will'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('accepted.s.01.recognized'), ['recognized']),\n",
       "   [','],\n",
       "   Tree(Lemma('carry_through.v.01.fulfill'), ['fulfilled']),\n",
       "   Tree(Lemma('prevision.n.01.prevision'), ['prevision']),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('vaguely.r.01.vaguely'), ['vaguely']),\n",
       "   [','],\n",
       "   Tree(Lemma('effective.a.01.effective'), ['effective']),\n",
       "   Tree(Lemma('beginning.n.04.source'), ['source']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('eldritch.s.01.weird'), ['weird']),\n",
       "   Tree(Lemma('deja_vu.n.01.deja_vu'), ['deja', 'vu']),\n",
       "   Tree(Lemma('impression.n.01.feeling'), ['feeling']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('contrary.s.01.contrary'), ['Contrary']),\n",
       "   ['to'],\n",
       "   ['these'],\n",
       "   Tree(Lemma('anticipation.n.04.expectation'), ['expectations']),\n",
       "   ['we'],\n",
       "   ['have'],\n",
       "   Tree(Lemma('find.v.05.find'), ['found']),\n",
       "   ['it'],\n",
       "   Tree(Lemma('impossible.a.01.impossible'), ['impossible']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('obtain.v.01.obtain'), ['obtain']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('reproducibility.n.01.reproducibility'), ['reproducibility']),\n",
       "   ['one'],\n",
       "   ['would'],\n",
       "   Tree(Lemma('wish.v.02.wish'), ['wish']),\n",
       "   [','],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   ['with'],\n",
       "   Tree('extensive.s.00', ['extensive']),\n",
       "   Tree(Lemma('attempt.n.01.effort'), ['efforts']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('prepare.v.03.prepare'), ['prepare']),\n",
       "   Tree(Lemma('particularly.r.01.especially'), ['especially']),\n",
       "   Tree(Lemma('pure.a.01.pure'), ['pure']),\n",
       "   Tree(Lemma('reagent.n.01.reagent'), ['reagents']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('microscopic.a.01.microscopic'), ['Microscopic']),\n",
       "   Tree(Lemma('survey.n.01.study'), ['studies']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('gastrocnemius.n.01.gastrocnemius'), ['gastrocnemius']),\n",
       "   [','],\n",
       "   Tree(Lemma('pectoralis_major.n.01.pectoralis_major'), ['pectoralis', 'major']),\n",
       "   [','],\n",
       "   Tree(Lemma('transversus_abdominis_muscle.n.01.transversus_abdominis'), ['transversus', 'abdominis']),\n",
       "   [','],\n",
       "   Tree(Lemma('biceps_brachii.n.01.biceps_brachii'), ['biceps', 'brachii']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('diaphragm.n.02.diaphragm'), ['diaphragm']),\n",
       "   Tree(Lemma('show.v.01.show'), ['showed']),\n",
       "   Tree(Lemma('atrophy.n.01.atrophy'), ['atrophy']),\n",
       "   ['as', 'well', 'as'],\n",
       "   Tree(Lemma('vary.v.03.vary'), ['varying']),\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degrees']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('injury.n.01.injury'), ['injury']),\n",
       "   Tree(Lemma('range.v.01.range'), ['ranging']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('swelling.n.01.swelling'), ['swelling']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('vacuolization.n.01.vacuolization'), ['vacuolization']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('focal.s.01.focal'), ['focal']),\n",
       "   Tree(Lemma('necrosis.n.01.necrosis'), ['necrosis']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('muscle_cell.n.01.muscle_fiber'), ['muscle', 'fibers']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('furthermore.r.01.furthermore'), ['Furthermore']),\n",
       "   [','],\n",
       "   Tree(Lemma('conditional_reflex.n.01.conditioned_reaction'), ['conditioned', 'reactions']),\n",
       "   ['are'],\n",
       "   Tree(Lemma('basically.r.01.fundamentally'), ['fundamentally']),\n",
       "   Tree(Lemma('change.v.01.alter'), ['altered']),\n",
       "   ['when'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('hypothalamic.a.01.hypothalamic'), ['hypothalamic']),\n",
       "   Tree(Lemma('sympathetic.a.01.sympathetic'), ['sympathetic']),\n",
       "   Tree(Lemma('responsiveness.n.01.reactivity'), ['reactivity']),\n",
       "   ['is'],\n",
       "   Tree(Lemma('augment.v.02.augment'), ['augmented']),\n",
       "   ['beyond'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('critical.a.02.critical'), ['critical']),\n",
       "   Tree(Lemma('degree.n.01.level'), ['level']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree('several.s.01', ['several']),\n",
       "   Tree(Lemma('type.n.01.type'), ['types']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('behavioral.a.01.behavioral'), ['behavioral']),\n",
       "   Tree(Lemma('change.n.01.change'), ['changes']),\n",
       "   Tree(Lemma('probably.r.01.probably'), ['probably']),\n",
       "   Tree(Lemma('related.a.01.related_to'), ['related', 'to']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('central.a.02.central'), ['central']),\n",
       "   Tree(Lemma('autonomic.s.01.autonomic'), ['autonomic']),\n",
       "   ['``'],\n",
       "   Tree(Lemma('tuning.n.01.tuning'), ['tuning']),\n",
       "   [\"''\"],\n",
       "   ['are'],\n",
       "   Tree(Lemma('detect.v.01.observe'), ['observed']),\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   ['our'],\n",
       "   Tree(Lemma('attempt.n.01.attempt'), ['attempt']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('interpret.v.01.interpret'), ['interpret']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('emotion.n.01.emotion'), ['emotions']),\n",
       "   ['in'],\n",
       "   ['their'],\n",
       "   Tree(Lemma('physiological.a.01.physiological'), ['physiological']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('pathological.a.01.pathological'), ['pathological']),\n",
       "   Tree(Lemma('scope.n.01.range'), ['range']),\n",
       "   [','],\n",
       "   ['we'],\n",
       "   Tree(Lemma('stress.v.01.emphasize'), ['emphasized']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('importance.n.01.importance'), ['importance']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('action.n.02.activity'), ['activity']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('parasympathetic.a.01.parasympathetic'), ['parasympathetic']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('sympathetic.a.01.sympathetic'), ['sympathetic']),\n",
       "   Tree(Lemma('part.n.09.division'), ['divisions']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('hypothalamic.a.01.hypothalamic'), ['hypothalamic']),\n",
       "   Tree(Lemma('system.n.06.system'), ['system']),\n",
       "   ['and'],\n",
       "   ['their'],\n",
       "   Tree(Lemma('influence.n.02.influence'), ['influence']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('inhibitory.s.01.inhibitory'), ['inhibitory']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('excitant.s.01.excitatory'), ['excitatory']),\n",
       "   Tree(Lemma('system.n.06.system'), ['systems']),\n",
       "   [','],\n",
       "   Tree(Lemma('respectively.r.01.respectively'), ['respectively']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('general.a.01.general'), ['general']),\n",
       "   Tree('intellectual.a.00', ['intellectual']),\n",
       "   Tree(Lemma('mentality.n.01.outlook'), ['outlook']),\n",
       "   ['which'],\n",
       "   ['had'],\n",
       "   Tree(Lemma('appear.v.02.appear'), ['appeared']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('eleventh.s.01.eleventh'), ['eleventh']),\n",
       "   Tree(Lemma('century.n.01.century'), ['century']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('now.r.01.now'), ['now']),\n",
       "   Tree(Lemma('consolidate.v.01.consolidate'), ['consolidated']),\n",
       "   ['to'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('significant.s.02.significant'), ['significant']),\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['.']],\n",
       "  [['Those'],\n",
       "   Tree(Lemma('modern.s.03.modern'), ['modern']),\n",
       "   Tree(Lemma('scholar.n.01.scholar'), ['scholars']),\n",
       "   ['who'],\n",
       "   Tree(Lemma('urge.v.01.urge'), ['urge']),\n",
       "   ['that'],\n",
       "   ['we'],\n",
       "   ['must'],\n",
       "   Tree(Lemma('keep.v.01.keep'), ['keep']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('mind.n.01.mind'), ['mind']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('cardinal.s.01.fundamental'), ['fundamental']),\n",
       "   Tree(Lemma('continuity.n.01.continuity'), ['continuity']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('aegean.a.01.Aegean'), ['Aegean']),\n",
       "   Tree(Lemma('development.n.02.development'), ['development']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('early.a.01.early'), ['earliest']),\n",
       "   Tree(Lemma('times.n.01.times'), ['times']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('given.s.01.granted'), ['granted']),\n",
       "   Tree(Lemma('occasional.s.01.occasional'), ['occasional']),\n",
       "   Tree(Lemma('irruption.n.01.irruption'), ['irruptions']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('people.n.01.people'), ['peoples']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('idea.n.01.idea'), ['ideas']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('outside.n.01.outside'), ['outside']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('be.v.01.be'), ['are']),\n",
       "   Tree(Lemma('correct.a.01.correct'), ['correct']),\n",
       "   [';'],\n",
       "   ['but'],\n",
       "   Tree(Lemma('all_too.r.01.all_too'), ['all', 'too']),\n",
       "   Tree(Lemma('many.a.01.many'), ['many']),\n",
       "   Tree(Lemma('observer.n.02.observer'), ['observers']),\n",
       "   ['have'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('misinform.v.01.mislead'), ['misled']),\n",
       "   ['by'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('fact.n.01.fact'), ['fact']),\n",
       "   ['into'],\n",
       "   Tree(Lemma('understate.v.01.minimize'), ['minimizing']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('change.n.02.change'), ['change']),\n",
       "   ['which'],\n",
       "   Tree(Lemma('happen.v.01.take_place'), ['took', 'place']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('early.a.01.early'), ['early']),\n",
       "   Tree(Lemma('first.s.02.first'), ['first']),\n",
       "   Tree(Lemma('millennium.n.01.millennium'), ['millennium']),\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   Tree(Lemma('appear.v.04.appear'), ['appeared']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('limited.a.01.limited'), ['limited']),\n",
       "   Tree(Lemma('information.n.01.information'), ['information']),\n",
       "   Tree(Lemma('available.a.01.available'), ['available']),\n",
       "   ['that'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('aerated.s.01.aerated'), ['aerated']),\n",
       "   Tree(Lemma('lagoon.n.01.lagoon'), ['lagoon']),\n",
       "   ['might'],\n",
       "   Tree(Lemma('offer.v.01.offer'), ['offer']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('satisfactory.a.01.satisfactory'), ['satisfactory']),\n",
       "   Tree(Lemma('means.n.01.means'), ['means']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('increase.v.01.increase'), ['increasing']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('capacity.n.03.capacity'), ['capacity']),\n",
       "   ['of'],\n",
       "   Tree('existing.s.01', ['existing']),\n",
       "   Tree(Lemma('oxidation.n.01.oxidation'), ['oxidation']),\n",
       "   Tree(Lemma('pond.n.01.pond'), ['ponds']),\n",
       "   Tree(Lemma('besides.r.02.as_well'), ['as', 'well']),\n",
       "   ['as'],\n",
       "   Tree(Lemma('supply.v.01.provide'), ['providing']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('same.a.02.same'), ['same']),\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('treatment.n.02.treatment'), ['treatment']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('smaller.s.01.smaller'), ['smaller']),\n",
       "   Tree(Lemma('volume.n.01.volume'), ['volume']),\n",
       "   ['.']],\n",
       "  [['For'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('moment.n.02.moment'), ['moment']),\n",
       "   ['she'],\n",
       "   Tree(Lemma('entertain.v.02.think_of'), ['thought', 'of']),\n",
       "   Tree(Lemma('answer.v.01.answer'), ['answering']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('truth.n.03.truth'), ['truth']),\n",
       "   ['but'],\n",
       "   ['she'],\n",
       "   Tree(Lemma('know.v.01.know'), ['knew']),\n",
       "   ['there'],\n",
       "   Tree(Lemma('exist.v.01.be'), ['were']),\n",
       "   Tree(Lemma('man.n.01.man'), ['men']),\n",
       "   ['who'],\n",
       "   Tree(Lemma('shy_away_from.v.01.shy_away_from'), ['shied', 'away', 'from']),\n",
       "   Tree(Lemma('virginity.n.01.virginity'), ['virginity']),\n",
       "   [','],\n",
       "   ['who'],\n",
       "   Tree(Lemma('demand.v.03.demand'), ['demanded']),\n",
       "   ['some'],\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('education.n.05.education'), ['education']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('body.n.01.body'), ['body']),\n",
       "   ['as', 'well', 'as'],\n",
       "   Tree(Lemma('mind.n.01.mind'), ['mind']),\n",
       "   ['.']],\n",
       "  [['Since'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('magnitude.n.01.magnitude'), ['magnitude']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('plan.n.01.plan'), ['plan']),\n",
       "   Tree(Lemma('make.v.02.make'), ['made']),\n",
       "   Tree(Lemma('privacy.n.02.secrecy'), ['secrecy']),\n",
       "   Tree(Lemma('impossible.a.01.impossible'), ['impossible']),\n",
       "   [','],\n",
       "   Tree(Lemma('once.r.02.once'), ['once']),\n",
       "   ['the'],\n",
       "   Tree('wheels.n.00', ['wheels']),\n",
       "   ['had'],\n",
       "   Tree(Lemma('get_down.v.07.begin'), ['began']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('turn.v.09.turn'), ['turn']),\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), ['persons']),\n",
       "   Tree(Lemma('control.v.01.control'), ['controlling']),\n",
       "   Tree(Lemma('german.a.01.German'), ['German']),\n",
       "   Tree(Lemma('industry.n.01.industry'), ['industries']),\n",
       "   [','],\n",
       "   Tree(Lemma('social.a.01.social'), ['social']),\n",
       "   Tree(Lemma('institution.n.01.institution'), ['institutions']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('military.n.01.armed_forces'), ['armed', 'forces']),\n",
       "   Tree(Lemma('become.v.02.become'), ['became']),\n",
       "   [','],\n",
       "   ['through'],\n",
       "   ['their'],\n",
       "   Tree(Lemma('anti-semitism.n.01.anti-Semitism'), ['anti-Semitism']),\n",
       "   ['or'],\n",
       "   ['their'],\n",
       "   Tree(Lemma('tolerance.n.03.tolerance'), ['tolerance']),\n",
       "   ['of', 'it'],\n",
       "   [','],\n",
       "   Tree(Lemma('conscious.a.02.conscious'), ['conscious']),\n",
       "   Tree(Lemma('accomplice.n.01.accomplice'), ['accomplices']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('hitler.n.01.Hitler'), ['Hitler']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('crime.n.01.crime'), ['crimes']),\n",
       "   [';'],\n",
       "   ['whether'],\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('last.s.07.last'), ['last']),\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['or'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('lesser.a.01.lesser'), ['lesser']),\n",
       "   ['one'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('topic.n.02.matter'), ['matter']),\n",
       "   ['to'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('decide.v.01.determine'), ['determined']),\n",
       "   Tree(Lemma('individually.r.01.individually'), ['individually']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('practically.r.01.practically'), ['Practically']),\n",
       "   Tree('all_of.a.00', ['all', 'of']),\n",
       "   ['these'],\n",
       "   Tree(Lemma('practical.a.01.practical'), ['practical']),\n",
       "   Tree(Lemma('skill.n.01.skill'), ['skills']),\n",
       "   Tree(Lemma('be.v.01.be'), ['are']),\n",
       "   ['of'],\n",
       "   Tree('such.s.00', ['such']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('nature.n.01.nature'), ['nature']),\n",
       "   ['that'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('command.n.06.mastery'), ['mastery']),\n",
       "   ['can'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('obtain.v.01.obtain'), ['obtained']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('senior_high_school.n.01.high_school'), ['high', 'school']),\n",
       "   Tree(Lemma('sufficient.a.01.sufficient'), ['sufficient']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('enable.v.01.enable'), ['enable']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('young_person.n.01.youth'), ['youth']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('get.v.01.get'), ['get']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('occupation.n.01.job'), ['job']),\n",
       "   Tree(Lemma('immediately.r.01.at_once'), ['at', 'once']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('footing.n.02.basis'), ['basis']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('skill.n.01.skill'), ['skill']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('naturally.r.01.of_course'), ['Of', 'course']),\n",
       "   [','],\n",
       "   ['it'],\n",
       "   ['can'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('argue.v.01.argue'), ['argued']),\n",
       "   ['that'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('ability.n.02.ability'), ['ability']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('write.v.01.write'), ['write']),\n",
       "   Tree(Lemma('english.n.01.English'), ['English']),\n",
       "   Tree(Lemma('correctly.r.01.correctly'), ['correctly']),\n",
       "   ['and'],\n",
       "   ['with'],\n",
       "   ['some'],\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('elegance.n.01.elegance'), ['elegance']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('marketable.s.01.marketable'), ['marketable']),\n",
       "   Tree(Lemma('skill.n.01.skill'), ['skill']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('today.n.01.today'), ['Today']),\n",
       "   Tree(Lemma('many.a.01.many'), ['many']),\n",
       "   Tree(Lemma('college.n.01.college'), ['college']),\n",
       "   Tree(Lemma('bound.s.06.bound'), ['bound']),\n",
       "   Tree(Lemma('student.n.01.student'), ['students']),\n",
       "   Tree(Lemma('try.v.01.try'), ['try']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('learn.v.04.take'), ['take']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('course.n.01.course'), ['course']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('personal.a.01.personal'), ['personal']),\n",
       "   Tree(Lemma('typing.n.01.typing'), ['typing']),\n",
       "   [','],\n",
       "   ['as'],\n",
       "   ['they'],\n",
       "   Tree(Lemma('find.v.05.feel'), ['feel']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('certain.s.01.certain'), ['certain']),\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('command.n.06.mastery'), ['mastery']),\n",
       "   ['of'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('skill.n.01.skill'), ['skill']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('about.r.07.almost'), ['almost']),\n",
       "   Tree(Lemma('essential.s.01.essential'), ['essential']),\n",
       "   ['for'],\n",
       "   ['one'],\n",
       "   ['who'],\n",
       "   Tree(Lemma('aim.v.02.propose'), ['proposes']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('make.v.01.do'), ['do']),\n",
       "   Tree(Lemma('academic.a.01.academic'), ['academic']),\n",
       "   Tree(Lemma('study.n.02.work'), ['work']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('college.n.01.college'), ['college']),\n",
       "   ['and'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('professional.a.04.professional'), ['professional']),\n",
       "   Tree(Lemma('school.n.01.school'), ['school']),\n",
       "   ['.']],\n",
       "  [['We'],\n",
       "   Tree(Lemma('feel.v.03.feel'), ['feel']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('quality.n.03.quality'), ['quality']),\n",
       "   ['of'],\n",
       "   ['these'],\n",
       "   Tree(Lemma('power.n.01.power'), ['powers']),\n",
       "   Tree(Lemma('initially.r.01.initially'), ['initially']),\n",
       "   ['as'],\n",
       "   ['in'],\n",
       "   ['some'],\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   Tree(Lemma('wholesome.a.01.wholesome'), ['wholesome']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('baleful.s.02.threatening'), ['threatening']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('actual.a.01.actual'), ['actual']),\n",
       "   Tree(Lemma('mean.n.01.mean'), ['mean']),\n",
       "   ['of'],\n",
       "   ['1.07'],\n",
       "   Tree(Lemma('be.v.03.be'), ['being']),\n",
       "   ['about'],\n",
       "   Tree(Lemma('halfway.r.01.halfway'), ['halfway']),\n",
       "   ['between'],\n",
       "   Tree(Lemma('zero.n.02.0'), ['0']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('complete.a.01.complete'), ['complete']),\n",
       "   Tree(Lemma('correlation.n.01.correlation'), ['correlation']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('twenty.n.01.20'), ['2.0']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('no.a.01.no'), ['no']),\n",
       "   Tree(Lemma('correlation.n.01.correlation'), ['correlation']),\n",
       "   [','],\n",
       "   ['it'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('apparent.s.01.evident'), ['evident']),\n",
       "   ['that'],\n",
       "   ['there'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('reasonably.r.01.pretty'), ['pretty']),\n",
       "   Tree('fair.s.00', ['fair']),\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('similarity.n.01.similarity'), ['similarity']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('behavior.n.02.behavior'), ['behavior']),\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('particular.s.02.particular'), ['particular']),\n",
       "   Tree(Lemma('individual.a.01.individual'), ['individual']),\n",
       "   Tree(Lemma('detail.n.02.item'), ['items']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('meaning.n.01.meaning'), ['meaning']),\n",
       "   ['as'],\n",
       "   Tree(Lemma('involve.v.01.regard'), ['regards']),\n",
       "   Tree(Lemma('long-run.s.01.long-term'), ['long-term']),\n",
       "   Tree(Lemma('root.n.03.stem'), ['stem']),\n",
       "   Tree(Lemma('shift.n.01.displacement'), ['displacement']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   ['has'],\n",
       "   Tree(Lemma('announce.v.01.announce'), ['announced']),\n",
       "   Tree(Lemma('solution.n.02.result'), ['results']),\n",
       "   ['on'],\n",
       "   Tree(Lemma('hokan.n.01.Hokan'), ['Hokan']),\n",
       "   [','],\n",
       "   Tree(Lemma('penutian.n.01.Penutian'), ['Penutian']),\n",
       "   [','],\n",
       "   Tree(Lemma('uto-aztecan.n.01.Uto-Aztecan'), ['Uto-Aztecan']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('about.r.07.almost'), ['almost']),\n",
       "   ['all'],\n",
       "   Tree(Lemma('other.a.01.other'), ['other']),\n",
       "   Tree(Lemma('american.a.01.American'), ['American']),\n",
       "   Tree(Lemma('class.n.01.family'), ['families']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('phylum.n.01.phylum'), ['phyla']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['has'],\n",
       "   Tree(Lemma('diagram.v.01.diagram'), ['diagrammed']),\n",
       "   ['their'],\n",
       "   Tree(Lemma('degree.n.02.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('interrelation.n.01.interrelation'), ['interrelation']),\n",
       "   [';'],\n",
       "   ['but'],\n",
       "   ['he'],\n",
       "   ['has'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('elaborate.v.04.work_out'), ['worked', 'out']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('lexicostatistics.n.01.lexicostatistics'), ['lexicostatistics']),\n",
       "   Tree('one.s.00', ['one']),\n",
       "   Tree(Lemma('comprehensively.r.01.comprehensively'), ['comprehensively']),\n",
       "   Tree(Lemma('complete.a.01.complete'), ['complete']),\n",
       "   Tree(Lemma('classification.n.02.classification'), ['classification']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('individual.a.01.single'), ['single']),\n",
       "   Tree(Lemma('class.n.01.family'), ['family']),\n",
       "   Tree('other_than.s.00', ['other', 'than']),\n",
       "   Tree(Lemma('salish.n.01.Salish'), ['Salish']),\n",
       "   ['.']],\n",
       "  [['Because'],\n",
       "   ['of'],\n",
       "   ['this'],\n",
       "   [','],\n",
       "   Tree(Lemma('entirely.r.02.only'), ['only']),\n",
       "   ['those'],\n",
       "   ['with'],\n",
       "   Tree(Lemma('truly.r.01.truly'), ['truly']),\n",
       "   Tree('fine.s.00', ['fine']),\n",
       "   Tree(Lemma('equipment.n.01.equipment'), ['equipment']),\n",
       "   ['will'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   Tree(Lemma('able.a.01.able'), ['able']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('appreciate.v.02.appreciate'), ['appreciate']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('exact.a.01.exact'), ['exact']),\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('engineer.n.01.engineer'), ['engineers']),\n",
       "   [\"'\"],\n",
       "   Tree(Lemma('victory.n.01.triumph'), ['triumph']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('moving.a.01.moving'), ['moving']),\n",
       "   [\"''\"],\n",
       "   Tree(Lemma('picture.n.01.picture'), ['picture']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('train.n.01.train'), ['train']),\n",
       "   ['or'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('wave.n.01.wave'), ['wave']),\n",
       "   Tree(Lemma('come.v.01.come'), ['coming']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('audience.n.01.audience'), ['audience']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   [','],\n",
       "   Tree(Lemma('to_be_sure.r.01.to_be_sure'), ['to', 'be', 'sure']),\n",
       "   [','],\n",
       "   Tree(Lemma('more.r.01.more'), ['more']),\n",
       "   Tree(Lemma('intense.a.01.intense'), ['intense']),\n",
       "   ['than'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('inactive.s.10.still'), ['still']),\n",
       "   Tree(Lemma('picture.n.01.picture'), ['picture']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('same.a.01.same'), ['same']),\n",
       "   Tree(Lemma('subject.n.02.subject'), ['subject']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('difference.n.01.difference'), ['difference']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('actually.r.01.really'), ['really']),\n",
       "   ['one'],\n",
       "   ['of'],\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   [';'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('cinematic.a.01.cinematic'), ['cinematic']),\n",
       "   Tree(Lemma('component.n.03.element'), ['element']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('time.n.05.time'), ['time']),\n",
       "   ['is'],\n",
       "   Tree(Lemma('merely.r.01.merely'), ['merely']),\n",
       "   Tree(Lemma('use.v.01.use'), ['used']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('increase.v.01.increase'), ['increase']),\n",
       "   ['the'],\n",
       "   Tree('realism.n.00', ['realism']),\n",
       "   ['of'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('object.n.01.object'), ['object']),\n",
       "   ['which'],\n",
       "   ['would'],\n",
       "   Tree(Lemma('still.r.01.still'), ['still']),\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   Tree(Lemma('reasonably.r.01.reasonably'), ['reasonably']),\n",
       "   Tree(Lemma('naturalistic.s.01.realistic'), ['realistic']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('inactive.s.10.still'), ['still']),\n",
       "   Tree(Lemma('photograph.n.01.photo'), ['photo']),\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('curious.s.01.curious'), ['curious']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   Tree(Lemma('century.n.01.century'), ['centuries']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('repeat.n.01.repetition'), ['repetition']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree('yearly.a.00', ['yearly']),\n",
       "   Tree(Lemma('cycle.n.05.cycle'), ['cycle']),\n",
       "   ['did'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('induce.v.01.induce'), ['induce']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('sufficient.a.01.sufficient'), ['sufficient']),\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('confidence.n.02.confidence'), ['confidence']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('let.v.01.allow'), ['allow']),\n",
       "   Tree(Lemma('people.n.01.people'), ['people']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('abandon.v.01.abandon'), ['abandon']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('ceremony.n.01.ceremony'), ['ceremonies']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('winter_solstice.n.01.winter_solstice'), ['winter', 'solstice']),\n",
       "   ['.']],\n",
       "  [['('],\n",
       "   ['2'],\n",
       "   [')'],\n",
       "   ['In'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('critical.a.02.critical'), ['critical']),\n",
       "   Tree(Lemma('micelle.n.01.micelle'), ['micelle']),\n",
       "   Tree(Lemma('region.n.01.region'), ['region']),\n",
       "   [','],\n",
       "   ['there'],\n",
       "   Tree(Lemma('be.v.05.be'), ['is']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('rapid.s.01.rapid'), ['rapid']),\n",
       "   Tree(Lemma('agglomeration.n.01.agglomeration'), ['agglomeration']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('polymerization.n.01.polymerization'), ['polymerization']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('render.v.04.give'), ['give']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('micelle.n.01.micelle'), ['micelles']),\n",
       "   [','],\n",
       "   ['which'],\n",
       "   Tree(Lemma('have.v.02.have'), ['have']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('polymerization.n.01.polymerization'), ['polymerization']),\n",
       "   Tree(Lemma('average.v.01.average'), ['averaging']),\n",
       "   Tree(Lemma('approximately.r.01.around'), ['around']),\n",
       "   Tree(Lemma('sixty.s.01.60'), ['60']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('eighty.s.01.80'), ['80']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('lung.n.01.lung'), ['Lung']),\n",
       "   Tree(Lemma('type.n.01.type'), ['type']),\n",
       "   Tree(Lemma('three.s.01.3'), ['3']),\n",
       "   [','],\n",
       "   ['('],\n",
       "   Tree(Lemma('figure.n.01.fig'), ['fig.']),\n",
       "   Tree(Lemma('three.s.01.3'), ['3']),\n",
       "   [')'],\n",
       "   Tree(Lemma('constitute.v.01.be'), ['is']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('some.a.01.some'), ['some']),\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('complex.n.01.composite'), ['composite']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('type.n.01.type'), ['types']),\n",
       "   Tree(Lemma('one.s.01.1'), ['1']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('two.s.01.2'), ['2']),\n",
       "   [','],\n",
       "   ['.']],\n",
       "  [Tree(Lemma('besides.r.02.also'), ['Also']),\n",
       "   [','],\n",
       "   Tree(Lemma('interlobular.a.01.interlobular'), ['interlobular']),\n",
       "   Tree(Lemma('air.n.01.air'), ['air']),\n",
       "   Tree(Lemma('drift.n.01.drift'), ['drifts']),\n",
       "   ['may'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   Tree('all_but.r.00', ['all', 'but']),\n",
       "   Tree(Lemma('nonexistent.a.01.nonexistent'), ['nonexistent']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('cow.n.01.cow'), ['cow']),\n",
       "   [';'],\n",
       "   Tree(Lemma('probably.r.01.probably'), ['probably']),\n",
       "   Tree('occur.v.00', ['occur']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('horse.n.01.horse'), ['horse']),\n",
       "   Tree(Lemma('much_as.r.01.much_as'), ['much', 'as']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('homo.n.02.human_being'), ['human', 'being']),\n",
       "   [';'],\n",
       "   ['and'],\n",
       "   [','],\n",
       "   ['in'],\n",
       "   Tree(Lemma('contrast.n.02.contrast'), ['contrast']),\n",
       "   Tree(Lemma('be.v.01.be'), ['are']),\n",
       "   Tree(Lemma('present.a.02.present'), ['present']),\n",
       "   ['to'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('relatively.r.01.relatively'), ['relatively']),\n",
       "   Tree(Lemma('huge.s.01.immense'), ['immense']),\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['on'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('metameric.s.01.segmental'), ['segmental']),\n",
       "   Tree(Lemma('basis.n.02.basis'), ['basis']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('dog.n.01.dog'), ['dog']),\n",
       "   ['where'],\n",
       "   Tree(Lemma('lobule.n.01.lobule'), ['lobules']),\n",
       "   Tree(Lemma('be.v.01.be'), ['are']),\n",
       "   Tree(Lemma('absent.a.01.absent'), ['absent']),\n",
       "   ['('],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Van', 'Allen'])]),\n",
       "   ['and'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Lindskog'])]),\n",
       "   [','],\n",
       "   [\"'\"],\n",
       "   ['31'],\n",
       "   [')'],\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('ethic.n.01.value-system'), ['value-system']),\n",
       "   ['of'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('community.n.01.community'), ['community']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('society.n.01.society'), ['society']),\n",
       "   ['is'],\n",
       "   Tree(Lemma('always.r.01.always'), ['always']),\n",
       "   Tree(Lemma('correlative.s.01.correlated'), ['correlated']),\n",
       "   ['with'],\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['to'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   Tree(Lemma('dependent.a.01.dependent'), ['dependent']),\n",
       "   ['upon'],\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree(Lemma('approximately.r.01.more_or_less'), ['more', 'or', 'less']),\n",
       "   Tree(Lemma('shared.a.01.shared'), ['shared']),\n",
       "   Tree(Lemma('arrangement.n.03.system'), ['system']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('religion.n.01.religious_belief'), ['religious', 'beliefs']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('conviction.n.01.conviction'), ['convictions']),\n",
       "   ['.']],\n",
       "  [['Both'],\n",
       "   Tree(Lemma('party.n.01.party'), ['parties']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Ministry', 'of', 'the', 'Interior'])]),\n",
       "   Tree(Lemma('be.v.01.be'), ['were']),\n",
       "   Tree(Lemma('busily.r.01.busily'), ['busily']),\n",
       "   Tree(Lemma('at_work.s.01.at_work'), ['at', 'work']),\n",
       "   ['after'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('election.n.01.election'), ['elections']),\n",
       "   Tree(Lemma('try.v.01.try'), ['trying']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('unearth.v.01.unearth'), ['unearth']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('political.a.01.political'), ['political']),\n",
       "   Tree(Lemma('affiliation.n.01.affiliation'), ['affiliations']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('successful.a.01.successful'), ['successful']),\n",
       "   Tree(Lemma('campaigner.n.01.candidate'), ['candidates']),\n",
       "   ['and'],\n",
       "   [','],\n",
       "   Tree(Lemma('thereby.r.01.thereby'), ['thereby']),\n",
       "   [','],\n",
       "   Tree(Lemma('give.v.01.give'), ['give']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('election.n.01.election'), ['elections']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('confidential.s.01.confidential'), ['confidential']),\n",
       "   ['but'],\n",
       "   Tree(Lemma('known.a.01.known'), ['known']),\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('national.a.01.national'), ['national']),\n",
       "   Tree(Lemma('political.a.01.political'), ['political']),\n",
       "   Tree(Lemma('significance.n.01.significance'), ['significance']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   Tree(Lemma('dearly.r.01.dearly'), ['Dearly']),\n",
       "   Tree(Lemma('beloved.s.01.beloved'), ['beloved']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   ['he'],\n",
       "   Tree(Lemma('preach.v.01.preach'), ['preached']),\n",
       "   [','],\n",
       "   ['``'],\n",
       "   ['unless'],\n",
       "   ['you'],\n",
       "   Tree(Lemma('repent.v.01.repent'), ['repent']),\n",
       "   ['of'],\n",
       "   ['your'],\n",
       "   Tree(Lemma('sin.n.02.sin'), ['sins']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree('measure.n.00', ['measure']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('become.v.01.become'), ['become']),\n",
       "   Tree(Lemma('convert.v.03.convert'), ['converted']),\n",
       "   ['to'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   [','],\n",
       "   ['you'],\n",
       "   ['will'],\n",
       "   [','],\n",
       "   ['I'],\n",
       "   Tree(Lemma('regret.v.04.regret'), ['regret']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('state.v.01.say'), ['say']),\n",
       "   [','],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   Tree(Lemma('cursed.s.02.damned'), ['damned']),\n",
       "   ['to'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('approximately.r.01.more_or_less'), ['more', 'or', 'less']),\n",
       "   Tree(Lemma('extent.n.02.extent'), ['extent']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('true.a.01.true'), ['true']),\n",
       "   [','],\n",
       "   ['that'],\n",
       "   Tree(Lemma('nothing.n.01.nothing'), ['nothing']),\n",
       "   ['has'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('determine.v.01.find'), ['found']),\n",
       "   Tree(Lemma('comparable_with.s.01.comparable_with'), ['comparable', 'with']),\n",
       "   Tree(Lemma('electricity.n.01.electricity'), ['electricity']),\n",
       "   ['by'],\n",
       "   ['communication'],\n",
       "   [';'],\n",
       "   ['but'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('phenomenon.n.01.phenomenon'), ['phenomena']),\n",
       "   Tree(Lemma('detect.v.01.observe'), ['observed']),\n",
       "   Tree(Lemma('have.v.02.have'), ['had']),\n",
       "   Tree('such.s.00', ['such']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree('analogy.n.00', ['analogy']),\n",
       "   ['to'],\n",
       "   ['those'],\n",
       "   Tree(Lemma('contingent.s.02.depending_on'), ['depending', 'on']),\n",
       "   Tree(Lemma('electrical.a.01.electrical'), ['electrical']),\n",
       "   Tree(Lemma('distribution.n.02.distribution'), ['distribution']),\n",
       "   ['that'],\n",
       "   ['one'],\n",
       "   ['could'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('detect.v.01.find'), ['find']),\n",
       "   ['the'],\n",
       "   Tree('slightest.s.00', ['slightest']),\n",
       "   Tree(Lemma('difference.n.01.difference'), ['difference']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('continuance.n.01.continuation'), ['continuation']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('expansion.n.01.expansion'), ['expansion']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('shooting.n.01.shooting'), ['shooting']),\n",
       "   Tree(Lemma('development.n.01.development'), ['development']),\n",
       "   Tree(Lemma('plan.n.01.program'), ['program']),\n",
       "   ['will'],\n",
       "   Tree(Lemma('guarantee.v.02.assure'), ['assure']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('some.a.01.some'), ['some']),\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('national.a.01.national'), ['national']),\n",
       "   ['and'],\n",
       "   Tree('community.s.00', ['community']),\n",
       "   Tree(Lemma('leadership.n.02.leaders'), ['leaders']),\n",
       "   ['will'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('make.v.02.make'), ['made']),\n",
       "   Tree(Lemma('aware.a.01.aware'), ['aware']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('ever.r.03.ever'), ['ever']),\n",
       "   Tree('growing.s.00', ['growing']),\n",
       "   Tree(Lemma('need.n.01.need'), ['need']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('shooting.n.01.shooting'), ['shooting']),\n",
       "   Tree(Lemma('facility.n.01.facility'), ['facilities']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('activity.n.01.activity'), ['activities']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('hunt.n.08.hunting'), ['hunting']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('shooting.n.01.shooting'), ['shooting']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('answer.n.01.answer'), ['answer']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('public.s.02.public'), ['public']),\n",
       "   Tree(Lemma('demand.n.01.demand'), ['demand']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('land.n.02.soil'), ['Soil']),\n",
       "   Tree(Lemma('type.n.01.type'), ['type']),\n",
       "   [','],\n",
       "   Tree(Lemma('drain.n.01.drainage'), ['drainage']),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('slope.n.01.slope'), ['slope']),\n",
       "   ['can'],\n",
       "   Tree(Lemma('make.v.01.make'), ['make']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('difference.n.01.difference'), ['difference']),\n",
       "   ['between'],\n",
       "   Tree(Lemma('good.a.01.good'), ['good']),\n",
       "   Tree(Lemma('crop.n.01.crop'), ['crops']),\n",
       "   ['and'],\n",
       "   Tree('poor.s.00', ['poor']),\n",
       "   ['ones'],\n",
       "   ['.']],\n",
       "  [['This'],\n",
       "   Tree(Lemma('entail.v.01.mean'), ['means']),\n",
       "   ['that'],\n",
       "   Tree('such.s.00', ['such']),\n",
       "   Tree(Lemma('factor.n.01.factor'), ['factors']),\n",
       "   ['as'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('health.n.01.health'), ['health']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('parent.n.01.parent'), ['parents']),\n",
       "   [','],\n",
       "   Tree(Lemma('particularly.r.01.particularly'), ['particularly']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('mother.n.01.mother'), ['mother']),\n",
       "   [','],\n",
       "   ['their'],\n",
       "   Tree(Lemma('ability.n.01.ability'), ['ability']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('provide.v.02.provide'), ['provide']),\n",
       "   ['their'],\n",
       "   Tree(Lemma('child.n.02.child'), ['children']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('necessity.n.02.necessity'), ['necessities']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('life.n.02.life'), ['life']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('population.n.02.population'), ['population']),\n",
       "   Tree(Lemma('density.n.01.density'), ['density']),\n",
       "   ['of'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('state.n.04.country'), ['country']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('deficit.n.01.shortage'), ['shortage']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('housing.n.01.housing'), ['housing']),\n",
       "   Tree(Lemma('facility.n.01.facility'), ['facilities']),\n",
       "   ['may'],\n",
       "   Tree(Lemma('legitimately.r.01.legitimately'), ['legitimately']),\n",
       "   ['be'],\n",
       "   Tree(Lemma('assume.v.03.take'), ['taken']),\n",
       "   ['into'],\n",
       "   Tree(Lemma('consideration.n.01.consideration'), ['consideration']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('decide.v.01.determine'), ['determining']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('number.n.02.number'), ['number']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('offspring.n.01.offspring'), ['offspring']),\n",
       "   ['.']],\n",
       "  [['Many', 'of'],\n",
       "   ['them'],\n",
       "   Tree(Lemma('sincerely.r.01.sincerely'), ['sincerely']),\n",
       "   Tree(Lemma('believe.v.01.believe'), ['believe']),\n",
       "   ['that'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('use.n.01.use'), ['use']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('liquor.n.01.liquor'), ['liquor']),\n",
       "   ['in'],\n",
       "   ['any'],\n",
       "   Tree(Lemma('kind.n.01.form'), ['form']),\n",
       "   ['or'],\n",
       "   ['in'],\n",
       "   ['any'],\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('intrinsically.r.01.intrinsically'), ['intrinsically']),\n",
       "   Tree('evil.s.00', ['evil']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('iniquitous.s.01.sinful'), ['sinful']),\n",
       "   ['.']],\n",
       "  [['After'],\n",
       "   Tree(Lemma('merely.r.01.only'), ['only']),\n",
       "   Tree(Lemma('eighteen.s.01.eighteen'), ['eighteen']),\n",
       "   Tree(Lemma('year.n.01.year'), ['years']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('nonintervention.n.01.noninterference'), ['non-interference']),\n",
       "   [','],\n",
       "   ['there'],\n",
       "   ['were'],\n",
       "   Tree(Lemma('already.r.01.already'), ['already']),\n",
       "   Tree(Lemma('indication.n.01.indication'), ['indications']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('amelioration.n.01.melioration'), ['melioration']),\n",
       "   [','],\n",
       "   ['though'],\n",
       "   ['``'],\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree('slight.s.00', ['slight']),\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   Tree(Lemma('to_be_sure.r.01.to_be_sure'), ['to', 'be', 'sure']),\n",
       "   ['.']],\n",
       "  [['What'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('american.a.01.American'), ['American']),\n",
       "   Tree(Lemma('citizenry.n.01.people'), ['people']),\n",
       "   ['will'],\n",
       "   Tree(Lemma('make.v.01.do'), ['do']),\n",
       "   Tree(Lemma('depend_on.v.01.turn_on'), ['turns']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('large.a.01.large'), ['large']),\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['on'],\n",
       "   ['their'],\n",
       "   Tree(Lemma('leadership.n.02.leadership'), ['leadership']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('increase.n.02.increase'), ['increase']),\n",
       "   Tree(Lemma('stem.v.01.stem'), ['stems']),\n",
       "   Tree(Lemma('largely.r.01.largely'), ['largely']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('grow.v.02.grow'), ['growing']),\n",
       "   Tree(Lemma('complexity.n.01.complexity'), ['complexity']),\n",
       "   ['of'],\n",
       "   ['and'],\n",
       "   Tree(Lemma('higher.s.01.higher'), ['higher']),\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('care.n.06.maintenance'), ['maintenance']),\n",
       "   Tree(Lemma('needed.s.01.required'), ['required']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('new.a.01.new'), ['newer']),\n",
       "   Tree(Lemma('weapon.n.01.weapon'), ['weapons']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('equipment.n.01.equipment'), ['equipment']),\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   ['would'],\n",
       "   ['have'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('desirable.a.01.desirable'), ['desirable']),\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('two.s.01.two'), ['two']),\n",
       "   Tree(Lemma('community.n.01.community'), ['communities']),\n",
       "   ['to'],\n",
       "   ['have'],\n",
       "   Tree(Lemma('differ.v.01.differ'), ['differed']),\n",
       "   Tree(Lemma('entirely.r.02.only'), ['only']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('respect.n.01.respect'), ['respect']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('variable.n.01.variable'), ['variable']),\n",
       "   ['being'],\n",
       "   Tree(Lemma('investigate.v.01.investigate'), ['investigated']),\n",
       "   [':'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('structure.n.03.structure'), ['structure']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('teaching_method.n.01.teaching_method'), ['teaching', 'method']),\n",
       "   ['.']],\n",
       "  [['There'],\n",
       "   ['is'],\n",
       "   Tree(Lemma('much.a.01.much'), ['much']),\n",
       "   Tree(Lemma('research.n.01.research'), ['research']),\n",
       "   Tree(Lemma('evidence.n.01.evidence'), ['evidence']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('validate.v.02.validate'), ['validate']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('use.n.01.use'), ['use']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('instrument.n.01.instrument'), ['instrument']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('distinguish.v.01.differentiate'), ['differentiating']),\n",
       "   Tree(Lemma('person.n.01.individual'), ['individuals']),\n",
       "   ['who'],\n",
       "   Tree(Lemma('be.v.01.be'), ['are']),\n",
       "   Tree(Lemma('likely.a.01.likely'), ['likely']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('attest.v.01.manifest'), ['manifest']),\n",
       "   Tree(Lemma('anxiety.n.01.anxiety'), ['anxiety']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('varying.s.01.varying'), ['varying']),\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degrees']),\n",
       "   ['.']],\n",
       "  [['When'],\n",
       "   Tree(Lemma('help.v.01.help'), ['helped']),\n",
       "   ['by'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('high.a.01.high'), ['high']),\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('structure.n.03.structure'), ['structure']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('lesson.n.01.lesson'), ['lesson']),\n",
       "   Tree(Lemma('presentation.n.01.presentation'), ['presentation']),\n",
       "   [','],\n",
       "   Tree(Lemma('then.r.03.then'), ['then']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('entirely.r.02.only'), ['only']),\n",
       "   Tree(Lemma('then.r.03.then'), ['then']),\n",
       "   [','],\n",
       "   ['does'],\n",
       "   Tree('such.s.00', ['such']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('child.n.01.child'), ['child']),\n",
       "   Tree(Lemma('achieve.v.01.attain'), ['attain']),\n",
       "   Tree(Lemma('unusual.a.01.unusual'), ['unusual']),\n",
       "   Tree(Lemma('success.n.02.success'), ['success']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('difficulty.n.04.difficulty'), ['difficulty']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('analysis.n.01.analysis'), ['analysis']),\n",
       "   ['of'],\n",
       "   ['any'],\n",
       "   Tree(Lemma('subsystem.n.01.subsystem'), ['subsystem']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('phonology.n.01.phonology'), ['phonology']),\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['an'],\n",
       "   Tree(Lemma('inverse_function.n.01.inverse_function'), ['inverse', 'function']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('size.n.01.size'), ['size']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('smaller.s.01.smaller'), ['smaller']),\n",
       "   Tree(Lemma('system.n.02.system'), ['systems']),\n",
       "   Tree(Lemma('be.v.01.be'), ['are']),\n",
       "   Tree(Lemma('more.r.01.more'), ['more']),\n",
       "   Tree(Lemma('troublesome.s.01.troublesome'), ['troublesome']),\n",
       "   ['-'],\n",
       "   ['for'],\n",
       "   ['any'],\n",
       "   Tree('given.s.00', ['given']),\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('morphophonemic.a.01.morphophonemic'), ['morphophonemic']),\n",
       "   Tree(Lemma('complexity.n.01.complexity'), ['complexity']),\n",
       "   ['.']],\n",
       "  [['An'],\n",
       "   Tree(Lemma('elephant.n.01.elephant'), ['elephant']),\n",
       "   ['or'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('fox.n.01.fox'), ['fox']),\n",
       "   ['or'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('swan.n.01.swan'), ['swan']),\n",
       "   ['or'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('coconut.n.03.coco_palm'), ['cocopalm']),\n",
       "   ['or'],\n",
       "   ['a'],\n",
       "   Tree('banana.n.2;1', ['banana']),\n",
       "   Tree(Lemma('possess.v.01.possess'), ['possess']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('unusually.r.01.unusually'), ['unusually']),\n",
       "   Tree(Lemma('high.a.01.high'), ['high']),\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['this'],\n",
       "   Tree(Lemma('quality.n.03.quality'), ['quality']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('obvious.a.01.obvious'), ['obvious']),\n",
       "   [','],\n",
       "   Tree(Lemma('commonsense.s.01.commonsense'), ['common-sense']),\n",
       "   [','],\n",
       "   Tree(Lemma('beyond_doubt.s.01.indubitable'), ['indubitable']),\n",
       "   Tree(Lemma('identity.n.02.identity'), ['identity']),\n",
       "   [','],\n",
       "   ['as'],\n",
       "   Tree(Lemma('suffice.v.01.do'), ['do']),\n",
       "   ['an'],\n",
       "   Tree(Lemma('eye.n.01.eye'), ['eye']),\n",
       "   ['or'],\n",
       "   Tree('tooth.n.3;1', ['tooth']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('nail.n.01.nail'), ['nail']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('outrageousness.n.02.enormity'), ['enormity']),\n",
       "   ['of'],\n",
       "   ['what'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Conrad'])]),\n",
       "   ['had'],\n",
       "   Tree(Lemma('tell.v.02.tell'), ['told']),\n",
       "   ['him'],\n",
       "   Tree(Lemma('make.v.02.make'), ['made']),\n",
       "   ['it'],\n",
       "   Tree(Lemma('impossible.a.01.impossible'), ['impossible']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Gilborn'])]),\n",
       "   ['to'],\n",
       "   Tree(Lemma('accept.v.01.accept'), ['accept']),\n",
       "   [','],\n",
       "   ['with'],\n",
       "   ['any'],\n",
       "   Tree(Lemma('degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('reality.n.02.realism'), ['realism']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('actuality.n.01.actuality'), ['actuality']),\n",
       "   ['of'],\n",
       "   ['it'],\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Dr.', 'Clark'])]),\n",
       "   Tree(Lemma('have.v.01.hold'), ['holds']),\n",
       "   ['an'],\n",
       "   Tree(Lemma('earned.a.01.earned'), ['earned']),\n",
       "   Tree(Lemma('doctor_of_education.n.01.Doctor_of_Education'), ['Doctor', 'of', 'Education']),\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degree']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['University', 'of', 'Oklahoma'])]),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('besides.r.02.also'), ['also']),\n",
       "   Tree(Lemma('receive.v.01.receive'), ['received']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('master_of_science.n.01.Master_of_Science'), ['Master', 'of', 'Science']),\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degree']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Texas', 'A+I', 'College'])]),\n",
       "   ['and'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('bachelor_of_science.n.01.Bachelor_of_Science'), ['Bachelor', 'of', 'Science']),\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degree']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Southwestern', 'State', 'College'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Weatherford'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Okla.'])]),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('besides.r.02.also'), ['also']),\n",
       "   Tree(Lemma('receive.v.01.receive'), ['received']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('master_of_science.n.01.Master_of_Science'), ['Master', 'of', 'Science']),\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degree']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Texas', 'A+I', 'College'])]),\n",
       "   ['and'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('bachelor_of_science.n.01.Bachelor_of_Science'), ['Bachelor', 'of', 'Science']),\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degree']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Southwestern', 'State', 'College'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Weatherford'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Okla.'])]),\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   Tree(Lemma('all.a.01.all'), ['all']),\n",
       "   ['``'],\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degree']),\n",
       "   [\"''\"],\n",
       "   Tree(Lemma('course.n.01.course'), ['courses']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('interior_decoration.n.02.interior_design'), ['interior', 'design']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('number.n.01.number'), ['number']),\n",
       "   ['of'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('academic.a.01.academic'), ['academic']),\n",
       "   [\"''\"],\n",
       "   ['or'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('general.a.01.general'), ['general']),\n",
       "   Tree(Lemma('discipline.n.01.study'), ['studies']),\n",
       "   [\"''\"],\n",
       "   Tree(Lemma('course.n.01.course'), ['courses']),\n",
       "   ['are'],\n",
       "   Tree(Lemma('include.v.01.include'), ['included']),\n",
       "   ['.']],\n",
       "  [['For'],\n",
       "   Tree(Lemma('proper.a.01.proper'), ['proper']),\n",
       "   Tree(Lemma('accreditation.n.01.accreditation'), ['accreditation']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('school.n.01.school'), ['schools']),\n",
       "   [','],\n",
       "   Tree(Lemma('teacher.n.01.teacher'), ['teachers']),\n",
       "   ['in'],\n",
       "   ['any'],\n",
       "   Tree(Lemma('course.n.01.course'), ['course']),\n",
       "   ['must'],\n",
       "   Tree(Lemma('have.v.01.have'), ['have']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degree']),\n",
       "   Tree(Lemma('at_least.r.02.at_least'), ['at', 'least']),\n",
       "   Tree(Lemma('one.s.01.one'), ['one']),\n",
       "   Tree(Lemma('grade.n.02.level'), ['level']),\n",
       "   ['above'],\n",
       "   ['that'],\n",
       "   ['for'],\n",
       "   ['which'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('student.n.01.student'), ['student']),\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('candidate.n.02.candidate'), ['candidate']),\n",
       "   ['.']],\n",
       "  [['Indeed'],\n",
       "   [','],\n",
       "   ['it'],\n",
       "   ['has'],\n",
       "   Tree(Lemma('merely.r.01.only'), ['only']),\n",
       "   Tree(Lemma('be.v.01.be'), ['been']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('topic.n.02.matter'), ['matter']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('last.s.01.last'), ['last']),\n",
       "   Tree(Lemma('few.a.01.few'), ['few']),\n",
       "   Tree(Lemma('year.n.01.year'), ['years']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('reputable.a.01.reputable'), ['reputable']),\n",
       "   Tree(Lemma('school.n.01.school'), ['schools']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('art.n.02.art'), ['art']),\n",
       "   ['have'],\n",
       "   Tree(Lemma('award.v.02.grant'), ['granted']),\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degrees']),\n",
       "   Tree(Lemma('at_all.r.01.at_all'), ['at', 'all']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('basic.a.01.basic'), ['basic']),\n",
       "   Tree(Lemma('problem.n.01.problem'), ['problem']),\n",
       "   Tree(Lemma('involve.v.01.involve'), ['involved']),\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['that'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('college.n.01.college'), ['college']),\n",
       "   Tree(Lemma('establish.v.01.set_up'), ['setting', 'up']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('graduate_school.n.01.graduate_school'), ['graduate', 'school']),\n",
       "   ['must'],\n",
       "   Tree(Lemma('have.v.01.have'), ['have']),\n",
       "   ['an'],\n",
       "   Tree(Lemma('wholly.r.01.entirely'), ['entirely']),\n",
       "   Tree(Lemma('separate.a.01.separate'), ['separate']),\n",
       "   Tree(Lemma('staff.n.03.faculty'), ['faculty']),\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('advanced.s.04.advanced'), ['advanced']),\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degree']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('most.a.01.most'), ['Most']),\n",
       "   Tree(Lemma('professor.n.01.professor'), ['professors']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('course.n.01.course'), ['course']),\n",
       "   ['must'],\n",
       "   [','],\n",
       "   Tree(Lemma('naturally.r.01.naturally'), ['naturally']),\n",
       "   [','],\n",
       "   Tree(Lemma('again.r.01.again'), ['again']),\n",
       "   Tree(Lemma('have.v.01.have'), ['have']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('high.a.01.high'), ['higher']),\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degree']),\n",
       "   ['than'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('course.n.01.course'), ['course']),\n",
       "   Tree(Lemma('offer.v.01.offer'), ['offers']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('one.s.01.one'), ['One']),\n",
       "   Tree(Lemma('solution.n.02.solution'), ['solution']),\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('acquisition.n.01.acquisition'), ['acquisition']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degrees']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('education.n.04.education'), ['education']),\n",
       "   ['but'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   ['a'],\n",
       "   Tree('poor.s.00', ['poor']),\n",
       "   Tree(Lemma('substitute.n.01.substitute'), ['substitute']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('independent.a.01.independent'), ['Independent']),\n",
       "   Tree(Lemma('art_school.n.01.art_school'), ['art', 'schools']),\n",
       "   Tree(Lemma('award.v.02.grant'), ['granting']),\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degrees']),\n",
       "   ['must'],\n",
       "   [','],\n",
       "   Tree(Lemma('naturally.r.01.naturally'), ['naturally']),\n",
       "   [','],\n",
       "   Tree(Lemma('follow.v.10.follow'), ['follow']),\n",
       "   ['this'],\n",
       "   ['with'],\n",
       "   Tree(Lemma('academic.a.01.academic'), ['academic']),\n",
       "   Tree(Lemma('accreditation.n.01.accreditation'), ['accreditation']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('appropriate.a.01.appropriate'), ['appropriate']),\n",
       "   Tree(Lemma('regional.a.01.regional'), ['regional']),\n",
       "   Tree(Lemma('group.n.01.group'), ['group']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('complete.v.01.complete'), ['completed']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('training.n.01.training'), ['training']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('pharmacy.n.01.pharmacy'), ['pharmacy']),\n",
       "   Tree(Lemma('besides.r.02.also'), ['also']),\n",
       "   [','],\n",
       "   Tree(Lemma('accept.v.02.take'), ['taking']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degree']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('high.a.01.high'), ['high']),\n",
       "   Tree(Lemma('award.n.02.honor'), ['honors']),\n",
       "   ['in'],\n",
       "   ['1797'],\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['in'],\n",
       "   ['1799'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('award.v.01.award'), ['awarded']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('doctor_of_philosophy.n.01.Doctor_of_Philosophy'), ['Doctor', 'of', 'Philosophy']),\n",
       "   ['along'],\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('prize.n.01.prize'), ['prize']),\n",
       "   ['for'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('essay.n.01.essay'), ['essay']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('medicine.n.01.medicine'), ['medicine']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('complete.v.01.complete'), ['completed']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('training.n.01.training'), ['training']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('pharmacy.n.01.pharmacy'), ['pharmacy']),\n",
       "   Tree(Lemma('besides.r.02.also'), ['also']),\n",
       "   [','],\n",
       "   Tree(Lemma('accept.v.02.take'), ['taking']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degree']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('high.a.01.high'), ['high']),\n",
       "   Tree(Lemma('award.n.02.honor'), ['honors']),\n",
       "   ['in'],\n",
       "   ['1797'],\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['in'],\n",
       "   ['1799'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('award.v.01.award'), ['awarded']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degree']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('doctor_of_philosophy.n.01.Doctor_of_Philosophy'), ['Doctor', 'of', 'Philosophy']),\n",
       "   ['along'],\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('prize.n.01.prize'), ['prize']),\n",
       "   ['for'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('essay.n.01.essay'), ['essay']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('medicine.n.01.medicine'), ['medicine']),\n",
       "   ['.']],\n",
       "  [['On'],\n",
       "   Tree(Lemma('december.n.01.December'), ['December']),\n",
       "   Tree(Lemma('ninth.n.01.ninth'), ['9']),\n",
       "   [','],\n",
       "   ['1862'],\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Sergeant', 'Edwin', 'H.', 'Fay'])]),\n",
       "   [','],\n",
       "   ['an'],\n",
       "   Tree(Lemma('unusual.a.01.unusual'), ['unusual']),\n",
       "   Tree(Lemma('louisianan.n.01.Louisianan'), ['Louisianan']),\n",
       "   ['who'],\n",
       "   Tree(Lemma('have.v.01.hold'), ['held']),\n",
       "   Tree(Lemma('bachelor_of_arts.n.01.AB'), ['A.', 'B.']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('master_of_arts.n.01.MA'), ['M.', 'A.']),\n",
       "   Tree(Lemma('academic_degree.n.01.degree'), ['degrees']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('harvard_university.n.01.Harvard_University'), ['Harvard', 'University']),\n",
       "   ['and'],\n",
       "   ['who'],\n",
       "   ['before'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('war.n.02.war'), ['war']),\n",
       "   Tree(Lemma('be.v.02.be'), ['was']),\n",
       "   Tree(Lemma('headmaster.n.01.headmaster'), ['headmaster']),\n",
       "   ['of'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('private_school.n.01.private_school'), ['private', 'school']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('male_child.n.01.boy'), ['boys']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('louisiana.n.01.Louisiana'), ['Louisiana']),\n",
       "   [','],\n",
       "   Tree(Lemma('write.v.02.write'), ['wrote']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('wife.n.01.wife'), ['wife']),\n",
       "   [':']],\n",
       "  [Tree(Lemma('assay.n.01.check'), ['Check']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('elevation.n.03.elevation'), ['elevation']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('land.n.04.ground'), ['ground']),\n",
       "   [','],\n",
       "   Tree(Lemma('degree.n.04.degree'), ['degree']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('direction.n.02.direction'), ['direction']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('slope.n.01.slope'), ['slopes']),\n",
       "   [','],\n",
       "   Tree(Lemma('drain.n.01.drainage'), ['drainage']),\n",
       "   [','],\n",
       "   Tree(Lemma('outcrop.n.01.rock_outcrop'), ['rock', 'outcrops']),\n",
       "   [','],\n",
       "   Tree(Lemma('topsoil.n.01.topsoil'), ['topsoil']),\n",
       "   Tree(Lemma('type.n.01.type'), ['types']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('quality.n.01.quality'), ['quality']),\n",
       "   [','],\n",
       "   ['as', 'well', 'as'],\n",
       "   Tree(Lemma('subsoil.n.01.subsoil'), ['subsoil']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('consequence.n.01.result'), ['result']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('observation.n.01.observation'), ['observations']),\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['('],\n",
       "   ['in'],\n",
       "   ['`'],\n",
       "   Tree(Lemma('kelvin.n.01.K'), ['K']),\n",
       "   [')'],\n",
       "   ['**f'],\n",
       "   ['where'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('phase.n.01.phase'), ['phase']),\n",
       "   Tree(Lemma('angle.n.01.angle'), ['angle']),\n",
       "   [','],\n",
       "   ['|qt'],\n",
       "   [','],\n",
       "   ['is'],\n",
       "   Tree(Lemma('measure.v.03.measure'), ['measured']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('degree.n.04.degree'), ['degrees']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('new_moon.n.01.new_moon'), ['new', 'moon']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('probable.s.02.probable'), ['probable']),\n",
       "   Tree(Lemma('erroneousness.n.01.error'), ['errors']),\n",
       "   Tree(Lemma('include.v.01.include'), ['include']),\n",
       "   Tree(Lemma('absolute.a.01.absolute'), ['absolute']),\n",
       "   ['as', 'well', 'as'],\n",
       "   Tree(Lemma('relative.a.01.relative'), ['relative']),\n",
       "   Tree(Lemma('erroneousness.n.01.error'), ['errors']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('transducer.n.01.transducer'), ['transducer']),\n",
       "   ['itself'],\n",
       "   Tree(Lemma('move.v.02.move'), ['moves']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('beam.n.03.beam'), ['beam']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('sector.n.01.sector'), ['sector']),\n",
       "   Tree(Lemma('scan.n.01.scan'), ['scan']),\n",
       "   [','],\n",
       "   Tree(Lemma('precisely.r.01.just'), ['just']),\n",
       "   ['like'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('radar.n.01.radar'), ['radar']),\n",
       "   Tree(Lemma('antenna.n.01.antenna'), ['antenna']),\n",
       "   [','],\n",
       "   ['while'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('entire.s.01.entire'), ['entire']),\n",
       "   Tree(Lemma('transducer.n.01.transducer'), ['transducer']),\n",
       "   Tree(Lemma('structure.n.01.structure'), ['structure']),\n",
       "   ['is'],\n",
       "   Tree(Lemma('move.v.02.move'), ['moved']),\n",
       "   ['over'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('ninety.s.01.90'), ['90']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('degree.n.04.degree'), ['degree']),\n",
       "   Tree(Lemma('arc.n.02.arc'), ['arc']),\n",
       "   ['in', 'front', 'of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('eye.n.01.eye'), ['eye']),\n",
       "   ['to'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('investigate.v.01.look_into'), ['look', 'into']),\n",
       "   [\"''\"],\n",
       "   ['all'],\n",
       "   Tree(Lemma('corner.n.05.corner'), ['corners']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('entire.s.01.total'), ['total']),\n",
       "   Tree(Lemma('video.n.01.picture'), ['picture']),\n",
       "   ['is'],\n",
       "   Tree(Lemma('entirely.r.02.only'), ['only']),\n",
       "   Tree(Lemma('see.v.01.see'), ['seen']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('television_camera.n.01.camera'), ['camera']),\n",
       "   ['which'],\n",
       "   Tree(Lemma('integrate.v.01.integrate'), ['integrates']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('many.a.01.many'), ['many']),\n",
       "   Tree(Lemma('sector.n.01.sector'), ['sector']),\n",
       "   Tree(Lemma('scan.n.01.scan'), ['scans']),\n",
       "   ['over'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('entire.s.01.entire'), ['entire']),\n",
       "   Tree(Lemma('ninety.s.01.90'), ['90']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('degree.n.04.degree'), ['degree']),\n",
       "   Tree(Lemma('rotation.n.01.rotation'), ['rotation']),\n",
       "   Tree(Lemma('period.n.02.period'), ['period']),\n",
       "   ['.']],\n",
       "  [['Within'],\n",
       "   ['about'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('hour.n.01.hour'), ['hour']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('aid.n.02.help'), ['help']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('report.n.02.report'), ['reports']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('seismic.s.01.seismic'), ['seismic']),\n",
       "   Tree(Lemma('station.n.01.station'), ['stations']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('alaska.n.01.Alaska'), ['Alaska']),\n",
       "   [','],\n",
       "   Tree(Lemma('arizona.n.01.Arizona'), ['Arizona']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('california.n.01.California'), ['California']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('earthquake.n.01.quake'), ['quake']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('epicenter.n.01.epicenter'), ['epicenter']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('place.v.11.place'), ['placed']),\n",
       "   ['at'],\n",
       "   ['51'],\n",
       "   Tree(Lemma('degree.n.04.degree'), ['degrees']),\n",
       "   Tree(Lemma('north.n.03.north'), ['North']),\n",
       "   Tree(Lemma('latitude.n.01.latitude'), ['latitude']),\n",
       "   ['and'],\n",
       "   ['158'],\n",
       "   Tree(Lemma('degree.n.04.degree'), ['degrees']),\n",
       "   Tree(Lemma('east.n.01.east'), ['East']),\n",
       "   Tree(Lemma('longitude.n.01.longitude'), ['longitude']),\n",
       "   ['.']],\n",
       "  [['Within'],\n",
       "   ['about'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('hour.n.01.hour'), ['hour']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('aid.n.02.help'), ['help']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('report.n.02.report'), ['reports']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('seismic.s.01.seismic'), ['seismic']),\n",
       "   Tree(Lemma('station.n.01.station'), ['stations']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('alaska.n.01.Alaska'), ['Alaska']),\n",
       "   [','],\n",
       "   Tree(Lemma('arizona.n.01.Arizona'), ['Arizona']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('california.n.01.California'), ['California']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('earthquake.n.01.quake'), ['quake']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('epicenter.n.01.epicenter'), ['epicenter']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('place.v.11.place'), ['placed']),\n",
       "   ['at'],\n",
       "   ['51'],\n",
       "   Tree(Lemma('degree.n.04.degree'), ['degrees']),\n",
       "   Tree(Lemma('north.n.03.north'), ['North']),\n",
       "   Tree(Lemma('latitude.n.01.latitude'), ['latitude']),\n",
       "   ['and'],\n",
       "   ['158'],\n",
       "   Tree(Lemma('degree.n.04.degree'), ['degrees']),\n",
       "   Tree(Lemma('east.n.01.east'), ['East']),\n",
       "   Tree(Lemma('longitude.n.01.longitude'), ['longitude']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('valley.n.01.valley'), ['valley']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('merely.r.01.only'), ['only']),\n",
       "   Tree(Lemma('a_few.s.01.a_few'), ['a', 'few']),\n",
       "   Tree(Lemma('hundred.s.01.hundred'), ['hundred']),\n",
       "   Tree(Lemma('yard.n.01.yard'), ['yards']),\n",
       "   Tree(Lemma('wide.a.01.wide'), ['wide']),\n",
       "   ['with'],\n",
       "   Tree('just_about.r.00', ['just', 'about']),\n",
       "   Tree(Lemma('room.n.02.room'), ['room']),\n",
       "   Tree(Lemma('adequate.s.02.enough'), ['enough']),\n",
       "   ['for'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('properly.r.01.properly'), ['properly']),\n",
       "   Tree(Lemma('perform.v.01.perform'), ['performed']),\n",
       "   ['hundred-and-eighty'],\n",
       "   Tree(Lemma('degree.n.04.degree'), ['degree']),\n",
       "   Tree(Lemma('turn.n.06.turn'), ['turn']),\n",
       "   ['.']],\n",
       "  [['Despite'],\n",
       "   ['the'],\n",
       "   ['45'],\n",
       "   ['-'],\n",
       "   Tree(Lemma('degree.n.06.degree'), ['degree']),\n",
       "   Tree(Lemma('weather.n.01.weather'), ['weather']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('game.n.01.game'), ['game']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('click_off.v.01.click_off'), ['clicked', 'off']),\n",
       "   ['in'],\n",
       "   ['1'],\n",
       "   [':'],\n",
       "   ['48'],\n",
       "   [','],\n",
       "   Tree(Lemma('thanks.n.01.thanks'), ['thanks']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('merely.r.01.only'), ['only']),\n",
       "   Tree(Lemma('three.s.01.three'), ['three']),\n",
       "   Tree(Lemma('base_on_balls.n.01.base_on_balls'), ['bases', 'on', 'balls']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('some.a.01.some'), ['some']),\n",
       "   Tree(Lemma('good.a.01.good'), ['good']),\n",
       "   Tree(Lemma('baseball_diamond.n.01.infield'), ['infield']),\n",
       "   Tree(Lemma('maneuver.n.03.play'), ['play']),\n",
       "   ['.']]],\n",
       " [6, 23, 46, 59, 66, 67])"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_word_data('degree', 'n')\n",
    "sel.get_selected_sense_sents(sel.get_senses_for_curr_word())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senses for word model.n\n",
      "Number of sentences for sense Synset('exemplar.n.01') 3\n",
      "Number of sentences for sense Synset('model.n.03') 6\n",
      "Number of sentences for sense Synset('model.n.04') 4\n",
      "Number of sentences for sense Synset('model.n.07') 1\n",
      "Number of sentences for sense Synset('model.n.02') 11\n",
      "Number of sentences for sense Synset('model.n.06') 1\n",
      "Number of sentences for sense Synset('model.n.01') 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['The Glazer-Fine Arts edition ( Concert-Disc ) is a model of lucidity and organization .',\n",
       "  'We shall not be able entirely to pass over these connections to the East as we consider Ripe Geometric pottery , the epic and the myth , and the religious evolution of early Greece ; the important point , however , is that these magnificent achievements , unlike those of later decades , were only incidentally influenced by Oriental models .',\n",
       "  'The Brooklyn College student shows some striking departures from prevailing collegiate models .',\n",
       "  \"`` What kind of models would you prefer '' ?\",\n",
       "  'His first model arrived at dusk .',\n",
       "  'The model quite plainly thought Michelangelo crazy ; only the instructions from his rabbi kept him from bolting .',\n",
       "  'But at the end of the sitting , when Michelangelo showed him the quick , free drawings , with the mother roughed in , holding her son , the model grasped what Michelangelo was after , and promised to speak to his friends .',\n",
       "  'He worked for two hours a day with each model sent by the rabbi .',\n",
       "  \"I asked Quasimodo recently how he accomplished this , and he replied that he had painted his model `` a beautiful shade of red and then had her breathe on the canvas '' , which was his typical tongue-in-cheek way of chiding me for my lack of sensitivity .\",\n",
       "  'Yet he never allowed these models to become fixed in his mind ; they remained rough starting points .',\n",
       "  'When carving he was charged with spontaneous energy ; too careful or detailed studies in clay and wax would have glued him down to a mere enlarging of his model .',\n",
       "  'Drawing and models were his thinking .',\n",
       "  'Everywhere else his ideas lay or hung in visible form : his models , drawings , ten foot canvases in monochromes from his painting days , and underfoot a windfall of broken-backed books that looked as though their insides had been ransacked by a maniac .',\n",
       "  'Eichmann himself is a model of how the myth of the enemy Jew can be used to transform the ordinary man of present-day society into a menace to all his neighbors .',\n",
       "  \"When she said that she did n't have the money , he said that she could come in for treatment with his office model until she was ready to buy one .\",\n",
       "  'Figures 1 to 3 show photographic and schematic views of the test stand and of two different models of the anode holder .',\n",
       "  'Two pyrometers shown in figure 1 and 2 ( Pyrometer Instrument Co. Model 95 ) served for simultaneous measurement of the anode surface temperature and the temperature distribution along the anode holder .',\n",
       "  'The magnetic resonance absorption was detected by employing a Varian model **f broad line spectrometer and the associated 12 - inch electromagnet system .',\n",
       "  'One measurement at 40 Mc / sec was obtained with the Varian model **f unit .',\n",
       "  'These were read at 280 m | m in a Beckman model DU spectrophotometer and tested for antibody activity as described above .',\n",
       "  'Paper electrophoresis was carried out on the concentrated samples in a Spinco model R cell using barbital buffer , pH 8.6 , ionic strength 0.075 , at room temperature on Whatman 3 MM filter paper .',\n",
       "  'They were then centrifuged at 59780 rpm for 35 to 80 min at 20 ` C in a Spinco model E ultracentrifuge at a protein concentration of 1.00 to 1.25 % .',\n",
       "  'Ultracentrifugation was then carried out in a Spinco model L ultracentrifuge at 40000 rpm for 125 to 150 min , refrigeration being used throughout the run .',\n",
       "  \"Cardboard noisemakers , substitutes for the unavailable tin models , were being hawked and bought at makeshift stands every few yards along Broadway , and one 's ears were continually serenaded by the horns ' rasps and bleats .\",\n",
       "  'Latest models serve hot meals at reasonable prices , and at a profit to you .',\n",
       "  'The observer of television or other products for a mass audience has only a permit to be , like the models he sees , even more like everybody else .',\n",
       "  'The information provided by the electron paramagnetic effects is then discussed , and finally the nuclear effects are interpreted in terms of various motional modified models of the **f bond in **f .',\n",
       "  'We devote a chapter to the binomial distribution not only because it is a mathematical model for an enormous variety of real life phenomena , but also because it has important properties that recur in many other probability models .',\n",
       "  'We devote a chapter to the binomial distribution not only because it is a mathematical model for an enormous variety of real life phenomena , but also because it has important properties that recur in many other probability models .',\n",
       "  'On the other hand , even when the binomial model does not describe well the physical phenomenon being studied , the binomial model may still be used as a baseline for comparative purposes ; that is , we may discuss the phenomenon in terms of its departures from the binomial model .',\n",
       "  'On the other hand , even when the binomial model does not describe well the physical phenomenon being studied , the binomial model may still be used as a baseline for comparative purposes ; that is , we may discuss the phenomenon in terms of its departures from the binomial model .',\n",
       "  'On the other hand , even when the binomial model does not describe well the physical phenomenon being studied , the binomial model may still be used as a baseline for comparative purposes ; that is , we may discuss the phenomenon in terms of its departures from the binomial model .',\n",
       "  'While there may be several such industries to which the model of this paper is applicable , the authors make particular claim of relevance to the explanation of the course of wages and prices in the steel industry of the United States since World War 2 , .',\n",
       "  \"Indeed , the apparent stiffening of the industry 's attitude in the recent steel strike has a direct explanation in terms of the model here presented .\",\n",
       "  'The model of this paper considers an industry which is not characterized by vigorous price competition , but which is so basic that its wage price policies are held in check by continuous critical public scrutiny .',\n",
       "  \"In order to focus clearly upon the operation of this one force , which we may call the effect of `` public limit pricing '' on `` key '' wage bargains , we deliberately simplify the model by abstracting from other forces , such as union power , which may be relevant in an actual situation .\",\n",
       "  'For expository purposes , this is best treated as a model which spells out the conditions under which an important industry affected with the public interest would find it profitable to raise wages even in the absence of union pressures for higher wages .',\n",
       "  'Part 1 , below describes this abstract model by spelling out its assumptions .',\n",
       "  'Part 2 , discusses the operation of the model and derives some significant conclusions .',\n",
       "  'The industry with which this model is concerned is a basic industry , producing a substantial share of gross national product .',\n",
       "  'The industry of this model is so important that its wage and price policies are affected with a public interest .',\n",
       "  'For the industry of this model , the effect of such public pressures in the past has been to hold the price well below the short-run profit maximizing price ( given the wage rate and the level of GNP ) , and even below the entry limited price ( but not below average cost ) .',\n",
       "  \"In this model , we abstract from all non wage sources of cost changes , so that the `` public limit price '' only rises as the wage rate rises .\",\n",
       "  'In this model , then , the industry is presumed to realize that they could successfully resist a change in the basic wage rate , but since such a change is the only effective means to raising prices they may , in circumstances to be spelled out in Part 2 , below , find it to their advantage to allow the wage rise .',\n",
       "  'From this presumption it is an easy step to the conclusion that any observed increases in the basic wage rate must be due to union behavior different and more aggressive than assumed in our model .'],\n",
       " [[['The'],\n",
       "   Tree('NE', ['Glazer-Fine', 'Arts']),\n",
       "   Tree(Lemma('edition.n.02.edition'), ['edition']),\n",
       "   ['('],\n",
       "   Tree('NE', ['Concert-Disc']),\n",
       "   [')'],\n",
       "   Tree(Lemma('constitute.v.01.be'), ['is']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('exemplar.n.01.model'), ['model']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('clarity.n.01.lucidity'), ['lucidity']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('arrangement.n.03.organization'), ['organization']),\n",
       "   ['.']],\n",
       "  [['We'],\n",
       "   ['shall'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   Tree(Lemma('able.a.01.able'), ['able']),\n",
       "   Tree(Lemma('wholly.r.01.entirely'), ['entirely']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('jump.v.13.pass_over'), ['pass', 'over']),\n",
       "   ['these'],\n",
       "   Tree(Lemma('association.n.04.connection'), ['connections']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('east.n.02.East'), ['East']),\n",
       "   ['as'],\n",
       "   ['we'],\n",
       "   Tree(Lemma('study.v.03.consider'), ['consider']),\n",
       "   Tree('NE', ['Ripe', 'Geometric']),\n",
       "   Tree(Lemma('pottery.n.01.pottery'), ['pottery']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('epic_poem.n.01.epic'), ['epic']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('myth.n.01.myth'), ['myth']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree('religious.a.00', ['religious']),\n",
       "   Tree(Lemma('development.n.02.evolution'), ['evolution']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('early.s.03.early'), ['early']),\n",
       "   Tree(Lemma('greece.n.01.Greece'), ['Greece']),\n",
       "   [';'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('important.a.01.important'), ['important']),\n",
       "   Tree(Lemma('detail.n.01.point'), ['point']),\n",
       "   [','],\n",
       "   Tree(Lemma('however.r.01.however'), ['however']),\n",
       "   [','],\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['that'],\n",
       "   ['these'],\n",
       "   Tree(Lemma('brilliant.s.03.magnificent'), ['magnificent']),\n",
       "   Tree(Lemma('accomplishment.n.01.achievement'), ['achievements']),\n",
       "   [','],\n",
       "   Tree(Lemma('unlike.a.01.unlike'), ['unlike']),\n",
       "   ['those'],\n",
       "   ['of'],\n",
       "   Tree(Lemma('later.s.01.later'), ['later']),\n",
       "   Tree(Lemma('decade.n.01.decade'), ['decades']),\n",
       "   [','],\n",
       "   ['were'],\n",
       "   Tree(Lemma('merely.r.01.only'), ['only']),\n",
       "   Tree(Lemma('incidentally.r.02.incidentally'), ['incidentally']),\n",
       "   Tree(Lemma('determine.v.02.influence'), ['influenced']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('oriental.s.01.oriental'), ['Oriental']),\n",
       "   Tree(Lemma('exemplar.n.01.model'), ['models']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Brooklyn', 'College'])]),\n",
       "   Tree(Lemma('student.n.01.student'), ['student']),\n",
       "   Tree(Lemma('show.v.01.show'), ['shows']),\n",
       "   ['some'],\n",
       "   Tree(Lemma('dramatic.s.02.striking'), ['striking']),\n",
       "   Tree(Lemma('deviation.n.01.departure'), ['departures']),\n",
       "   ['from'],\n",
       "   Tree('prevailing.s.00', ['prevailing']),\n",
       "   Tree(Lemma('collegiate.a.01.collegiate'), ['collegiate']),\n",
       "   Tree(Lemma('exemplar.n.01.model'), ['models']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   ['What'],\n",
       "   Tree(Lemma('kind.n.01.kind'), ['kind']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('model.n.03.model'), ['models']),\n",
       "   ['would'],\n",
       "   ['you'],\n",
       "   Tree(Lemma('prefer.v.01.prefer'), ['prefer']),\n",
       "   [\"''\"],\n",
       "   ['?']],\n",
       "  [['His'],\n",
       "   Tree(Lemma('first.s.02.first'), ['first']),\n",
       "   Tree(Lemma('model.n.03.model'), ['model']),\n",
       "   Tree(Lemma('arrive.v.01.arrive'), ['arrived']),\n",
       "   ['at'],\n",
       "   Tree(Lemma('twilight.n.01.dusk'), ['dusk']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('model.n.03.model'), ['model']),\n",
       "   Tree(Lemma('quite.r.01.quite'), ['quite']),\n",
       "   Tree(Lemma('obviously.r.01.plainly'), ['plainly']),\n",
       "   Tree(Lemma('think.v.01.think'), ['thought']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Michelangelo'])]),\n",
       "   Tree(Lemma('brainsick.s.01.crazy'), ['crazy']),\n",
       "   [';'],\n",
       "   Tree(Lemma('entirely.r.02.only'), ['only']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('direction.n.06.instruction'), ['instructions']),\n",
       "   ['from'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('rabbi.n.01.rabbi'), ['rabbi']),\n",
       "   Tree(Lemma('prevent.v.02.keep'), ['kept']),\n",
       "   ['him'],\n",
       "   ['from'],\n",
       "   Tree(Lemma('bolt.v.01.bolt'), ['bolting']),\n",
       "   ['.']],\n",
       "  [['But'],\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('end.n.03.end'), ['end']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('sitting.n.01.sitting'), ['sitting']),\n",
       "   [','],\n",
       "   ['when'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Michelangelo'])]),\n",
       "   Tree(Lemma('show.v.01.show'), ['showed']),\n",
       "   ['him'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('flying.s.02.quick'), ['quick']),\n",
       "   [','],\n",
       "   Tree('free.s.00', ['free']),\n",
       "   Tree(Lemma('drawing.n.02.drawing'), ['drawings']),\n",
       "   [','],\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('mother.n.01.mother'), ['mother']),\n",
       "   Tree(Lemma('rough_in.v.01.rough'), ['roughed']),\n",
       "   ['in'],\n",
       "   [','],\n",
       "   Tree(Lemma('hold.v.02.hold'), ['holding']),\n",
       "   ['her'],\n",
       "   Tree(Lemma('son.n.01.son'), ['son']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('model.n.03.model'), ['model']),\n",
       "   Tree(Lemma('grok.v.01.grasp'), ['grasped']),\n",
       "   ['what'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Michelangelo'])]),\n",
       "   Tree(Lemma('plan.v.01.be_after'), ['was', 'after']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('promise.v.01.promise'), ['promised']),\n",
       "   ['to'],\n",
       "   Tree('speak_to.v.00', ['speak', 'to']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('friend.n.01.friend'), ['friends']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('work.v.01.work'), ['worked']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('two.s.01.two'), ['two']),\n",
       "   Tree(Lemma('hour.n.01.hour'), ['hours']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('day.n.01.day'), ['day']),\n",
       "   ['with'],\n",
       "   Tree('each.s.01', ['each']),\n",
       "   Tree(Lemma('model.n.03.model'), ['model']),\n",
       "   Tree(Lemma('send.v.01.send'), ['sent']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('rabbi.n.01.rabbi'), ['rabbi']),\n",
       "   ['.']],\n",
       "  [['I'],\n",
       "   Tree(Lemma('ask.v.01.ask'), ['asked']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Quasimodo'])]),\n",
       "   Tree(Lemma('recently.r.01.recently'), ['recently']),\n",
       "   ['how'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('achieve.v.01.accomplish'), ['accomplished']),\n",
       "   ['this'],\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('answer.v.01.reply'), ['replied']),\n",
       "   ['that'],\n",
       "   ['he'],\n",
       "   ['had'],\n",
       "   Tree(Lemma('paint.v.02.paint'), ['painted']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('model.n.03.model'), ['model']),\n",
       "   ['``'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('beautiful.a.01.beautiful'), ['beautiful']),\n",
       "   Tree(Lemma('shade.n.02.shade'), ['shade']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('red.s.01.red'), ['red']),\n",
       "   Tree(Lemma('then.r.01.and_then'), ['and', 'then']),\n",
       "   Tree(Lemma('induce.v.02.have'), ['had']),\n",
       "   ['her'],\n",
       "   Tree(Lemma('breathe.v.01.breathe'), ['breathe']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('canvas.n.02.canvas'), ['canvas']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   ['which'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('typical.a.01.typical'), ['typical']),\n",
       "   Tree(Lemma('bantering.s.01.tongue-in-cheek'), ['tongue-in-cheek']),\n",
       "   Tree(Lemma('manner.n.01.way'), ['way']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('call_on_the_carpet.v.01.chide'), ['chiding']),\n",
       "   ['me'],\n",
       "   ['for'],\n",
       "   ['my'],\n",
       "   Tree(Lemma('lack.n.01.lack'), ['lack']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('sensitivity.n.03.sensitivity'), ['sensitivity']),\n",
       "   ['.']],\n",
       "  [['Yet'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('never.r.01.never'), ['never']),\n",
       "   Tree(Lemma('permit.v.01.allow'), ['allowed']),\n",
       "   ['these'],\n",
       "   Tree(Lemma('model.n.04.model'), ['models']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('become.v.01.become'), ['become']),\n",
       "   Tree(Lemma('fixed.s.04.fixed'), ['fixed']),\n",
       "   ['in'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('mind.n.01.mind'), ['mind']),\n",
       "   [';'],\n",
       "   ['they'],\n",
       "   Tree(Lemma('stay.v.01.remain'), ['remained']),\n",
       "   Tree(Lemma('approximate.s.01.rough'), ['rough']),\n",
       "   Tree(Lemma('terminus_a_quo.n.01.starting_point'), ['starting', 'points']),\n",
       "   ['.']],\n",
       "  [['When'],\n",
       "   Tree(Lemma('carve.v.02.carve'), ['carving']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('charged.s.02.charged'), ['charged']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('spontaneous.a.01.spontaneous'), ['spontaneous']),\n",
       "   Tree(Lemma('energy.n.03.energy'), ['energy']),\n",
       "   [';'],\n",
       "   Tree(Lemma('overcareful.s.01.too-careful'), ['too', 'careful']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('detailed.s.01.detailed'), ['detailed']),\n",
       "   Tree(Lemma('sketch.n.01.study'), ['studies']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('clay.n.01.clay'), ['clay']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('wax.n.01.wax'), ['wax']),\n",
       "   ['would'],\n",
       "   ['have'],\n",
       "   Tree(Lemma('glue.v.02.glue'), ['glued']),\n",
       "   ['him'],\n",
       "   ['down'],\n",
       "   ['to'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('mere.s.01.mere'), ['mere']),\n",
       "   Tree(Lemma('blow_up.v.02.enlarge'), ['enlarging']),\n",
       "   ['of'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('model.n.04.model'), ['model']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('drawing.n.01.drawing'), ['Drawing']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('model.n.04.model'), ['models']),\n",
       "   Tree(Lemma('constitute.v.01.be'), ['were']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('thinking.n.01.thinking'), ['thinking']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('everywhere.r.01.everywhere'), ['Everywhere']),\n",
       "   Tree('else.r.00', ['else']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('idea.n.01.idea'), ['ideas']),\n",
       "   Tree(Lemma('lie.v.01.lie'), ['lay']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('hang.v.01.hang'), ['hung']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('visible.a.01.visible'), ['visible']),\n",
       "   Tree(Lemma('form.n.03.form'), ['form']),\n",
       "   [':'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('model.n.04.model'), ['models']),\n",
       "   [','],\n",
       "   Tree(Lemma('drawing.n.02.drawing'), ['drawings']),\n",
       "   [','],\n",
       "   Tree(Lemma('ten.s.01.ten'), ['ten']),\n",
       "   Tree(Lemma('foot.n.02.foot'), ['foot']),\n",
       "   Tree(Lemma('canvas.n.02.canvas'), ['canvases']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('monochrome.n.01.monochrome'), ['monochromes']),\n",
       "   ['from'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('painting.n.02.painting'), ['painting']),\n",
       "   Tree(Lemma('day.n.02.day'), ['days']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('underfoot.r.01.underfoot'), ['underfoot']),\n",
       "   ['a'],\n",
       "   Tree('windfall.n.00', ['windfall']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('broken-backed.s.01.broken-backed'), ['broken-backed']),\n",
       "   Tree(Lemma('book.n.02.book'), ['books']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('look.v.02.look'), ['looked']),\n",
       "   ['as', 'though'],\n",
       "   ['their'],\n",
       "   Tree(Lemma('inside.n.01.inside'), ['insides']),\n",
       "   ['had'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('comb.v.02.ransack'), ['ransacked']),\n",
       "   ['by'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('lunatic.n.01.maniac'), ['maniac']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Eichmann'])]),\n",
       "   ['himself'],\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('model.n.07.model'), ['model']),\n",
       "   ['of'],\n",
       "   ['how'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('myth.n.01.myth'), ['myth']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree('enemy.s.00', ['enemy']),\n",
       "   Tree(Lemma('jew.n.01.Jew'), ['Jew']),\n",
       "   ['can'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('use.v.01.use'), ['used']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('transform.v.03.transform'), ['transform']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('average.s.02.ordinary'), ['ordinary']),\n",
       "   Tree(Lemma('man.n.03.man'), ['man']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('contemporary.s.02.present-day'), ['present-day']),\n",
       "   Tree(Lemma('society.n.01.society'), ['society']),\n",
       "   ['into'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('menace.n.01.menace'), ['menace']),\n",
       "   ['to'],\n",
       "   ['all'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('neighbor.n.01.neighbor'), ['neighbors']),\n",
       "   ['.']],\n",
       "  [['When'],\n",
       "   ['she'],\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['that'],\n",
       "   ['she'],\n",
       "   ['did'],\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   Tree(Lemma('have.v.01.have'), ['have']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('money.n.01.money'), ['money']),\n",
       "   [','],\n",
       "   ['he'],\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['that'],\n",
       "   ['she'],\n",
       "   ['could'],\n",
       "   Tree(Lemma('enter.v.01.come_in'), ['come', 'in']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('treatment.n.01.treatment'), ['treatment']),\n",
       "   ['with'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('office.n.01.office'), ['office']),\n",
       "   Tree(Lemma('model.n.02.model'), ['model']),\n",
       "   ['until'],\n",
       "   ['she'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('ready.a.01.ready'), ['ready']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('buy.v.01.buy'), ['buy']),\n",
       "   Tree(Lemma('one.s.01.one'), ['one']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('figure.n.01.figure'), ['Figures']),\n",
       "   ['1'],\n",
       "   ['to'],\n",
       "   ['3'],\n",
       "   Tree(Lemma('picture.v.02.show'), ['show']),\n",
       "   Tree(Lemma('photographic.a.01.photographic'), ['photographic']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('conventional.s.05.schematic'), ['schematic']),\n",
       "   Tree(Lemma('scene.n.08.view'), ['views']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree('test.s.00', ['test']),\n",
       "   Tree(Lemma('rack.n.05.stand'), ['stand']),\n",
       "   ['and'],\n",
       "   ['of'],\n",
       "   Tree(Lemma('two.s.01.two'), ['two']),\n",
       "   Tree(Lemma('different.a.01.different'), ['different']),\n",
       "   Tree(Lemma('model.n.02.model'), ['models']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('anode.n.01.anode'), ['anode']),\n",
       "   Tree(Lemma('holder.n.01.holder'), ['holder']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('two.s.01.two'), ['Two']),\n",
       "   Tree(Lemma('pyrometer.n.01.pyrometer'), ['pyrometers']),\n",
       "   Tree(Lemma('picture.v.02.show'), ['shown']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('figure.n.01.figure'), ['figure']),\n",
       "   ['1'],\n",
       "   ['and'],\n",
       "   ['2'],\n",
       "   ['('],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Pyrometer', 'Instrument', 'Co.'])]),\n",
       "   Tree(Lemma('model.n.02.model'), ['Model']),\n",
       "   ['95'],\n",
       "   [')'],\n",
       "   Tree(Lemma('serve.v.01.serve'), ['served']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('coincident.s.01.simultaneous'), ['simultaneous']),\n",
       "   Tree(Lemma('measurement.n.01.measurement'), ['measurement']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('anode.n.01.anode'), ['anode']),\n",
       "   Tree(Lemma('surface.n.01.surface'), ['surface']),\n",
       "   Tree(Lemma('temperature.n.01.temperature'), ['temperature']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('temperature.n.01.temperature'), ['temperature']),\n",
       "   Tree(Lemma('distribution.n.01.distribution'), ['distribution']),\n",
       "   ['along'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('anode.n.01.anode'), ['anode']),\n",
       "   Tree(Lemma('holder.n.01.holder'), ['holder']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('magnetic_resonance.n.01.magnetic_resonance'), ['magnetic', 'resonance']),\n",
       "   Tree(Lemma('absorption.n.02.absorption'), ['absorption']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('detect.v.01.detect'), ['detected']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('use.v.01.employ'), ['employing']),\n",
       "   ['a'],\n",
       "   Tree('NE', ['Varian']),\n",
       "   Tree(Lemma('model.n.02.model'), ['model']),\n",
       "   ['**f'],\n",
       "   Tree(Lemma('wide.a.01.broad'), ['broad']),\n",
       "   Tree(Lemma('line.n.02.line'), ['line']),\n",
       "   Tree(Lemma('mass_spectrometer.n.01.spectrometer'), ['spectrometer']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree('associated.s.00', ['associated']),\n",
       "   Tree(Lemma('twelve.s.01.12'), ['12']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('inch.n.01.inch'), ['inch']),\n",
       "   Tree(Lemma('electromagnet.n.01.electromagnet'), ['electromagnet']),\n",
       "   Tree(Lemma('system.n.01.system'), ['system']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('one.s.01.one'), ['One']),\n",
       "   Tree('measurement.n.00', ['measurement']),\n",
       "   ['at'],\n",
       "   Tree(Lemma('forty.s.01.40'), ['40']),\n",
       "   Tree(Lemma('megahertz.n.01.Mc'), ['Mc']),\n",
       "   ['/'],\n",
       "   Tree(Lemma('second.n.01.sec'), ['sec']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('obtain.v.01.obtain'), ['obtained']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree('NE', ['Varian']),\n",
       "   Tree(Lemma('model.n.02.model'), ['model']),\n",
       "   ['**f'],\n",
       "   Tree('unit.n.00', ['unit']),\n",
       "   ['.']],\n",
       "  [['These'],\n",
       "   ['were'],\n",
       "   Tree(Lemma('read.v.08.read'), ['read']),\n",
       "   ['at'],\n",
       "   ['280'],\n",
       "   Tree(Lemma('meter.n.01.m'), ['m']),\n",
       "   ['|'],\n",
       "   Tree(Lemma('meter.n.01.m'), ['m']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree('NE', ['Beckman']),\n",
       "   Tree(Lemma('model.n.02.model'), ['model']),\n",
       "   ['DU'],\n",
       "   Tree(Lemma('spectrophotometer.n.01.spectrophotometer'), ['spectrophotometer']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('screen.v.01.test'), ['tested']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('antibody.n.01.antibody'), ['antibody']),\n",
       "   Tree(Lemma('action.n.02.activity'), ['activity']),\n",
       "   ['as'],\n",
       "   Tree(Lemma('report.v.01.describe'), ['described']),\n",
       "   Tree(Lemma('above.r.01.above'), ['above']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('paper_electrophoresis.n.01.paper_electrophoresis'), ['Paper', 'electrophoresis']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('follow_through.v.02.carry_out'), ['carried', 'out']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('concentrated.s.02.concentrated'), ['concentrated']),\n",
       "   Tree(Lemma('sample.n.01.sample'), ['samples']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree('NE', ['Spinco']),\n",
       "   Tree(Lemma('model.n.02.model'), ['model']),\n",
       "   ['R'],\n",
       "   Tree(Lemma('cell.n.02.cell'), ['cell']),\n",
       "   Tree(Lemma('use.v.01.use'), ['using']),\n",
       "   Tree(Lemma('barbital.n.01.barbital'), ['barbital']),\n",
       "   Tree(Lemma('buffer.n.01.buffer'), ['buffer']),\n",
       "   [','],\n",
       "   Tree(Lemma('ph.n.01.pH'), ['pH']),\n",
       "   ['8.6'],\n",
       "   [','],\n",
       "   Tree(Lemma('ionic.a.01.ionic'), ['ionic']),\n",
       "   Tree(Lemma('strength.n.01.strength'), ['strength']),\n",
       "   ['0.075'],\n",
       "   [','],\n",
       "   ['at'],\n",
       "   Tree(Lemma('room_temperature.n.01.room_temperature'), ['room', 'temperature']),\n",
       "   ['on'],\n",
       "   Tree('NE', ['Whatman']),\n",
       "   Tree(Lemma('three.s.01.3'), ['3']),\n",
       "   ['MM'],\n",
       "   Tree(Lemma('filter_paper.n.01.filter_paper'), ['filter', 'paper']),\n",
       "   ['.']],\n",
       "  [['They'],\n",
       "   ['were'],\n",
       "   Tree(Lemma('then.r.01.then'), ['then']),\n",
       "   Tree(Lemma('centrifuge.v.01.centrifuge'), ['centrifuged']),\n",
       "   ['at'],\n",
       "   ['59780'],\n",
       "   Tree(Lemma('revolutions_per_minute.n.01.rpm'), ['rpm']),\n",
       "   ['for'],\n",
       "   ['35'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('eighty.s.01.80'), ['80']),\n",
       "   Tree(Lemma('min.n.02.Min'), ['min']),\n",
       "   ['at'],\n",
       "   Tree(Lemma('twenty.s.01.20'), ['20']),\n",
       "   ['`'],\n",
       "   Tree(Lemma('degree_centigrade.n.01.C'), ['C']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree('NE', ['Spinco']),\n",
       "   Tree(Lemma('model.n.02.model'), ['model']),\n",
       "   ['E'],\n",
       "   Tree(Lemma('ultracentrifuge.n.01.ultracentrifuge'), ['ultracentrifuge']),\n",
       "   ['at'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('protein.n.01.protein'), ['protein']),\n",
       "   Tree(Lemma('concentration.n.01.concentration'), ['concentration']),\n",
       "   ['of'],\n",
       "   ['1.00'],\n",
       "   ['to'],\n",
       "   ['1.25'],\n",
       "   ['%'],\n",
       "   ['.']],\n",
       "  [Tree(Lemma('ultracentrifugation.n.01.ultracentrifugation'), ['Ultracentrifugation']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('then.r.01.then'), ['then']),\n",
       "   Tree(Lemma('follow_through.v.02.carry_out'), ['carried', 'out']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree('NE', ['Spinco']),\n",
       "   Tree(Lemma('model.n.02.model'), ['model']),\n",
       "   ['L'],\n",
       "   Tree(Lemma('ultracentrifuge.n.01.ultracentrifuge'), ['ultracentrifuge']),\n",
       "   ['at'],\n",
       "   ['40000'],\n",
       "   Tree(Lemma('revolutions_per_minute.n.01.rpm'), ['rpm']),\n",
       "   ['for'],\n",
       "   ['125'],\n",
       "   ['to'],\n",
       "   ['150'],\n",
       "   Tree(Lemma('minute.n.01.min'), ['min']),\n",
       "   [','],\n",
       "   Tree(Lemma('refrigeration.n.01.refrigeration'), ['refrigeration']),\n",
       "   ['being'],\n",
       "   Tree(Lemma('use.v.01.use'), ['used']),\n",
       "   ['throughout'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('test.n.05.run'), ['run']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('cardboard.n.01.cardboard'), ['Cardboard']),\n",
       "   Tree(Lemma('noisemaker.n.01.noisemaker'), ['noisemakers']),\n",
       "   [','],\n",
       "   Tree(Lemma('substitute.v.02.substitute'), ['substitutes']),\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('unavailable.a.01.unavailable'), ['unavailable']),\n",
       "   Tree(Lemma('tin.n.01.tin'), ['tin']),\n",
       "   Tree(Lemma('model.n.02.model'), ['models']),\n",
       "   [','],\n",
       "   ['were'],\n",
       "   ['being'],\n",
       "   Tree(Lemma('peddle.v.01.hawk'), ['hawked']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('buy.v.01.buy'), ['bought']),\n",
       "   ['at'],\n",
       "   Tree(Lemma('improvised.s.01.makeshift'), ['makeshift']),\n",
       "   Tree(Lemma('stand.n.04.stand'), ['stands']),\n",
       "   ['every'],\n",
       "   Tree(Lemma('few.a.01.few'), ['few']),\n",
       "   Tree(Lemma('yard.n.01.yard'), ['yards']),\n",
       "   ['along'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Broadway'])]),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['one'],\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('ear.n.02.ear'), ['ears']),\n",
       "   ['were'],\n",
       "   Tree(Lemma('continually.r.01.continually'), ['continually']),\n",
       "   Tree(Lemma('serenade.v.01.serenade'), ['serenaded']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('horn.n.01.horn'), ['horns']),\n",
       "   [\"'\"],\n",
       "   Tree(Lemma('rasp.n.01.rasp'), ['rasps']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('bleat.n.01.bleat'), ['bleats']),\n",
       "   ['.']],\n",
       "  [Tree('latest.s.00', ['Latest']),\n",
       "   Tree(Lemma('model.n.02.model'), ['models']),\n",
       "   Tree(Lemma('serve.v.05.serve'), ['serve']),\n",
       "   Tree(Lemma('hot.a.01.hot'), ['hot']),\n",
       "   Tree(Lemma('meal.n.01.meal'), ['meals']),\n",
       "   ['at'],\n",
       "   Tree(Lemma('fair.s.02.reasonable'), ['reasonable']),\n",
       "   Tree(Lemma('monetary_value.n.01.price'), ['prices']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['at'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('profit.n.02.profit'), ['profit']),\n",
       "   ['to'],\n",
       "   ['you'],\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('perceiver.n.01.observer'), ['observer']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('television.n.01.television'), ['television']),\n",
       "   ['or'],\n",
       "   Tree('other.s.00', ['other']),\n",
       "   Tree(Lemma('product.n.02.product'), ['products']),\n",
       "   ['for'],\n",
       "   ['a'],\n",
       "   Tree('mass.s.00', ['mass']),\n",
       "   Tree(Lemma('audience.n.02.audience'), ['audience']),\n",
       "   Tree(Lemma('have.v.01.have'), ['has']),\n",
       "   Tree(Lemma('entirely.r.02.only'), ['only']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('license.n.04.permit'), ['permit']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   [','],\n",
       "   ['like'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('model.n.06.model'), ['models']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('see.v.01.see'), ['sees']),\n",
       "   [','],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   Tree(Lemma('more.a.01.more'), ['more']),\n",
       "   ['like'],\n",
       "   ['everybody'],\n",
       "   ['else'],\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('information.n.02.information'), ['information']),\n",
       "   Tree(Lemma('supply.v.01.provide'), ['provided']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('electron.n.01.electron'), ['electron']),\n",
       "   Tree(Lemma('paramagnetic.a.01.paramagnetic'), ['paramagnetic']),\n",
       "   Tree(Lemma('consequence.n.01.effect'), ['effects']),\n",
       "   ['is'],\n",
       "   Tree(Lemma('then.r.01.then'), ['then']),\n",
       "   Tree(Lemma('discourse.v.01.discuss'), ['discussed']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('last.r.02.finally'), ['finally']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('nuclear.a.02.nuclear'), ['nuclear']),\n",
       "   Tree(Lemma('consequence.n.01.effect'), ['effects']),\n",
       "   ['are'],\n",
       "   Tree(Lemma('rede.v.01.interpret'), ['interpreted']),\n",
       "   Tree('in_terms_of.s.00', ['in', 'terms', 'of']),\n",
       "   Tree(Lemma('assorted.s.02.various'), ['various']),\n",
       "   Tree(Lemma('motional.a.01.motional'), ['motional']),\n",
       "   Tree(Lemma('modified.a.01.modified'), ['modified']),\n",
       "   Tree(Lemma('model.n.01.model'), ['models']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   ['**f'],\n",
       "   Tree(Lemma('chemical_bond.n.01.bond'), ['bond']),\n",
       "   ['in'],\n",
       "   ['**f'],\n",
       "   ['.']],\n",
       "  [['We'],\n",
       "   Tree(Lemma('give.v.18.devote'), ['devote']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('chapter.n.01.chapter'), ['chapter']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('binomial_distribution.n.01.binomial_distribution'), ['binomial', 'distribution']),\n",
       "   Tree('not_only.r.00', ['not', 'only']),\n",
       "   ['because'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('mathematical.a.01.mathematical'), ['mathematical']),\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['for'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('enormous.s.01.enormous'), ['enormous']),\n",
       "   Tree(Lemma('assortment.n.01.variety'), ['variety']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('real_world.n.01.real_life'), ['real', 'life']),\n",
       "   Tree(Lemma('phenomenon.n.01.phenomenon'), ['phenomena']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   Tree(Lemma('besides.r.02.also'), ['also']),\n",
       "   ['because'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('have.v.02.have'), ['has']),\n",
       "   Tree(Lemma('important.a.01.important'), ['important']),\n",
       "   Tree(Lemma('property.n.02.property'), ['properties']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('recur.v.01.recur'), ['recur']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('many.a.01.many'), ['many']),\n",
       "   Tree(Lemma('other.a.01.other'), ['other']),\n",
       "   Tree(Lemma('probability.n.01.probability'), ['probability']),\n",
       "   Tree(Lemma('model.n.01.model'), ['models']),\n",
       "   ['.']],\n",
       "  [['We'],\n",
       "   Tree(Lemma('give.v.18.devote'), ['devote']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('chapter.n.01.chapter'), ['chapter']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('binomial_distribution.n.01.binomial_distribution'), ['binomial', 'distribution']),\n",
       "   Tree('not_only.r.00', ['not', 'only']),\n",
       "   ['because'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('mathematical.a.01.mathematical'), ['mathematical']),\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['for'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('enormous.s.01.enormous'), ['enormous']),\n",
       "   Tree(Lemma('assortment.n.01.variety'), ['variety']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('real_world.n.01.real_life'), ['real', 'life']),\n",
       "   Tree(Lemma('phenomenon.n.01.phenomenon'), ['phenomena']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   Tree(Lemma('besides.r.02.also'), ['also']),\n",
       "   ['because'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('have.v.02.have'), ['has']),\n",
       "   Tree(Lemma('important.a.01.important'), ['important']),\n",
       "   Tree(Lemma('property.n.02.property'), ['properties']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('recur.v.01.recur'), ['recur']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('many.a.01.many'), ['many']),\n",
       "   Tree(Lemma('other.a.01.other'), ['other']),\n",
       "   Tree(Lemma('probability.n.01.probability'), ['probability']),\n",
       "   Tree(Lemma('model.n.01.model'), ['models']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('on_the_other_hand.r.01.on_the_other_hand'), ['On', 'the', 'other', 'hand']),\n",
       "   [','],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   ['when'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('binomial.a.01.binomial'), ['binomial']),\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['does'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('describe.v.01.describe'), ['describe']),\n",
       "   Tree(Lemma('well.r.01.well'), ['well']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('physical_phenomenon.n.01.physical_phenomenon'), ['physical', 'phenomenon']),\n",
       "   ['being'],\n",
       "   Tree(Lemma('analyze.v.01.study'), ['studied']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('binomial.a.01.binomial'), ['binomial']),\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['may'],\n",
       "   Tree(Lemma('still.r.01.still'), ['still']),\n",
       "   ['be'],\n",
       "   Tree(Lemma('use.v.01.use'), ['used']),\n",
       "   ['as'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('baseline.n.01.baseline'), ['baseline']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('comparative.a.01.comparative'), ['comparative']),\n",
       "   Tree(Lemma('function.n.02.purpose'), ['purposes']),\n",
       "   [';'],\n",
       "   Tree('that_is.r.00', ['that', 'is']),\n",
       "   [','],\n",
       "   ['we'],\n",
       "   ['may'],\n",
       "   Tree(Lemma('discourse.v.01.discuss'), ['discuss']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('phenomenon.n.01.phenomenon'), ['phenomenon']),\n",
       "   Tree('in_terms_of.s.00', ['in', 'terms', 'of']),\n",
       "   ['its'],\n",
       "   Tree(Lemma('deviation.n.01.departure'), ['departures']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('binomial.a.01.binomial'), ['binomial']),\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('on_the_other_hand.r.01.on_the_other_hand'), ['On', 'the', 'other', 'hand']),\n",
       "   [','],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   ['when'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('binomial.a.01.binomial'), ['binomial']),\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['does'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('describe.v.01.describe'), ['describe']),\n",
       "   Tree(Lemma('well.r.01.well'), ['well']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('physical_phenomenon.n.01.physical_phenomenon'), ['physical', 'phenomenon']),\n",
       "   ['being'],\n",
       "   Tree(Lemma('analyze.v.01.study'), ['studied']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('binomial.a.01.binomial'), ['binomial']),\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['may'],\n",
       "   Tree(Lemma('still.r.01.still'), ['still']),\n",
       "   ['be'],\n",
       "   Tree(Lemma('use.v.01.use'), ['used']),\n",
       "   ['as'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('baseline.n.01.baseline'), ['baseline']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('comparative.a.01.comparative'), ['comparative']),\n",
       "   Tree(Lemma('function.n.02.purpose'), ['purposes']),\n",
       "   [';'],\n",
       "   Tree('that_is.r.00', ['that', 'is']),\n",
       "   [','],\n",
       "   ['we'],\n",
       "   ['may'],\n",
       "   Tree(Lemma('discourse.v.01.discuss'), ['discuss']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('phenomenon.n.01.phenomenon'), ['phenomenon']),\n",
       "   Tree('in_terms_of.s.00', ['in', 'terms', 'of']),\n",
       "   ['its'],\n",
       "   Tree(Lemma('deviation.n.01.departure'), ['departures']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('binomial.a.01.binomial'), ['binomial']),\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('on_the_other_hand.r.01.on_the_other_hand'), ['On', 'the', 'other', 'hand']),\n",
       "   [','],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   ['when'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('binomial.a.01.binomial'), ['binomial']),\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['does'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('describe.v.01.describe'), ['describe']),\n",
       "   Tree(Lemma('well.r.01.well'), ['well']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('physical_phenomenon.n.01.physical_phenomenon'), ['physical', 'phenomenon']),\n",
       "   ['being'],\n",
       "   Tree(Lemma('analyze.v.01.study'), ['studied']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('binomial.a.01.binomial'), ['binomial']),\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['may'],\n",
       "   Tree(Lemma('still.r.01.still'), ['still']),\n",
       "   ['be'],\n",
       "   Tree(Lemma('use.v.01.use'), ['used']),\n",
       "   ['as'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('baseline.n.01.baseline'), ['baseline']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('comparative.a.01.comparative'), ['comparative']),\n",
       "   Tree(Lemma('function.n.02.purpose'), ['purposes']),\n",
       "   [';'],\n",
       "   Tree('that_is.r.00', ['that', 'is']),\n",
       "   [','],\n",
       "   ['we'],\n",
       "   ['may'],\n",
       "   Tree(Lemma('discourse.v.01.discuss'), ['discuss']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('phenomenon.n.01.phenomenon'), ['phenomenon']),\n",
       "   Tree('in_terms_of.s.00', ['in', 'terms', 'of']),\n",
       "   ['its'],\n",
       "   Tree(Lemma('deviation.n.01.departure'), ['departures']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('binomial.a.01.binomial'), ['binomial']),\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['.']],\n",
       "  [['While'],\n",
       "   ['there'],\n",
       "   ['may'],\n",
       "   Tree(Lemma('exist.v.01.be'), ['be']),\n",
       "   Tree('several.s.01', ['several']),\n",
       "   Tree('such.s.00', ['such']),\n",
       "   Tree(Lemma('industry.n.01.industry'), ['industries']),\n",
       "   ['to'],\n",
       "   ['which'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['of'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('composition.n.08.paper'), ['paper']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('applicable.s.01.applicable'), ['applicable']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('writer.n.01.author'), ['authors']),\n",
       "   Tree(Lemma('make.v.01.make'), ['make']),\n",
       "   Tree(Lemma('particular.s.01.particular'), ['particular']),\n",
       "   Tree(Lemma('claim.n.02.claim'), ['claim']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('relevance.n.01.relevance'), ['relevance']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('explanation.n.02.explanation'), ['explanation']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('course.n.02.course'), ['course']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('wage.n.01.wage'), ['wages']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('monetary_value.n.01.price'), ['prices']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('steel.n.01.steel'), ['steel']),\n",
       "   Tree(Lemma('industry.n.01.industry'), ['industry']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('united_states.n.01.United_States'), ['United', 'States']),\n",
       "   ['since'],\n",
       "   Tree(Lemma('world_war_ii.n.01.World_War_II'), ['World', 'War', '2']),\n",
       "   [','],\n",
       "   ['.']],\n",
       "  [Tree(Lemma('indeed.r.01.indeed'), ['Indeed']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('apparent.s.01.apparent'), ['apparent']),\n",
       "   Tree(Lemma('stiffening.n.01.stiffening'), ['stiffening']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('industry.n.01.industry'), ['industry']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('attitude.n.01.attitude'), ['attitude']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('recent.s.01.recent'), ['recent']),\n",
       "   Tree(Lemma('steel.n.01.steel'), ['steel']),\n",
       "   Tree(Lemma('strike.n.01.strike'), ['strike']),\n",
       "   Tree(Lemma('have.v.01.have'), ['has']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('direct.a.01.direct'), ['direct']),\n",
       "   Tree(Lemma('explanation.n.02.explanation'), ['explanation']),\n",
       "   Tree('in_terms_of.s.00', ['in', 'terms', 'of']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   Tree(Lemma('here.r.02.here'), ['here']),\n",
       "   Tree(Lemma('present.v.02.present'), ['presented']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['of'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('composition.n.08.paper'), ['paper']),\n",
       "   Tree(Lemma('study.v.03.consider'), ['considers']),\n",
       "   ['an'],\n",
       "   Tree(Lemma('industry.n.01.industry'), ['industry']),\n",
       "   ['which'],\n",
       "   ['is'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('characterize.v.02.characterize'), ['characterized']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('vigorous.s.01.vigorous'), ['vigorous']),\n",
       "   Tree(Lemma('price_war.n.01.price_competition'), ['price', 'competition']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   ['which'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('so.r.01.so'), ['so']),\n",
       "   Tree('basic.s.00', ['basic']),\n",
       "   ['that'],\n",
       "   ['its'],\n",
       "   Tree(Lemma('wage.n.01.wage'), ['wage']),\n",
       "   Tree(Lemma('monetary_value.n.01.price'), ['price']),\n",
       "   Tree(Lemma('policy.n.01.policy'), ['policies']),\n",
       "   Tree(Lemma('be.v.01.be'), ['are']),\n",
       "   Tree(Lemma('keep.v.01.hold'), ['held']),\n",
       "   Tree('in_check.r.00', ['in', 'check']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('continuous.a.01.continuous'), ['continuous']),\n",
       "   Tree(Lemma('critical.a.01.critical'), ['critical']),\n",
       "   Tree(Lemma('public.a.01.public'), ['public']),\n",
       "   Tree(Lemma('examination.n.01.scrutiny'), ['scrutiny']),\n",
       "   ['.']],\n",
       "  [['In', 'order', 'to'],\n",
       "   Tree(Lemma('concenter.v.01.focus'), ['focus']),\n",
       "   Tree(Lemma('intelligibly.r.01.clearly'), ['clearly']),\n",
       "   ['upon'],\n",
       "   ['the'],\n",
       "   Tree('operation.n.00', ['operation']),\n",
       "   ['of'],\n",
       "   ['this'],\n",
       "   Tree('one.s.00', ['one']),\n",
       "   Tree(Lemma('force.n.01.force'), ['force']),\n",
       "   [','],\n",
       "   ['which'],\n",
       "   ['we'],\n",
       "   ['may'],\n",
       "   Tree(Lemma('call.v.02.call'), ['call']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('consequence.n.01.effect'), ['effect']),\n",
       "   ['of'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('public.s.02.public'), ['public']),\n",
       "   Tree(Lemma('limit.n.01.limit'), ['limit']),\n",
       "   Tree(Lemma('price.n.02.price'), ['pricing']),\n",
       "   [\"''\"],\n",
       "   ['on'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('cardinal.s.01.key'), ['key']),\n",
       "   [\"''\"],\n",
       "   Tree(Lemma('wage.n.01.wage'), ['wage']),\n",
       "   Tree(Lemma('bargain.n.01.bargain'), ['bargains']),\n",
       "   [','],\n",
       "   ['we'],\n",
       "   Tree(Lemma('intentionally.r.01.deliberately'), ['deliberately']),\n",
       "   Tree('simplify.v.00', ['simplify']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('abstract.v.01.abstract'), ['abstracting']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('other.a.01.other'), ['other']),\n",
       "   Tree(Lemma('force.n.01.force'), ['forces']),\n",
       "   [','],\n",
       "   Tree('such_as.s.00', ['such', 'as']),\n",
       "   Tree(Lemma('union.n.01.union'), ['union']),\n",
       "   Tree(Lemma('power.n.01.power'), ['power']),\n",
       "   [','],\n",
       "   ['which'],\n",
       "   ['may'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   Tree(Lemma('relevant.a.01.relevant'), ['relevant']),\n",
       "   ['in'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('actual.a.01.actual'), ['actual']),\n",
       "   Tree(Lemma('situation.n.01.situation'), ['situation']),\n",
       "   ['.']],\n",
       "  [['For'],\n",
       "   Tree(Lemma('expository.s.01.expository'), ['expository']),\n",
       "   Tree(Lemma('purpose.n.01.purpose'), ['purposes']),\n",
       "   [','],\n",
       "   ['this'],\n",
       "   ['is'],\n",
       "   Tree(Lemma('best.r.02.best'), ['best']),\n",
       "   Tree(Lemma('cover.v.05.treat'), ['treated']),\n",
       "   ['as'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['which'],\n",
       "   Tree(Lemma('spell_out.v.01.spell_out'), ['spells', 'out']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('condition.n.01.condition'), ['conditions']),\n",
       "   ['under'],\n",
       "   ['which'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('important.a.01.important'), ['important']),\n",
       "   Tree(Lemma('industry.n.01.industry'), ['industry']),\n",
       "   Tree(Lemma('affected.a.01.affected'), ['affected']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('populace.n.01.public'), ['public']),\n",
       "   Tree(Lemma('sake.n.01.interest'), ['interest']),\n",
       "   ['would'],\n",
       "   Tree(Lemma('determine.v.01.find'), ['find']),\n",
       "   ['it'],\n",
       "   Tree('profitable.s.00', ['profitable']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('raise.v.01.raise'), ['raise']),\n",
       "   Tree(Lemma('wage.n.01.wage'), ['wages']),\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('absence.n.02.absence'), ['absence']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('union.n.01.union'), ['union']),\n",
       "   Tree(Lemma('pressure.n.02.pressure'), ['pressures']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('high.a.01.high'), ['higher']),\n",
       "   Tree(Lemma('wage.n.01.wage'), ['wages']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('part.n.01.part'), ['Part']),\n",
       "   Tree(Lemma('one.s.01.1'), ['1']),\n",
       "   [','],\n",
       "   Tree(Lemma('below.r.03.below'), ['below']),\n",
       "   Tree(Lemma('report.v.01.describe'), ['describes']),\n",
       "   ['this'],\n",
       "   Tree('abstract.s.00', ['abstract']),\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('spell_out.v.01.spell_out'), ['spelling', 'out']),\n",
       "   ['its'],\n",
       "   Tree(Lemma('assumption.n.02.assumption'), ['assumptions']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('part.n.01.part'), ['Part']),\n",
       "   Tree(Lemma('two.s.01.2'), ['2']),\n",
       "   [','],\n",
       "   Tree(Lemma('discourse.v.01.discuss'), ['discusses']),\n",
       "   ['the'],\n",
       "   Tree('operation.n.00', ['operation']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('deduce.v.01.derive'), ['derives']),\n",
       "   ['some'],\n",
       "   Tree(Lemma('significant.a.01.significant'), ['significant']),\n",
       "   Tree(Lemma('decision.n.02.conclusion'), ['conclusions']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('industry.n.01.industry'), ['industry']),\n",
       "   ['with'],\n",
       "   ['which'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('concerned.s.02.concerned'), ['concerned']),\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['a'],\n",
       "   Tree('basic.s.00', ['basic']),\n",
       "   Tree(Lemma('industry.n.01.industry'), ['industry']),\n",
       "   [','],\n",
       "   Tree(Lemma('produce.v.02.produce'), ['producing']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('significant.s.02.substantial'), ['substantial']),\n",
       "   Tree(Lemma('share.n.01.share'), ['share']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('gross_national_product.n.01.gross_national_product'), ['gross', 'national', 'product']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('industry.n.01.industry'), ['industry']),\n",
       "   ['of'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('so.r.01.so'), ['so']),\n",
       "   Tree(Lemma('important.a.01.important'), ['important']),\n",
       "   ['that'],\n",
       "   ['its'],\n",
       "   Tree(Lemma('wage.n.01.wage'), ['wage']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('monetary_value.n.01.price'), ['price']),\n",
       "   Tree(Lemma('policy.n.01.policy'), ['policies']),\n",
       "   ['are'],\n",
       "   Tree(Lemma('affect.v.01.affect'), ['affected']),\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('public.a.01.public'), ['public']),\n",
       "   Tree(Lemma('sake.n.01.interest'), ['interest']),\n",
       "   ['.']],\n",
       "  [['For'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('industry.n.01.industry'), ['industry']),\n",
       "   ['of'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('consequence.n.01.effect'), ['effect']),\n",
       "   ['of'],\n",
       "   Tree('such.s.00', ['such']),\n",
       "   Tree(Lemma('populace.n.01.public'), ['public']),\n",
       "   Tree(Lemma('pressure.n.02.pressure'), ['pressures']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('past.n.01.past'), ['past']),\n",
       "   ['has'],\n",
       "   Tree(Lemma('be.v.01.be'), ['been']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('keep.v.01.hold'), ['hold']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('monetary_value.n.01.price'), ['price']),\n",
       "   Tree(Lemma('well.r.04.well'), ['well']),\n",
       "   ['below'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('short-run.s.01.short-run'), ['short-run']),\n",
       "   Tree(Lemma('net_income.n.01.profit'), ['profit']),\n",
       "   Tree(Lemma('maximize.v.01.maximize'), ['maximizing']),\n",
       "   Tree(Lemma('monetary_value.n.01.price'), ['price']),\n",
       "   ['('],\n",
       "   Tree(Lemma('given.s.01.given'), ['given']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('wage.n.01.wage'), ['wage']),\n",
       "   Tree(Lemma('rate.n.02.rate'), ['rate']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('degree.n.01.level'), ['level']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('gross_national_product.n.01.GNP'), ['GNP']),\n",
       "   [')'],\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['even'],\n",
       "   ['below'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('introduction.n.01.entry'), ['entry']),\n",
       "   Tree(Lemma('limited.a.01.limited'), ['limited']),\n",
       "   Tree(Lemma('monetary_value.n.01.price'), ['price']),\n",
       "   ['('],\n",
       "   ['but'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   ['below'],\n",
       "   Tree(Lemma('average_cost.n.01.average_cost'), ['average', 'cost']),\n",
       "   [')'],\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   [','],\n",
       "   ['we'],\n",
       "   Tree(Lemma('abstract.v.01.abstract'), ['abstract']),\n",
       "   ['from'],\n",
       "   ['all'],\n",
       "   Tree('non.s.00', ['non']),\n",
       "   Tree(Lemma('wage.n.01.wage'), ['wage']),\n",
       "   Tree(Lemma('beginning.n.04.source'), ['sources']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('cost.n.01.cost'), ['cost']),\n",
       "   Tree(Lemma('change.n.04.change'), ['changes']),\n",
       "   [','],\n",
       "   Tree(Lemma('so.r.02.so'), ['so']),\n",
       "   ['that'],\n",
       "   ['the'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('public.s.02.public'), ['public']),\n",
       "   Tree(Lemma('limit.n.01.limit'), ['limit']),\n",
       "   Tree(Lemma('monetary_value.n.01.price'), ['price']),\n",
       "   [\"''\"],\n",
       "   Tree(Lemma('entirely.r.02.only'), ['only']),\n",
       "   Tree(Lemma('rise.v.02.rise'), ['rises']),\n",
       "   ['as'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('wage.n.01.wage'), ['wage']),\n",
       "   Tree(Lemma('rate.n.02.rate'), ['rate']),\n",
       "   Tree(Lemma('rise.v.02.rise'), ['rises']),\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   [','],\n",
       "   ['then'],\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('industry.n.01.industry'), ['industry']),\n",
       "   ['is'],\n",
       "   Tree(Lemma('assume.v.01.presume'), ['presumed']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('recognize.v.02.realize'), ['realize']),\n",
       "   ['that'],\n",
       "   ['they'],\n",
       "   ['could'],\n",
       "   Tree(Lemma('successfully.r.01.successfully'), ['successfully']),\n",
       "   Tree(Lemma('defy.v.02.resist'), ['resist']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('change.n.03.change'), ['change']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('basic.a.01.basic'), ['basic']),\n",
       "   Tree(Lemma('wage.n.01.wage'), ['wage']),\n",
       "   Tree(Lemma('rate.n.02.rate'), ['rate']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   ['since'],\n",
       "   Tree('such.s.00', ['such']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('change.n.03.change'), ['change']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   ['the'],\n",
       "   Tree('only.s.00', ['only']),\n",
       "   Tree(Lemma('effective.s.03.effective'), ['effective']),\n",
       "   Tree(Lemma('means.n.01.means'), ['means']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('raise.v.01.raise'), ['raising']),\n",
       "   Tree(Lemma('monetary_value.n.01.price'), ['prices']),\n",
       "   ['they'],\n",
       "   ['may'],\n",
       "   [','],\n",
       "   ['in'],\n",
       "   Tree(Lemma('circumstance.n.01.circumstance'), ['circumstances']),\n",
       "   ['to'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('spell_out.v.01.spell_out'), ['spelled', 'out']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('part.n.01.part'), ['Part']),\n",
       "   Tree(Lemma('two.s.01.2'), ['2']),\n",
       "   [','],\n",
       "   Tree(Lemma('below.r.03.below'), ['below']),\n",
       "   [','],\n",
       "   Tree(Lemma('determine.v.01.find'), ['find']),\n",
       "   ['it'],\n",
       "   ['to'],\n",
       "   ['their'],\n",
       "   Tree(Lemma('advantage.n.01.advantage'), ['advantage']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('permit.v.01.allow'), ['allow']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('wage.n.01.wage'), ['wage']),\n",
       "   Tree(Lemma('raise.n.01.rise'), ['rise']),\n",
       "   ['.']],\n",
       "  [['From'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('given.n.01.presumption'), ['presumption']),\n",
       "   ['it'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   ['an'],\n",
       "   Tree(Lemma('easy.a.01.easy'), ['easy']),\n",
       "   Tree(Lemma('measure.n.01.step'), ['step']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('decision.n.02.conclusion'), ['conclusion']),\n",
       "   ['that'],\n",
       "   ['any'],\n",
       "   Tree('observed.s.00', ['observed']),\n",
       "   Tree(Lemma('addition.n.03.increase'), ['increases']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('basic.a.01.basic'), ['basic']),\n",
       "   Tree(Lemma('wage.n.01.wage'), ['wage']),\n",
       "   Tree(Lemma('rate.n.02.rate'), ['rate']),\n",
       "   ['must'],\n",
       "   Tree(Lemma('be_due.v.01.be_due'), ['be', 'due']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('union.n.01.union'), ['union']),\n",
       "   Tree(Lemma('behavior.n.01.behavior'), ['behavior']),\n",
       "   Tree(Lemma('different.a.01.different'), ['different']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('more.r.01.more'), ['more']),\n",
       "   Tree(Lemma('aggressive.a.01.aggressive'), ['aggressive']),\n",
       "   ['than'],\n",
       "   Tree(Lemma('assume.v.01.assume'), ['assumed']),\n",
       "   ['in'],\n",
       "   ['our'],\n",
       "   Tree(Lemma('model.n.01.model'), ['model']),\n",
       "   ['.']]],\n",
       " [3, 9, 13, 14, 25, 26, 45])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_word_data('model', 'n')\n",
    "sel.get_selected_sense_sents(sel.get_senses_for_curr_word())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "01       22\n",
       "02       11\n",
       "03        6\n",
       "04        4\n",
       "06        1\n",
       "07        1"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('model', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>07</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "01       43\n",
       "02       12\n",
       "04        4\n",
       "05        1\n",
       "06        2\n",
       "07        1"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('right', 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senses for word bank.n\n",
      "Number of sentences for sense Synset('bank.n.04') 1\n",
      "Number of sentences for sense Synset('depository_financial_institution.n.01') 20\n",
      "Number of sentences for sense Synset('bank.n.03') 2\n",
      "Number of sentences for sense Synset('bank.n.01') 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['In the ballroom below , the dark had given way to moonlight coming in through the bank of French windows .',\n",
       "  'The bill , which Daniel said he drafted personally , would force banks , insurance firms , pipeline companies and other corporations to report such property to the state treasurer .',\n",
       "  'Dewey Lawrence , a Tyler lawyer representing the Texas Bankers Association , sounded the opposition keynote when he said it would force banks to violate their contractual obligations with depositors and undermine the confidence of bank customers .',\n",
       "  'Dewey Lawrence , a Tyler lawyer representing the Texas Bankers Association , sounded the opposition keynote when he said it would force banks to violate their contractual obligations with depositors and undermine the confidence of bank customers .',\n",
       "  \"`` If you destroy confidence in banks , you do something to the economy '' , he said .\",\n",
       "  \"Rep. Charles E. Hughes of Sherman , sponsor of the bill , said a failure to enact it would `` amount to making a gift out of the taxpayers ' pockets to banks , insurance and pipeline companies '' .\",\n",
       "  \"These short , `` streamlined '' meetings usually are sponsored by local banks , Chambers of Commerce , trade associations , or other civic organizations .\",\n",
       "  'Participation loans are those made jointly by the SBA and banks or other private lending institutions .',\n",
       "  'Interest rates are determined by the board of directors of the bank with the approval of the Farm Credit Administration .',\n",
       "  'Shares of capital stock at $ 15 each in the latter company were payable at the Bank of Manchester or at various other Vermont banks .',\n",
       "  \"If the retailer and hotelman 's downtown unit sales have been decreasing , however , his dollar volume continues to rise , and it is dollars which you put in the bank .\",\n",
       "  'It really ought to be rebuilt , and he determined to go up and talk to the city banks about this .',\n",
       "  'The bank which held the mortgage on the old church declared that the interest was considerably in arrears , and the real estate people said flatly that the land across the river was being held for an eventual development for white working people who were coming in , and that none would be sold to colored folk .',\n",
       "  \"In 1927 his father 's business collapsed , and , rather than go bankrupt , Mercer senior turned his firm over to a bank for liquidation .\",\n",
       "  'Some years later the bank handling the Mercer liquidation received a check for $ 300000 , enough to clear up the debt .',\n",
       "  \"`` That 's Johnny '' , sighed the bank president , `` the best hearted boy in the world , but absent-minded '' .\",\n",
       "  'When he remembered that he might have not signed the check , Mercer made out another for the same amount , instructing the bank to destroy the other - especially if he had happened to have absent-mindedly signed both of them .',\n",
       "  \"She 'd be smart about it , get him to give it to her in little bills so 's nobody would suspect - maybe could n't get it until Monday account of that , the banks - But that was n't really long to wait .\",\n",
       "  \"Madden , with his investigation centered on the fraud , said that tomorrow he would go to the Bronx bank through which Mrs. Meeker 's checks to Johnston had cleared .\",\n",
       "  \"Two millions were added to what had been set aside for it in Mrs. Meeker 's lifetime , and the proviso made that as long as Brian Thayer continued to discharge his duties as administrator of the fund to the satisfaction of the board of trustees ( hereinafter appointed by the bank administering the estate ) he was to be retained in his present capacity at a salary commensurate with the increased responsibilities enlargement of the fund would entail .\",\n",
       "  \"`` Just as soon as I go to the bank , and '' -\",\n",
       "  'Grabbing his Winchester from its sheath , Cook prepared to fight from behind the arroyo bank .',\n",
       "  'And wherever the new thruways go up their banks are lined by neat glass and metal and colored brick light industry .',\n",
       "  'The next step was construction by the Manchester Light and Power Company of a plant on the west bank of the Battenkill south of Union Street bridge .',\n",
       "  'Over on the bank , the west bank , a man stood , calling to him .',\n",
       "  'Over on the bank , the west bank , a man stood , calling to him .',\n",
       "  'He improvised as he went along , completing a life-size clay figure , then bought yards of an inexpensive material from a draper , wet the lightweight cloth in a basin and covered it over with clay that Argiento brought from the bank of the Tiber , to the consistency of thick mud .',\n",
       "  \"Along Wappinger Creek in Dutchess County , past the white church at Fishkill , past Verplanck 's Point on the east bank of the Hudson , to the white salt crusted roads of the Long Island Rockaways there was a watching and an activity of preparing for something explosive to happen .\",\n",
       "  'It stood some fifty paces from the edge of the bank .',\n",
       "  'An officer with a squad of men had been waiting on the bank .',\n",
       "  'What in the name of God was he doing , crouched in a timbered pit on the wrong bank of the river ?',\n",
       "  'Hillman had ordered him not to leave the far bank .',\n",
       "  'To his left , the two skiffs dented their sharp bows into the soft bank .',\n",
       "  'He turned slowly and began to crawl back up the bank toward the rampart .',\n",
       "  'Watson stumbled down the bank .',\n",
       "  'Watson supported the man to the edge of the bank and passed the frail figure over the bow of the nearest skiff .',\n",
       "  'Through the splash of the rising waters , they could hear the roar of the river as it raged through its canyon , gnashing big chunks out of the banks .'],\n",
       " [[['In'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('ballroom.n.01.ballroom'), ['ballroom']),\n",
       "   Tree(Lemma('downstairs.r.01.below'), ['below']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('dark.n.01.dark'), ['dark']),\n",
       "   ['had'],\n",
       "   Tree(Lemma('move_over.v.01.give_way'), ['given', 'way']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('moonlight.n.01.moonlight'), ['moonlight']),\n",
       "   Tree(Lemma('enter.v.01.come_in'), ['coming', 'in']),\n",
       "   ['through'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bank.n.04.bank'), ['bank']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('french_window.n.01.French_window'), ['French', 'windows']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('bill.n.01.bill'), ['bill']),\n",
       "   [','],\n",
       "   ['which'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Daniel'])]),\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('draft.v.01.draft'), ['drafted']),\n",
       "   Tree(Lemma('personally.r.01.personally'), ['personally']),\n",
       "   [','],\n",
       "   ['would'],\n",
       "   Tree(Lemma('coerce.v.01.force'), ['force']),\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['banks']),\n",
       "   [','],\n",
       "   Tree(Lemma('insurance_company.n.01.insurance_firm'), ['insurance', 'firms']),\n",
       "   [','],\n",
       "   Tree(Lemma('pipeline_company.n.01.pipeline_company'), ['pipeline', 'companies']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('other.a.01.other'), ['other']),\n",
       "   Tree(Lemma('corporation.n.01.corporation'), ['corporations']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('report.v.01.report'), ['report']),\n",
       "   Tree('such.s.00', ['such']),\n",
       "   Tree(Lemma('property.n.01.property'), ['property']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('state_treasurer.n.01.state_treasurer'), ['state', 'treasurer']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Dewey', 'Lawrence'])]),\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Tyler'])]),\n",
       "   Tree(Lemma('lawyer.n.01.lawyer'), ['lawyer']),\n",
       "   Tree(Lemma('represent.v.03.represent'), ['representing']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Texas', 'Bankers', 'Association'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('sound.v.01.sound'), ['sounded']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('opposition.n.04.opposition'), ['opposition']),\n",
       "   Tree(Lemma('keynote.n.01.keynote'), ['keynote']),\n",
       "   ['when'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['it'],\n",
       "   ['would'],\n",
       "   Tree(Lemma('coerce.v.01.force'), ['force']),\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['banks']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('transgress.v.01.violate'), ['violate']),\n",
       "   ['their'],\n",
       "   Tree(Lemma('contractual.a.01.contractual'), ['contractual']),\n",
       "   Tree(Lemma('duty.n.01.obligation'), ['obligations']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('depositor.n.01.depositor'), ['depositors']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('sabotage.v.01.undermine'), ['undermine']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('confidence.n.02.confidence'), ['confidence']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['bank']),\n",
       "   Tree(Lemma('customer.n.01.customer'), ['customers']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Dewey', 'Lawrence'])]),\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Tyler'])]),\n",
       "   Tree(Lemma('lawyer.n.01.lawyer'), ['lawyer']),\n",
       "   Tree(Lemma('represent.v.03.represent'), ['representing']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Texas', 'Bankers', 'Association'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('sound.v.01.sound'), ['sounded']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('opposition.n.04.opposition'), ['opposition']),\n",
       "   Tree(Lemma('keynote.n.01.keynote'), ['keynote']),\n",
       "   ['when'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['it'],\n",
       "   ['would'],\n",
       "   Tree(Lemma('coerce.v.01.force'), ['force']),\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['banks']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('transgress.v.01.violate'), ['violate']),\n",
       "   ['their'],\n",
       "   Tree(Lemma('contractual.a.01.contractual'), ['contractual']),\n",
       "   Tree(Lemma('duty.n.01.obligation'), ['obligations']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('depositor.n.01.depositor'), ['depositors']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('sabotage.v.01.undermine'), ['undermine']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('confidence.n.02.confidence'), ['confidence']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['bank']),\n",
       "   Tree(Lemma('customer.n.01.customer'), ['customers']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   ['If'],\n",
       "   ['you'],\n",
       "   Tree(Lemma('destroy.v.01.destroy'), ['destroy']),\n",
       "   Tree(Lemma('confidence.n.02.confidence'), ['confidence']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['banks']),\n",
       "   [','],\n",
       "   ['you'],\n",
       "   Tree(Lemma('make.v.01.do'), ['do']),\n",
       "   ['something'],\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('economy.n.01.economy'), ['economy']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   ['he'],\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Rep.', 'Charles', 'E.', 'Hughes'])]),\n",
       "   ['of'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Sherman'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('patron.n.03.sponsor'), ['sponsor']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bill.n.01.bill'), ['bill']),\n",
       "   [','],\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('failure.n.01.failure'), ['failure']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('ordain.v.01.enact'), ['enact']),\n",
       "   ['it'],\n",
       "   ['would'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('amount.v.01.amount'), ['amount']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('make.v.02.make'), ['making']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('gift.n.01.gift'), ['gift']),\n",
       "   ['out', 'of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('taxpayer.n.01.taxpayer'), ['taxpayers']),\n",
       "   [\"'\"],\n",
       "   Tree(Lemma('pocket.n.03.pocket'), ['pockets']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['banks']),\n",
       "   [','],\n",
       "   Tree(Lemma('insurance_company.n.01.insurance_company'), ['insurance']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('pipeline_company.n.01.pipeline_company'), ['pipeline', 'companies']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['These'],\n",
       "   Tree(Lemma('short.a.01.short'), ['short']),\n",
       "   [','],\n",
       "   ['``'],\n",
       "   Tree(Lemma('streamlined.s.01.streamlined'), ['streamlined']),\n",
       "   [\"''\"],\n",
       "   Tree(Lemma('meeting.n.01.meeting'), ['meetings']),\n",
       "   Tree(Lemma('normally.r.01.usually'), ['usually']),\n",
       "   ['are'],\n",
       "   Tree(Lemma('sponsor.v.01.sponsor'), ['sponsored']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('local.a.01.local'), ['local']),\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['banks']),\n",
       "   [','],\n",
       "   Tree(Lemma('chamber_of_commerce.n.01.chamber_of_commerce'), ['Chambers', 'of', 'Commerce']),\n",
       "   [','],\n",
       "   Tree(Lemma('trade.n.03.trade'), ['trade']),\n",
       "   Tree(Lemma('association.n.01.association'), ['associations']),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   Tree(Lemma('other.a.01.other'), ['other']),\n",
       "   Tree(Lemma('civic.a.01.civic'), ['civic']),\n",
       "   Tree(Lemma('organization.n.01.organization'), ['organizations']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('participation_loan.n.01.participation_loan'), ['Participation', 'loans']),\n",
       "   Tree(Lemma('be.v.02.be'), ['are']),\n",
       "   ['those'],\n",
       "   ['made'],\n",
       "   Tree(Lemma('jointly.r.01.jointly'), ['jointly']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   ['SBA'],\n",
       "   ['and'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['banks']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('other.a.01.other'), ['other']),\n",
       "   Tree(Lemma('private.a.01.private'), ['private']),\n",
       "   Tree(Lemma('lending_institution.n.01.lending_institution'), ['lending', 'institutions']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('interest_rate.n.01.interest_rate'), ['Interest', 'rates']),\n",
       "   ['are'],\n",
       "   Tree(Lemma('determine.v.03.determine'), ['determined']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('directorate.n.01.board_of_directors'), ['board', 'of', 'directors']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['bank']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('blessing.n.01.approval'), ['approval']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Farm', 'Credit', 'Administration'])]),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('share.n.02.share'), ['Shares']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('authorized_shares.n.01.capital_stock'), ['capital', 'stock']),\n",
       "   ['at'],\n",
       "   ['$'],\n",
       "   Tree(Lemma('fifteen.s.01.15'), ['15']),\n",
       "   Tree(Lemma('each.r.01.each'), ['each']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('latter.a.01.latter'), ['latter']),\n",
       "   Tree(Lemma('company.n.01.company'), ['company']),\n",
       "   Tree(Lemma('be.v.01.be'), ['were']),\n",
       "   Tree(Lemma('collectible.s.01.payable'), ['payable']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Bank', 'of', 'Manchester'])]),\n",
       "   ['or'],\n",
       "   ['at'],\n",
       "   Tree(Lemma('assorted.s.02.various'), ['various']),\n",
       "   Tree(Lemma('other.a.01.other'), ['other']),\n",
       "   Tree(Lemma('vermont.n.01.Vermont'), ['Vermont']),\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['banks']),\n",
       "   ['.']],\n",
       "  [['If'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('retailer.n.01.retailer'), ['retailer']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('hotelier.n.01.hotelman'), ['hotelman']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('business_district.n.01.downtown'), ['downtown']),\n",
       "   Tree(Lemma('unit.n.02.unit'), ['unit']),\n",
       "   Tree(Lemma('sale.n.01.sale'), ['sales']),\n",
       "   ['have'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('decrease.v.01.decrease'), ['decreasing']),\n",
       "   [','],\n",
       "   Tree(Lemma('however.r.01.however'), ['however']),\n",
       "   [','],\n",
       "   ['his'],\n",
       "   Tree(Lemma('dollar_volume.n.01.dollar_volume'), ['dollar', 'volume']),\n",
       "   Tree(Lemma('continue.v.01.continue'), ['continues']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('wax.v.02.rise'), ['rise']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['it'],\n",
       "   ['is'],\n",
       "   Tree(Lemma('dollar.n.02.dollar'), ['dollars']),\n",
       "   ['which'],\n",
       "   ['you'],\n",
       "   Tree(Lemma('store.v.01.put_in'), ['put', 'in']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['bank']),\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   Tree(Lemma('truly.r.01.really'), ['really']),\n",
       "   ['ought'],\n",
       "   ['to'],\n",
       "   ['be'],\n",
       "   Tree('rebuilt.s.00', ['rebuilt']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('decide.v.01.determine'), ['determined']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('approach.v.01.go_up'), ['go', 'up']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('talk.v.01.talk'), ['talk']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('city.n.01.city'), ['city']),\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['banks']),\n",
       "   ['about'],\n",
       "   ['this'],\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['bank']),\n",
       "   ['which'],\n",
       "   Tree(Lemma('bear.v.11.hold'), ['held']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('mortgage.n.01.mortgage'), ['mortgage']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('old.a.02.old'), ['old']),\n",
       "   Tree(Lemma('church.n.02.church'), ['church']),\n",
       "   Tree(Lemma('declare.v.01.declare'), ['declared']),\n",
       "   ['that'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('interest.n.04.interest'), ['interest']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('well.r.07.considerably'), ['considerably']),\n",
       "   Tree('in_arrears.s.00', ['in', 'arrears']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('real_property.n.01.real_estate'), ['real', 'estate']),\n",
       "   Tree(Lemma('people.n.01.people'), ['people']),\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   Tree(Lemma('flatly.r.01.flatly'), ['flatly']),\n",
       "   ['that'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('land.n.01.land'), ['land']),\n",
       "   ['across'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('river.n.01.river'), ['river']),\n",
       "   ['was'],\n",
       "   ['being'],\n",
       "   Tree('hold.v.00', ['held']),\n",
       "   ['for'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('eventual.s.01.eventual'), ['eventual']),\n",
       "   Tree(Lemma('development.n.06.development'), ['development']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('white.n.01.White'), ['white']),\n",
       "   Tree(Lemma('working.s.01.working'), ['working']),\n",
       "   Tree(Lemma('people.n.01.people'), ['people']),\n",
       "   ['who'],\n",
       "   ['were'],\n",
       "   Tree(Lemma('enter.v.01.come_in'), ['coming', 'in']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['that'],\n",
       "   ['none'],\n",
       "   ['would'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('sell.v.01.sell'), ['sold']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('colored.s.02.colored'), ['colored']),\n",
       "   Tree(Lemma('folk.n.01.folk'), ['folk']),\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   ['1927'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('father.n.01.father'), ['father']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('business.n.01.business'), ['business']),\n",
       "   Tree(Lemma('collapse.v.01.collapse'), ['collapsed']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   [','],\n",
       "   ['rather', 'than'],\n",
       "   Tree(Lemma('become.v.01.go'), ['go']),\n",
       "   Tree(Lemma('bankrupt.s.01.bankrupt'), ['bankrupt']),\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Mercer'])]),\n",
       "   Tree(Lemma('senior.a.01.senior'), ['senior']),\n",
       "   Tree(Lemma('pass.v.05.turn_over'), ['turned']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('firm.n.01.firm'), ['firm']),\n",
       "   ['over'],\n",
       "   ['to'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['bank']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('liquidation.n.01.liquidation'), ['liquidation']),\n",
       "   ['.']],\n",
       "  [Tree('some.s.00', ['Some']),\n",
       "   Tree(Lemma('year.n.01.year'), ['years']),\n",
       "   Tree(Lemma('subsequently.r.01.later'), ['later']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['bank']),\n",
       "   Tree(Lemma('manage.v.02.handle'), ['handling']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Mercer'])]),\n",
       "   Tree(Lemma('liquidation.n.01.liquidation'), ['liquidation']),\n",
       "   Tree(Lemma('receive.v.01.receive'), ['received']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('check.n.01.check'), ['check']),\n",
       "   ['for'],\n",
       "   ['$'],\n",
       "   ['300000'],\n",
       "   [','],\n",
       "   Tree(Lemma('enough.n.01.enough'), ['enough']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('clear.v.24.clear_up'), ['clear', 'up']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('debt.n.02.debt'), ['debt']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   ['That'],\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Johnny'])]),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   Tree(Lemma('sigh.v.02.sigh'), ['sighed']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['bank']),\n",
       "   Tree(Lemma('president.n.01.president'), ['president']),\n",
       "   [','],\n",
       "   ['``'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('best.a.01.best'), ['best']),\n",
       "   Tree('hearted.a.00', ['hearted']),\n",
       "   Tree(Lemma('boy.n.02.boy'), ['boy']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree('world.n.00', ['world']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   Tree(Lemma('absent.s.03.absentminded'), ['absent-minded']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['When'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('remember.v.01.remember'), ['remembered']),\n",
       "   ['that'],\n",
       "   ['he'],\n",
       "   ['might'],\n",
       "   ['have'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('sign.v.01.sign'), ['signed']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('check.n.01.check'), ['check']),\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Mercer'])]),\n",
       "   Tree(Lemma('write_out.v.02.make_out'), ['made', 'out']),\n",
       "   ['another'],\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('like.a.02.same'), ['same']),\n",
       "   Tree(Lemma('sum.n.01.amount'), ['amount']),\n",
       "   [','],\n",
       "   Tree(Lemma('instruct.v.02.instruct'), ['instructing']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['bank']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('destroy.v.02.destroy'), ['destroy']),\n",
       "   ['the'],\n",
       "   ['other'],\n",
       "   ['-'],\n",
       "   Tree(Lemma('particularly.r.01.especially'), ['especially']),\n",
       "   ['if'],\n",
       "   ['he'],\n",
       "   ['had'],\n",
       "   ['happened', 'to'],\n",
       "   ['have'],\n",
       "   Tree(Lemma('absently.r.01.absentmindedly'), ['absent-mindedly']),\n",
       "   Tree(Lemma('sign.v.01.sign'), ['signed']),\n",
       "   ['both'],\n",
       "   ['of'],\n",
       "   ['them'],\n",
       "   ['.']],\n",
       "  [['She'],\n",
       "   [\"'d\"],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   Tree(Lemma('smart.a.01.smart'), ['smart']),\n",
       "   ['about'],\n",
       "   ['it'],\n",
       "   [','],\n",
       "   Tree(Lemma('get.v.03.get'), ['get']),\n",
       "   ['him'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('give.v.03.give'), ['give']),\n",
       "   ['it'],\n",
       "   ['to'],\n",
       "   ['her'],\n",
       "   ['in'],\n",
       "   Tree(Lemma('small.a.01.little'), ['little']),\n",
       "   Tree(Lemma('bill.n.03.bill'), ['bills']),\n",
       "   Tree(Lemma('so.r.02.so'), ['so']),\n",
       "   [\"'s\"],\n",
       "   ['nobody'],\n",
       "   ['would'],\n",
       "   Tree(Lemma('suspect.v.01.suspect'), ['suspect']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('possibly.r.01.maybe'), ['maybe']),\n",
       "   ['could'],\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   Tree(Lemma('get.v.01.get'), ['get']),\n",
       "   ['it'],\n",
       "   ['until'],\n",
       "   Tree(Lemma('monday.n.01.Monday'), ['Monday']),\n",
       "   ['account', 'of'],\n",
       "   ['that'],\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['banks']),\n",
       "   ['-'],\n",
       "   ['But'],\n",
       "   ['that'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   Tree(Lemma('actually.r.01.really'), ['really']),\n",
       "   Tree(Lemma('long.a.01.long'), ['long']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('wait.v.02.wait'), ['wait']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Madden'])]),\n",
       "   [','],\n",
       "   ['with'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('probe.n.01.investigation'), ['investigation']),\n",
       "   Tree(Lemma('focus_on.v.01.center_on'), ['centered', 'on']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('fraud.n.01.fraud'), ['fraud']),\n",
       "   [','],\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('tomorrow.r.01.tomorrow'), ['tomorrow']),\n",
       "   ['he'],\n",
       "   ['would'],\n",
       "   Tree('go_to.v.00', ['go', 'to']),\n",
       "   Tree('the_bronx.n.00', ['the', 'Bronx']),\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['bank']),\n",
       "   ['through'],\n",
       "   ['which'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Mrs.', 'Meeker'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('check.n.01.check'), ['checks']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Johnston'])]),\n",
       "   ['had'],\n",
       "   Tree(Lemma('clear.v.07.clear'), ['cleared']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('two.s.01.two'), ['Two']),\n",
       "   Tree('millions.n.00', ['millions']),\n",
       "   ['were'],\n",
       "   Tree('add.v.4;1', ['added']),\n",
       "   ['to'],\n",
       "   ['what'],\n",
       "   ['had'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('allow.v.04.set_aside'), ['set', 'aside']),\n",
       "   ['for'],\n",
       "   ['it'],\n",
       "   ['in'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Mrs.', 'Meeker'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('life.n.05.lifetime'), ['lifetime']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('provision.n.01.proviso'), ['proviso']),\n",
       "   Tree(Lemma('lay_down.v.01.make'), ['made']),\n",
       "   ['that'],\n",
       "   ['as'],\n",
       "   Tree(Lemma('long.a.01.long'), ['long']),\n",
       "   ['as'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Brian', 'Thayer'])]),\n",
       "   Tree(Lemma('continue.v.01.continue'), ['continued']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('dispatch.v.02.discharge'), ['discharge']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('duty.n.02.duty'), ['duties']),\n",
       "   ['as'],\n",
       "   Tree(Lemma('administrator.n.02.administrator'), ['administrator']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('fund.n.01.fund'), ['fund']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('satisfaction.n.01.satisfaction'), ['satisfaction']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('board_of_trustees.n.01.board_of_trustees'), ['board', 'of', 'trustees']),\n",
       "   ['('],\n",
       "   Tree(Lemma('hereinafter.r.01.hereinafter'), ['hereinafter']),\n",
       "   Tree(Lemma('appoint.v.01.appoint'), ['appointed']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['bank']),\n",
       "   Tree(Lemma('administer.v.01.administer'), ['administering']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('estate.n.01.estate'), ['estate']),\n",
       "   [')'],\n",
       "   ['he'],\n",
       "   ['was'],\n",
       "   ['to'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('retain.v.02.retain'), ['retained']),\n",
       "   ['in'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('present.a.01.present'), ['present']),\n",
       "   Tree(Lemma('capacity.n.05.capacity'), ['capacity']),\n",
       "   ['at'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('wage.n.01.salary'), ['salary']),\n",
       "   Tree(Lemma('commensurate.a.01.commensurate'), ['commensurate']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('increased.a.01.increased'), ['increased']),\n",
       "   Tree(Lemma('duty.n.01.responsibility'), ['responsibilities']),\n",
       "   Tree(Lemma('expansion.n.01.enlargement'), ['enlargement']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('fund.n.01.fund'), ['fund']),\n",
       "   ['would'],\n",
       "   Tree(Lemma('entail.v.02.entail'), ['entail']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   Tree(Lemma('precisely.r.01.just'), ['Just']),\n",
       "   ['as', 'soon', 'as'],\n",
       "   ['I'],\n",
       "   Tree(Lemma('travel.v.01.go'), ['go']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('depository_financial_institution.n.01.bank'), ['bank']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   [\"''\"],\n",
       "   ['-']],\n",
       "  [Tree(Lemma('snap_up.v.01.grab'), ['Grabbing']),\n",
       "   ['his'],\n",
       "   Tree('NE', ['Winchester']),\n",
       "   ['from'],\n",
       "   ['its'],\n",
       "   Tree(Lemma('sheath.n.01.sheath'), ['sheath']),\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Cook'])]),\n",
       "   Tree(Lemma('fix.v.12.prepare'), ['prepared']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('fight.v.02.fight'), ['fight']),\n",
       "   ['from'],\n",
       "   ['behind'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('arroyo.n.01.arroyo'), ['arroyo']),\n",
       "   Tree(Lemma('bank.n.03.bank'), ['bank']),\n",
       "   ['.']],\n",
       "  [['And'],\n",
       "   ['wherever'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('new.a.01.new'), ['new']),\n",
       "   Tree(Lemma('expressway.n.01.thruway'), ['thruways']),\n",
       "   Tree(Lemma('go_up.v.04.go_up'), ['go', 'up']),\n",
       "   ['their'],\n",
       "   Tree(Lemma('bank.n.03.bank'), ['banks']),\n",
       "   ['are'],\n",
       "   Tree(Lemma('lined.s.01.lined'), ['lined']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('neat.s.01.neat'), ['neat']),\n",
       "   Tree(Lemma('glass.n.01.glass'), ['glass']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('metallic_element.n.01.metal'), ['metal']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('colored.a.01.colored'), ['colored']),\n",
       "   Tree(Lemma('brick.n.01.brick'), ['brick']),\n",
       "   Tree(Lemma('light.a.03.light'), ['light']),\n",
       "   Tree(Lemma('industry.n.02.industry'), ['industry']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree('next.s.01', ['next']),\n",
       "   Tree(Lemma('measure.n.01.step'), ['step']),\n",
       "   Tree(Lemma('be.v.02.be'), ['was']),\n",
       "   Tree(Lemma('construction.n.01.construction'), ['construction']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Manchester', 'Light', 'and', 'Power', 'Company'])]),\n",
       "   ['of'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('plant.n.01.plant'), ['plant']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('west.a.01.west'), ['west']),\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Battenkill'])]),\n",
       "   Tree(Lemma('south.a.01.south'), ['south']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Union', 'Street'])]),\n",
       "   Tree(Lemma('bridge.n.01.bridge'), ['bridge']),\n",
       "   ['.']],\n",
       "  [['Over'],\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('west.a.01.west'), ['west']),\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree(Lemma('man.n.01.man'), ['man']),\n",
       "   Tree(Lemma('stand.v.01.stand'), ['stood']),\n",
       "   [','],\n",
       "   Tree(Lemma('shout.v.02.call'), ['calling']),\n",
       "   ['to'],\n",
       "   ['him'],\n",
       "   ['.']],\n",
       "  [['Over'],\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('west.a.01.west'), ['west']),\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree(Lemma('man.n.01.man'), ['man']),\n",
       "   Tree(Lemma('stand.v.01.stand'), ['stood']),\n",
       "   [','],\n",
       "   Tree(Lemma('shout.v.02.call'), ['calling']),\n",
       "   ['to'],\n",
       "   ['him'],\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('improvise.v.01.improvise'), ['improvised']),\n",
       "   ['as'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('continue.v.01.go_along'), ['went', 'along']),\n",
       "   [','],\n",
       "   Tree(Lemma('complete.v.01.complete'), ['completing']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('life-size.s.01.life-size'), ['life-size']),\n",
       "   Tree(Lemma('clay.n.01.clay'), ['clay']),\n",
       "   Tree(Lemma('figure.n.04.figure'), ['figure']),\n",
       "   [','],\n",
       "   Tree(Lemma('then.r.01.then'), ['then']),\n",
       "   Tree(Lemma('buy.v.01.buy'), ['bought']),\n",
       "   Tree(Lemma('yard.n.01.yard'), ['yards']),\n",
       "   ['of'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('cheap.a.01.inexpensive'), ['inexpensive']),\n",
       "   Tree(Lemma('fabric.n.01.material'), ['material']),\n",
       "   ['from'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('draper.n.01.draper'), ['draper']),\n",
       "   [','],\n",
       "   Tree(Lemma('wet.v.01.wet'), ['wet']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('lightweight.s.01.lightweight'), ['lightweight']),\n",
       "   Tree(Lemma('fabric.n.01.cloth'), ['cloth']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('basin.n.01.basin'), ['basin']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('cover.v.01.cover'), ['covered']),\n",
       "   ['it'],\n",
       "   ['over'],\n",
       "   ['with'],\n",
       "   Tree(Lemma('clay.n.01.clay'), ['clay']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Argiento'])]),\n",
       "   Tree(Lemma('bring.v.01.bring'), ['brought']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree('NE', ['Tiber']),\n",
       "   [','],\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('consistency.n.01.consistency'), ['consistency']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('thick.a.03.thick'), ['thick']),\n",
       "   Tree(Lemma('mud.n.01.mud'), ['mud']),\n",
       "   ['.']],\n",
       "  [['Along'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Wappinger', 'Creek'])]),\n",
       "   ['in'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Dutchess', 'County'])]),\n",
       "   [','],\n",
       "   ['past'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('white.a.01.white'), ['white']),\n",
       "   Tree(Lemma('church.n.02.church'), ['church']),\n",
       "   ['at'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Fishkill'])]),\n",
       "   [','],\n",
       "   ['past'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Verplanck', \"'s\", 'Point'])]),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('east.a.01.east'), ['east']),\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('hudson.n.01.Hudson'), ['Hudson']),\n",
       "   [','],\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('white.a.01.white'), ['white']),\n",
       "   Tree(Lemma('salt.n.01.salt'), ['salt']),\n",
       "   Tree(Lemma('crusted.s.01.crusted'), ['crusted']),\n",
       "   Tree(Lemma('road.n.01.road'), ['roads']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Long', 'Island', 'Rockaways'])]),\n",
       "   ['there'],\n",
       "   Tree(Lemma('exist.v.01.be'), ['was']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('observation.n.02.watching'), ['watching']),\n",
       "   ['and'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('activity.n.01.activity'), ['activity']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('steel_oneself_against.v.01.prepare_for'), ['preparing', 'for']),\n",
       "   ['something'],\n",
       "   Tree(Lemma('explosive.s.02.explosive'), ['explosive']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('happen.v.02.happen'), ['happen']),\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   Tree(Lemma('stand.v.01.stand'), ['stood']),\n",
       "   ['some'],\n",
       "   Tree(Lemma('fifty.s.01.fifty'), ['fifty']),\n",
       "   Tree(Lemma('footstep.n.03.pace'), ['paces']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('edge.n.03.edge'), ['edge']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   ['.']],\n",
       "  [['An'],\n",
       "   Tree(Lemma('military_officer.n.01.officer'), ['officer']),\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('squad.n.01.squad'), ['squad']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('serviceman.n.01.man'), ['men']),\n",
       "   ['had'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('wait.v.01.wait'), ['waiting']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   ['.']],\n",
       "  [['What'],\n",
       "   ['in', 'the', 'name', 'of', 'God'],\n",
       "   ['was'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('make.v.01.do'), ['doing']),\n",
       "   [','],\n",
       "   Tree(Lemma('crouch.v.01.crouch'), ['crouched']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('timbered.s.02.timbered'), ['timbered']),\n",
       "   Tree(Lemma('pit.n.01.pit'), ['pit']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('incorrect.a.01.wrong'), ['wrong']),\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('river.n.01.river'), ['river']),\n",
       "   ['?']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Hillman'])]),\n",
       "   ['had'],\n",
       "   Tree(Lemma('order.v.01.order'), ['ordered']),\n",
       "   ['him'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('leave.v.01.leave'), ['leave']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('far.a.01.far'), ['far']),\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   ['.']],\n",
       "  [['To'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('left.n.01.left'), ['left']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('two.s.01.two'), ['two']),\n",
       "   Tree(Lemma('skiff.n.01.skiff'), ['skiffs']),\n",
       "   Tree(Lemma('indent.v.03.dent'), ['dented']),\n",
       "   ['their'],\n",
       "   Tree(Lemma('acuate.s.01.sharp'), ['sharp']),\n",
       "   Tree(Lemma('bow.n.04.bow'), ['bows']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('soft.a.01.soft'), ['soft']),\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('turn.v.01.turn'), ['turned']),\n",
       "   Tree(Lemma('slowly.r.01.slowly'), ['slowly']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('get_down.v.07.begin'), ['began']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('crawl.v.01.crawl'), ['crawl']),\n",
       "   Tree(Lemma('back.r.01.back'), ['back']),\n",
       "   ['up'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   ['toward'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('rampart.n.01.rampart'), ['rampart']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Watson'])]),\n",
       "   Tree(Lemma('stumble.v.01.stumble'), ['stumbled']),\n",
       "   Tree(Lemma('down.r.01.down'), ['down']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Watson'])]),\n",
       "   Tree(Lemma('hold.v.10.support'), ['supported']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('man.n.01.man'), ['man']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('edge.n.03.edge'), ['edge']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bank.n.01.bank'), ['bank']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('pass.v.05.pass'), ['passed']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('frail.a.01.frail'), ['frail']),\n",
       "   Tree(Lemma('human_body.n.01.figure'), ['figure']),\n",
       "   ['over'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bow.n.03.bow'), ['bow']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('near.a.01.near'), ['nearest']),\n",
       "   Tree(Lemma('skiff.n.01.skiff'), ['skiff']),\n",
       "   ['.']],\n",
       "  [['Through'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('splash.n.01.splash'), ['splash']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('rise.v.01.rise'), ['rising']),\n",
       "   Tree(Lemma('water.n.01.water'), ['waters']),\n",
       "   [','],\n",
       "   ['they'],\n",
       "   ['could'],\n",
       "   Tree(Lemma('hear.v.01.hear'), ['hear']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('boom.n.01.roar'), ['roar']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('river.n.01.river'), ['river']),\n",
       "   ['as'],\n",
       "   ['it'],\n",
       "   Tree(Lemma('rage.v.02.rage'), ['raged']),\n",
       "   ['through'],\n",
       "   ['its'],\n",
       "   Tree(Lemma('canyon.n.01.canyon'), ['canyon']),\n",
       "   [','],\n",
       "   Tree(Lemma('gnash.v.01.gnash'), ['gnashing']),\n",
       "   Tree(Lemma('large.a.01.big'), ['big']),\n",
       "   Tree(Lemma('ball.n.08.chunk'), ['chunks']),\n",
       "   ['out'],\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bank.n.01.bank'), ['banks']),\n",
       "   ['.']]],\n",
       " [1, 21, 23, 37])"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_word_data('bank', 'n')\n",
    "sel.get_selected_sense_sents(sel.get_senses_for_curr_word())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Senses for word right.n\n",
      "Number of sentences for sense Synset('right.n.06') 2\n",
      "Number of sentences for sense Synset('right.n.04') 4\n",
      "Number of sentences for sense Synset('right_field.n.01') 5\n",
      "Number of sentences for sense Synset('right.n.01') 38\n",
      "Number of sentences for sense Synset('right.n.02') 12\n",
      "Number of sentences for sense Synset('right.n.05') 1\n",
      "Number of sentences for sense Synset('right.n.07') 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['It has a fast pace , excellent music , expert direction , and not only a good comedian , but an appealing person in his own right , Mr. Berman .',\n",
       "  '( Several times recently I have wondered whether shows were being staged for the sake of the script or just to entertain the audience with the spectacle of scenery being shifted right in front of their eyes .',\n",
       "  'No one who has studied the radical Right can suppose that words are their sole staple in trade .',\n",
       "  \"If the demand for demythologization is unavoidable and so must be accepted by theology unconditionally , the position of the `` right '' is clearly untenable .\",\n",
       "  \"Whereas Bultmann 's `` center '' position is structurally inconsistent and is therefore indefensible on formal grounds alone , the general position of the `` right '' , as represented , say , by Karl Barth , involves the rejection or at least qualification of the demand for demythologization and so is invalidated on the material grounds we have just considered .\",\n",
       "  \"It will be recalled from the discussion in Section 7 that the position of the `` right '' , as represented by Barth , rests on the following thesis : The only tenable alternative to Bultmann 's position is a theology that ( 1 ) rejects or at least qualifies his unconditioned demand for demythologization and existential interpretation ; ( 2 ) accepts instead a special biblical hermeneutics or method of interpretation ; and ( 3 ) in so doing , frees itself to give appropriate emphasis to the event Jesus Christ by means of statements that , from Bultmann 's point of view , are mythological .\",\n",
       "  'Whitey Herzog , performing in right as the Orioles fielded possibly their strongest team of the spring , worked Keegan for a base on balls .',\n",
       "  \"The Orioles got a run in the first inning when Breeding , along with Robinson , the two Birds who got a pair of hits , doubled to right center , moved to third on Russ Snyder 's single to right and crossed on Kunkel 's wild pitch into the dirt in front of the plate .\",\n",
       "  \"The Orioles got a run in the first inning when Breeding , along with Robinson , the two Birds who got a pair of hits , doubled to right center , moved to third on Russ Snyder 's single to right and crossed on Kunkel 's wild pitch into the dirt in front of the plate .\",\n",
       "  \"Lumpe worked a walk as the first batter to face Hyde and romped around as Siebern blasted Hyde 's next toss 415 feet over the scoreboard in right center .\",\n",
       "  'In the third Frank Robinson hammered a long home run deep into the corner of the bleachers in right center , about 400 feet away , with two men on .',\n",
       "  'Natural gas public utility companies would be given the right of eminent domain , under a bill by Sen. Frank Owen /3 , of El Paso , to acquire sites for underground storage reservoirs for gas .',\n",
       "  'If to be a Christian means to say yes where I otherwise say no , or where I do not have the right to say anything at all , then my only choice is to refuse to be a Christian .',\n",
       "  'The largest of these organizations at present denies to the full time educator any vote on the conduct and standards of the group and , indeed , refuses him even the right to attach the customary initials after his name in the college catalog .',\n",
       "  \"As for states ' rights , they have never counted in the thinking of my liberal friends except as irritations of a minor and immoral nature which exist now only as anachronisms .\",\n",
       "  'And if he is so scornful of the rights of states , why not advocate a different sort of constitution that he could more sincerely support ?',\n",
       "  \"It is convenient to classify a child 's onset ages and completion ages as `` advanced '' , `` moderate '' ( modal ) , or `` delayed '' according to whether the child 's age equivalent `` dots '' appeared to the left of , upon , or to the right of the appropriate short transverse line .\",\n",
       "  'Until the Charter of Liberties was issued in the fall of 1958 , there were no guarantees of the right to assemble or to organize for political purposes .',\n",
       "  'Because community not severalty of property is the law of nature no man can assert an absolutely unalterable right to what is his .',\n",
       "  \"The editor of the Daily Journal warned , `` that if such a demonstration be made , it will not find support or countenance from any of the men whose names are recognized as having a right to speak for Providence '' .\",\n",
       "  'Whereas , John Brown has cheerfully risked his life in endeavoring to deliver those who are denied all rights and is this day doomed to suffer death for his efforts in behalf of those who have no helper :',\n",
       "  \"`` If they are here , then surely I have the right to be here '' , Rousseau said .\",\n",
       "  '`` And even more right .',\n",
       "  \"What made him think John had a right to witness his brother 's humiliation ?\",\n",
       "  'What right had John to any special consideration ?',\n",
       "  'We unanimously agreed that Prokofieff had won his rights as a world citizen to the first ranks of Twentieth Century Composers .',\n",
       "  \"Also , reserve the right to demand proof of death despite the fact that you 'll probably never use it .\",\n",
       "  'In those days , a wife had mighty few rights in the domestic sphere and even fewer in the sexual sphere .',\n",
       "  \"Immediately , the religious groups of the city were embroiled in an angry dispute over the alleged invasion of a man 's right to freedom of religious belief and conscience .\",\n",
       "  'By what right of superior virtue , Southerners ask , do the people of the North do this ?',\n",
       "  'If these people were denied a voice ( do they have a moral right to a voice ? )',\n",
       "  \"And here again we hear the same refrain mentioned above : `` The paramount goal of the United States , set long ago , was to guard the rights of the individual , ensure his development , enlarge his opportunity '' .\",\n",
       "  'The right to leave legacies should be substantially reduced and ultimately eliminated .',\n",
       "  'Attorney General Palmer made a series of raids that sent more than 4000 so-called radicals to the jails , in direct violation of their constitutional rights .',\n",
       "  'acquire secret processes , technical data , inventions , patent applications , patents , licenses , land and interests in land ( including water rights ) , plants and facilities , and other property or rights by purchase , license , lease , or donation ;',\n",
       "  'This subsection shall not be so construed as to deprive the owner of any background patent relating thereto of such rights as he may have thereunder .',\n",
       "  'In addition to the penalties provided in title 18 , United States Code , section 1001 , any person guilty of any act , as provided therein , with respect to any matter under this Title , shall forfeit all rights under this Title , and , if payment shall have been made or granted , the Commission shall take such action as may be necessary to recover the same .',\n",
       "  'Whoever , in the United States or elsewhere , pays or offers to pay , or promises to pay , or receives on account of services rendered or to be rendered in connection with any such claim , compensation which , when added to any amount previously paid on account of such services , will exceed the amount of fees so determined by the Commission , shall be guilty of a misdemeanor , and , upon conviction thereof , shall be fined not more than $ 5000 or imprisoned not more than twelve months , or both , and if any such payment shall have been made or granted , the Commission shall take such action as may be necessary to recover the same , and , in addition thereto , any such person shall forfeit all rights under this title .',\n",
       "  \"In addition , the right to vote the General Motors stock held by du Pont was to be vested in du Pont 's stockholders , other than Christiana and Delaware and the stockholders of Delaware ; du Pont , Christiana , and Delaware were to be enjoined from acquiring stock in or exercising control over General Motors ; du Pont , Christiana , and Delaware were to be prohibited to have any director or officer in common with General Motors , and vice versa ; and General Motors and du Pont were to be ordered to terminate any agreement that provided for the purchase by General Motors of any specified percentage of its requirements of any du Pont manufactured product , or for the grant of exclusive patent rights , or for a grant by General Motors to du Pont of a preferential right to make or sell any chemical discovery of General Motors , or for the maintenance of any joint commercial enterprise by the two companies .\",\n",
       "  \"Du Pont would be denied the right to acquire any additional General Motors stock except through General Motors ' distributions of stock or subscription rights to its stockholders .\",\n",
       "  \"He claims that he was denied due process of law in violation of the Fifth Amendment , because ( 1 ) at a hearing before a hearing officer of the Department of Justice , he was not permitted to rebut statements attributed to him by the local board , and ( 2 ) at the trial , he was denied the right to have the hearing officer 's report and the original report of the Federal Bureau of Investigation as to his claim .\",\n",
       "  \"He says that he was not permitted to rebut before the hearing officer statements attributed to him by the local board , and , further , that he was denied at trial the right to have the Department of Justice hearing officer 's report and the original report of the Federal Bureau of Investigation as to his claim - all in violation of the Fifth Amendment .\",\n",
       "  'Petitioner also claimed at trial the right to inspect the original Federal Bureau of Investigation reports to the Department of Justice .',\n",
       "  'He bases his present contention on the general right to explore , indicating that he hopes to find some discrepancy in the resume .',\n",
       "  'A minor is subject to tax on his own earnings even though his parent may , under local law , have the right to them and might actually have received the money .',\n",
       "  \"And he certainly could n't have guessed that she would resist his demand for the gold or that she was not the yielding - yes , and credible fool he had every right to expect .\",\n",
       "  'Kitti was thirty years younger than Stanley , taller than Stanley , prettier than Stanley had any right to hope for , much less expect .',\n",
       "  \"`` You mean anyone who stood up for his rights '' , Curt said .\",\n",
       "  'What the hell right did Eddie have saying a thing like that ?',\n",
       "  'At right is a casual style in a crushed unlined white leather .',\n",
       "  'Only too often , however , you have the feeling that you are sitting in a room with some of the instruments lined up on one wall to your left and others facing them on the wall to your right .',\n",
       "  \"With the first reports , Russell 's horse wheeled to the right and ran towards the buildings while Cook , followed by a hail of bullets , raced towards the arroyo of Salyer 's Canyon immediately in front of him , just reaching it as his horse fell .\",\n",
       "  'On their right rose the embankment covered with brush and trees .',\n",
       "  'Thus , stealthily they advanced upstream ; then they turned to the right , climbed the embankment , and walked into the valley again .',\n",
       "  'Her quarters were on the right as you walked into the building , and her small front room was clogged with heavy furniture - a big , round , oak dining table and chairs , a buffet , with a row of unclaimed letters inserted between the mirror and its frame .',\n",
       "  'Mynheer , Sir Francis , the valley society , the very smell of the river on his right purling along to the bay past fish weirs and rocks , and ahead the sleepy ribbon of moon drenched road .',\n",
       "  'Scarcity of paper caused many Southerners to adopt the practice of cross writing , i. e. , after writing from left to right of the page in the usual manner , they gave the sheet a half turn and wrote from end to end across the lines previously written .',\n",
       "  \"Private Jenkins Lloyd Jones of the Wisconsin Light Artillery wrote in his diary : `` I strolled among the Alabamans on the right , found some of the greenest specimens of humanity I think in the universe their ignorance being little less than the slave they despise with as imperfect a dialect ' They Recooned as how you ' uns all would be a heap wus to we ' uns all '' ' .\",\n",
       "  'He walked with a heavy list to the right , as that leg was four inches shorter than the other , but the lurch did not reduce his feline quickness with his guns .',\n",
       "  'Chandler , looking to right and left to see how his men were faring , suddenly saw another figure bounding up the hill , hurling grenades and hollering the battle cry as he ran .',\n",
       "  \"Cooper was beside his car , on the curb at the right , just standing there morosely ; he did n't even look up .\",\n",
       "  'He slammed into the wall , bounced back , and caught Curt with a roundhouse right which sent him spinning .',\n",
       "  'Regardless of rights and wrongs , a population and an area appropriate to a pre World War I , great power have been , following conquest , ruled against their will by a neighboring people , and have had imposed upon them social and economic controls they dislike .'],\n",
       " [[['It'],\n",
       "   Tree(Lemma('have.v.02.have'), ['has']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('fast.a.01.fast'), ['fast']),\n",
       "   Tree(Lemma('pace.n.01.pace'), ['pace']),\n",
       "   [','],\n",
       "   Tree(Lemma('excellent.s.01.excellent'), ['excellent']),\n",
       "   Tree(Lemma('music.n.01.music'), ['music']),\n",
       "   [','],\n",
       "   Tree(Lemma('adept.s.01.expert'), ['expert']),\n",
       "   Tree(Lemma('management.n.01.direction'), ['direction']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree('not_only.r.00', ['not', 'only']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('good.a.01.good'), ['good']),\n",
       "   Tree(Lemma('comedian.n.01.comedian'), ['comedian']),\n",
       "   [','],\n",
       "   ['but'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('appealing.a.01.appealing'), ['appealing']),\n",
       "   Tree(Lemma('person.n.01.person'), ['person']),\n",
       "   ['in'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('own.s.01.own'), ['own']),\n",
       "   Tree(Lemma('right.n.06.right'), ['right']),\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Mr.', 'Berman'])]),\n",
       "   ['.']],\n",
       "  [['('],\n",
       "   Tree(Lemma('several.s.03.several'), ['Several']),\n",
       "   Tree(Lemma('time.n.01.time'), ['times']),\n",
       "   Tree(Lemma('recently.r.01.recently'), ['recently']),\n",
       "   ['I'],\n",
       "   ['have'],\n",
       "   Tree(Lemma('wonder.v.02.wonder'), ['wondered']),\n",
       "   ['whether'],\n",
       "   Tree(Lemma('show.n.01.show'), ['shows']),\n",
       "   ['were'],\n",
       "   ['being'],\n",
       "   Tree(Lemma('stage.v.01.stage'), ['staged']),\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('sake.n.01.sake'), ['sake']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('script.n.01.script'), ['script']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('merely.r.01.just'), ['just']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('entertain.v.01.entertain'), ['entertain']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('audience.n.01.audience'), ['audience']),\n",
       "   ['with'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('spectacle.n.02.spectacle'), ['spectacle']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('scenery.n.01.scenery'), ['scenery']),\n",
       "   ['being'],\n",
       "   Tree(Lemma('shift.v.02.shift'), ['shifted']),\n",
       "   Tree(Lemma('right.n.06.right'), ['right']),\n",
       "   ['in', 'front', 'of'],\n",
       "   ['their'],\n",
       "   Tree(Lemma('eye.n.01.eye'), ['eyes']),\n",
       "   ['.']],\n",
       "  [['No'],\n",
       "   ['one'],\n",
       "   ['who'],\n",
       "   ['has'],\n",
       "   Tree(Lemma('learn.v.04.study'), ['studied']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('extremist.s.01.radical'), ['radical']),\n",
       "   Tree(Lemma('right.n.04.right'), ['Right']),\n",
       "   ['can'],\n",
       "   Tree(Lemma('speculate.v.01.suppose'), ['suppose']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('words.n.01.words'), ['words']),\n",
       "   Tree(Lemma('constitute.v.01.be'), ['are']),\n",
       "   ['their'],\n",
       "   Tree('sole.s.00', ['sole']),\n",
       "   Tree(Lemma('basic.n.02.staple'), ['staple']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('trade.n.02.trade'), ['trade']),\n",
       "   ['.']],\n",
       "  [['If'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('demand.n.01.demand'), ['demand']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('demythologization.n.01.demythologization'), ['demythologization']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('ineluctable.s.01.unavoidable'), ['unavoidable']),\n",
       "   ['and'],\n",
       "   ['so'],\n",
       "   ['must'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('accept.v.03.accept'), ['accepted']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('theology.n.01.theology'), ['theology']),\n",
       "   Tree(Lemma('unconditionally.r.01.unconditionally'), ['unconditionally']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('position.n.03.position'), ['position']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('right.n.04.right'), ['right']),\n",
       "   [\"''\"],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('clearly.r.01.clearly'), ['clearly']),\n",
       "   Tree(Lemma('indefensible.s.01.untenable'), ['untenable']),\n",
       "   ['.']],\n",
       "  [['Whereas'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Bultmann'])]),\n",
       "   [\"'s\"],\n",
       "   ['``'],\n",
       "   Tree(Lemma('center.n.12.center'), ['center']),\n",
       "   [\"''\"],\n",
       "   Tree(Lemma('position.n.03.position'), ['position']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('structurally.r.01.structurally'), ['structurally']),\n",
       "   Tree(Lemma('inconsistent.s.02.inconsistent'), ['inconsistent']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('therefore.r.01.therefore'), ['therefore']),\n",
       "   Tree(Lemma('indefensible.s.01.indefensible'), ['indefensible']),\n",
       "   ['on'],\n",
       "   Tree(Lemma('formal.a.03.formal'), ['formal']),\n",
       "   Tree(Lemma('reason.n.01.ground'), ['grounds']),\n",
       "   Tree(Lemma('entirely.r.02.alone'), ['alone']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('general.a.01.general'), ['general']),\n",
       "   Tree(Lemma('position.n.03.position'), ['position']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('right.n.04.right'), ['right']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   ['as'],\n",
       "   Tree(Lemma('represent.v.03.represent'), ['represented']),\n",
       "   [','],\n",
       "   ['say'],\n",
       "   [','],\n",
       "   ['by'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Karl', 'Barth'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('necessitate.v.01.involve'), ['involves']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('rejection.n.01.rejection'), ['rejection']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('at_least.r.01.at_least'), ['at', 'least']),\n",
       "   Tree(Lemma('qualification.n.02.qualification'), ['qualification']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('demand.n.01.demand'), ['demand']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('demythologization.n.01.demythologization'), ['demythologization']),\n",
       "   ['and'],\n",
       "   ['so'],\n",
       "   ['is'],\n",
       "   Tree(Lemma('invalidate.v.01.invalidate'), ['invalidated']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('material.a.03.material'), ['material']),\n",
       "   Tree(Lemma('reason.n.01.ground'), ['grounds']),\n",
       "   ['we'],\n",
       "   ['have'],\n",
       "   Tree(Lemma('just.r.03.just'), ['just']),\n",
       "   Tree(Lemma('consider.v.04.consider'), ['considered']),\n",
       "   ['.']],\n",
       "  [['It'],\n",
       "   ['will'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('remember.v.01.recall'), ['recalled']),\n",
       "   ['from'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('discussion.n.01.discussion'), ['discussion']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('section.n.01.section'), ['Section']),\n",
       "   Tree(Lemma('seven.s.01.7'), ['7']),\n",
       "   ['that'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('position.n.03.position'), ['position']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('right.n.04.right'), ['right']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   ['as'],\n",
       "   Tree(Lemma('represent.v.03.represent'), ['represented']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Barth'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('repose_on.v.01.rest_on'), ['rests', 'on']),\n",
       "   ['the'],\n",
       "   Tree('following.s.01', ['following']),\n",
       "   Tree(Lemma('thesis.n.01.thesis'), ['thesis']),\n",
       "   [':'],\n",
       "   ['The'],\n",
       "   Tree(Lemma('entirely.r.02.only'), ['only']),\n",
       "   Tree(Lemma('tenable.s.01.tenable'), ['tenable']),\n",
       "   Tree(Lemma('option.n.02.alternative'), ['alternative']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Bultmann'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('position.n.03.position'), ['position']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   ['a'],\n",
       "   Tree('theology.n.1;2', ['theology']),\n",
       "   ['that'],\n",
       "   ['('],\n",
       "   ['1'],\n",
       "   [')'],\n",
       "   Tree(Lemma('reject.v.01.reject'), ['rejects']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('at_least.r.01.at_least'), ['at', 'least']),\n",
       "   Tree(Lemma('qualify.v.03.qualify'), ['qualifies']),\n",
       "   ['his'],\n",
       "   Tree('unconditioned.s.00', ['unconditioned']),\n",
       "   Tree(Lemma('demand.n.01.demand'), ['demand']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('demythologization.n.01.demythologization'), ['demythologization']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('experiential.s.02.existential'), ['existential']),\n",
       "   Tree(Lemma('interpretation.n.01.interpretation'), ['interpretation']),\n",
       "   [';'],\n",
       "   ['('],\n",
       "   ['2'],\n",
       "   [')'],\n",
       "   Tree(Lemma('accept.v.01.accept'), ['accepts']),\n",
       "   Tree(Lemma('rather.r.01.instead'), ['instead']),\n",
       "   ['a'],\n",
       "   Tree('special.s.4;1', ['special']),\n",
       "   Tree(Lemma('biblical.a.01.biblical'), ['biblical']),\n",
       "   Tree(Lemma('hermeneutics.n.01.hermeneutics'), ['hermeneutics']),\n",
       "   ['or'],\n",
       "   Tree('method.n.00', ['method']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('interpretation.n.01.interpretation'), ['interpretation']),\n",
       "   [';'],\n",
       "   ['and'],\n",
       "   ['('],\n",
       "   ['3'],\n",
       "   [')'],\n",
       "   ['in'],\n",
       "   Tree(Lemma('so.r.03.so'), ['so']),\n",
       "   ['doing'],\n",
       "   [','],\n",
       "   Tree(Lemma('free.v.06.free'), ['frees']),\n",
       "   ['itself'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('give.v.10.give'), ['give']),\n",
       "   Tree(Lemma('appropriate.a.01.appropriate'), ['appropriate']),\n",
       "   Tree(Lemma('emphasis.n.01.emphasis'), ['emphasis']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('event.n.01.event'), ['event']),\n",
       "   Tree(Lemma('jesus.n.01.Jesus_Christ'), ['Jesus', 'Christ']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('means.n.01.means'), ['means']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('statement.n.01.statement'), ['statements']),\n",
       "   ['that'],\n",
       "   [','],\n",
       "   ['from'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Bultmann'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('point_of_view.n.01.point_of_view'), ['point', 'of', 'view']),\n",
       "   [','],\n",
       "   Tree(Lemma('be.v.01.be'), ['are']),\n",
       "   Tree(Lemma('fabulous.s.02.mythological'), ['mythological']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Whitey', 'Herzog'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('perform.v.02.perform'), ['performing']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('right_field.n.01.right'), ['right']),\n",
       "   ['as'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Orioles'])]),\n",
       "   Tree(Lemma('field.v.02.field'), ['fielded']),\n",
       "   Tree(Lemma('possibly.r.01.possibly'), ['possibly']),\n",
       "   ['their'],\n",
       "   Tree(Lemma('strong.a.01.strong'), ['strongest']),\n",
       "   Tree(Lemma('team.n.01.team'), ['team']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('spring.n.01.spring'), ['spring']),\n",
       "   [','],\n",
       "   Tree(Lemma('cultivate.v.02.work'), ['worked']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Keegan'])]),\n",
       "   ['for'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('base_on_balls.n.01.base_on_balls'), ['base', 'on', 'balls']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Orioles'])]),\n",
       "   Tree(Lemma('have.v.17.get'), ['got']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('run.n.01.run'), ['run']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('first.a.01.first'), ['first']),\n",
       "   Tree(Lemma('inning.n.01.inning'), ['inning']),\n",
       "   ['when'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Breeding'])]),\n",
       "   [','],\n",
       "   ['along'],\n",
       "   ['with'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Robinson'])]),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('two.s.01.two'), ['two']),\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Birds'])]),\n",
       "   ['who'],\n",
       "   Tree(Lemma('have.v.17.get'), ['got']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('couple.n.04.pair'), ['pair']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('hit.n.01.hit'), ['hits']),\n",
       "   [','],\n",
       "   Tree(Lemma('double.v.02.double'), ['doubled']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('right_field.n.01.right'), ['right']),\n",
       "   Tree(Lemma('center_field.n.01.center'), ['center']),\n",
       "   [','],\n",
       "   Tree(Lemma('travel.v.01.move'), ['moved']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('third_base.n.02.third'), ['third']),\n",
       "   ['on'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Russ', 'Snyder'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('single.n.01.single'), ['single']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('right_field.n.01.right'), ['right']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('traverse.v.01.cross'), ['crossed']),\n",
       "   ['on'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Kunkel'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('wild_pitch.n.01.wild_pitch'), ['wild', 'pitch']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('soil.n.02.dirt'), ['dirt']),\n",
       "   Tree(Lemma('ahead.r.01.in_front'), ['in', 'front']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('home_plate.n.01.plate'), ['plate']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Orioles'])]),\n",
       "   Tree(Lemma('have.v.17.get'), ['got']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('run.n.01.run'), ['run']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('first.a.01.first'), ['first']),\n",
       "   Tree(Lemma('inning.n.01.inning'), ['inning']),\n",
       "   ['when'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Breeding'])]),\n",
       "   [','],\n",
       "   ['along'],\n",
       "   ['with'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Robinson'])]),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('two.s.01.two'), ['two']),\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Birds'])]),\n",
       "   ['who'],\n",
       "   Tree(Lemma('have.v.17.get'), ['got']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('couple.n.04.pair'), ['pair']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('hit.n.01.hit'), ['hits']),\n",
       "   [','],\n",
       "   Tree(Lemma('double.v.02.double'), ['doubled']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('right_field.n.01.right'), ['right']),\n",
       "   Tree(Lemma('center_field.n.01.center'), ['center']),\n",
       "   [','],\n",
       "   Tree(Lemma('travel.v.01.move'), ['moved']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('third_base.n.02.third'), ['third']),\n",
       "   ['on'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Russ', 'Snyder'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('single.n.01.single'), ['single']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('right_field.n.01.right'), ['right']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('traverse.v.01.cross'), ['crossed']),\n",
       "   ['on'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Kunkel'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('wild_pitch.n.01.wild_pitch'), ['wild', 'pitch']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('soil.n.02.dirt'), ['dirt']),\n",
       "   Tree(Lemma('ahead.r.01.in_front'), ['in', 'front']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('home_plate.n.01.plate'), ['plate']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Lumpe'])]),\n",
       "   Tree(Lemma('cultivate.v.02.work'), ['worked']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('base_on_balls.n.01.walk'), ['walk']),\n",
       "   ['as'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('first.s.02.first'), ['first']),\n",
       "   Tree(Lemma('batter.n.01.batter'), ['batter']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('confront.v.01.face'), ['face']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Hyde'])]),\n",
       "   ['and'],\n",
       "   Tree(Lemma('frolic.v.01.romp'), ['romped']),\n",
       "   Tree(Lemma('about.r.04.around'), ['around']),\n",
       "   ['as'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Siebern'])]),\n",
       "   Tree(Lemma('smash.v.01.blast'), ['blasted']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Hyde'])]),\n",
       "   [\"'s\"],\n",
       "   Tree('next.s.01', ['next']),\n",
       "   Tree(Lemma('pass.n.15.toss'), ['toss']),\n",
       "   ['415'],\n",
       "   Tree(Lemma('foot.n.02.foot'), ['feet']),\n",
       "   ['over'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('scoreboard.n.01.scoreboard'), ['scoreboard']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('right_field.n.01.right'), ['right']),\n",
       "   Tree(Lemma('center_field.n.01.center'), ['center']),\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('third.s.01.third'), ['third']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Frank', 'Robinson'])]),\n",
       "   Tree(Lemma('hammer.v.01.hammer'), ['hammered']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('long.a.02.long'), ['long']),\n",
       "   Tree(Lemma('homer.n.01.home_run'), ['home', 'run']),\n",
       "   Tree(Lemma('deep.s.04.deep'), ['deep']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('corner.n.01.corner'), ['corner']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bleachers.n.01.bleachers'), ['bleachers']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('right_field.n.01.right'), ['right']),\n",
       "   Tree(Lemma('center_field.n.01.center'), ['center']),\n",
       "   [','],\n",
       "   ['about'],\n",
       "   ['400'],\n",
       "   Tree(Lemma('foot.n.02.foot'), ['feet']),\n",
       "   Tree('away.s.00', ['away']),\n",
       "   [','],\n",
       "   ['with'],\n",
       "   Tree(Lemma('two.s.01.two'), ['two']),\n",
       "   Tree(Lemma('man.n.01.man'), ['men']),\n",
       "   ['on'],\n",
       "   ['.']],\n",
       "  [Tree(Lemma('natural_gas.n.01.natural_gas'), ['Natural', 'gas']),\n",
       "   Tree(Lemma('utility.n.01.public_utility'), ['public', 'utility']),\n",
       "   Tree(Lemma('company.n.01.company'), ['companies']),\n",
       "   ['would'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('give.v.03.give'), ['given']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('eminent_domain.n.01.eminent_domain'), ['eminent', 'domain']),\n",
       "   [','],\n",
       "   ['under'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('bill.n.01.bill'), ['bill']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Sen.', 'Frank', 'Owen'])]),\n",
       "   ['/3'],\n",
       "   [','],\n",
       "   ['of'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['El', 'Paso'])]),\n",
       "   [','],\n",
       "   ['to'],\n",
       "   Tree(Lemma('get.v.01.acquire'), ['acquire']),\n",
       "   Tree(Lemma('site.n.01.site'), ['sites']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('belowground.s.01.underground'), ['underground']),\n",
       "   Tree(Lemma('storehouse.n.01.storage'), ['storage']),\n",
       "   Tree(Lemma('reservoir.n.03.reservoir'), ['reservoirs']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('gasoline.n.01.gas'), ['gas']),\n",
       "   ['.']],\n",
       "  [['If'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('christian.n.01.Christian'), ['Christian']),\n",
       "   Tree(Lemma('entail.v.01.mean'), ['means']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('state.v.01.say'), ['say']),\n",
       "   ['yes'],\n",
       "   ['where'],\n",
       "   ['I'],\n",
       "   Tree(Lemma('otherwise.r.01.otherwise'), ['otherwise']),\n",
       "   Tree(Lemma('state.v.01.say'), ['say']),\n",
       "   ['no'],\n",
       "   [','],\n",
       "   ['or'],\n",
       "   ['where'],\n",
       "   ['I'],\n",
       "   ['do'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('have.v.01.have'), ['have']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('state.v.01.say'), ['say']),\n",
       "   ['anything'],\n",
       "   Tree(Lemma('at_all.r.01.at_all'), ['at', 'all']),\n",
       "   [','],\n",
       "   Tree(Lemma('then.r.02.then'), ['then']),\n",
       "   ['my'],\n",
       "   Tree('only.s.00', ['only']),\n",
       "   Tree(Lemma('option.n.02.choice'), ['choice']),\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('refuse.v.01.refuse'), ['refuse']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('christian.n.01.Christian'), ['Christian']),\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree('largest.s.00', ['largest']),\n",
       "   ['of'],\n",
       "   ['these'],\n",
       "   Tree(Lemma('organization.n.01.organization'), ['organizations']),\n",
       "   Tree(Lemma('now.r.04.at_present'), ['at', 'present']),\n",
       "   Tree(Lemma('deny.v.04.deny'), ['denies']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('full-time.a.01.full-time'), ['full', 'time']),\n",
       "   Tree(Lemma('educator.n.01.educator'), ['educator']),\n",
       "   ['any'],\n",
       "   Tree(Lemma('vote.n.01.vote'), ['vote']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('demeanor.n.01.conduct'), ['conduct']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('criterion.n.02.standard'), ['standards']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), ['group']),\n",
       "   ['and'],\n",
       "   [','],\n",
       "   Tree(Lemma('indeed.r.01.indeed'), ['indeed']),\n",
       "   [','],\n",
       "   Tree(Lemma('deny.v.04.refuse'), ['refuses']),\n",
       "   ['him'],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('attach.v.01.attach'), ['attach']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('customary.s.01.customary'), ['customary']),\n",
       "   Tree(Lemma('initial.n.01.initial'), ['initials']),\n",
       "   ['after'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('name.n.01.name'), ['name']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('college.n.01.college'), ['college']),\n",
       "   Tree(Lemma('catalog.n.02.catalog'), ['catalog']),\n",
       "   ['.']],\n",
       "  [['As'],\n",
       "   ['for'],\n",
       "   Tree(Lemma('state.n.01.state'), ['states']),\n",
       "   [\"'\"],\n",
       "   Tree(Lemma('right.n.01.right'), ['rights']),\n",
       "   [','],\n",
       "   ['they'],\n",
       "   ['have'],\n",
       "   Tree(Lemma('never.r.01.never'), ['never']),\n",
       "   Tree(Lemma('count.v.02.count'), ['counted']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('thinking.n.01.thinking'), ['thinking']),\n",
       "   ['of'],\n",
       "   ['my'],\n",
       "   Tree(Lemma('liberal.n.01.liberal'), ['liberal']),\n",
       "   Tree(Lemma('friend.n.01.friend'), ['friends']),\n",
       "   ['except'],\n",
       "   ['as'],\n",
       "   Tree(Lemma('irritation.n.01.irritation'), ['irritations']),\n",
       "   ['of'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('minor.a.03.minor'), ['minor']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('base.s.04.immoral'), ['immoral']),\n",
       "   Tree(Lemma('nature.n.01.nature'), ['nature']),\n",
       "   ['which'],\n",
       "   Tree(Lemma('exist.v.01.exist'), ['exist']),\n",
       "   Tree(Lemma('nowadays.r.01.now'), ['now']),\n",
       "   Tree(Lemma('merely.r.01.only'), ['only']),\n",
       "   ['as'],\n",
       "   Tree(Lemma('anachronism.n.01.anachronism'), ['anachronisms']),\n",
       "   ['.']],\n",
       "  [['And'],\n",
       "   ['if'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree(Lemma('so.r.01.so'), ['so']),\n",
       "   Tree(Lemma('contemptuous.s.01.scornful'), ['scornful']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['rights']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('state.n.01.state'), ['states']),\n",
       "   [','],\n",
       "   Tree('why.r.00', ['why']),\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('recommend.v.01.advocate'), ['advocate']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('different.s.02.different'), ['different']),\n",
       "   Tree(Lemma('kind.n.01.sort'), ['sort']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('fundamental_law.n.01.constitution'), ['constitution']),\n",
       "   ['that'],\n",
       "   ['he'],\n",
       "   ['could'],\n",
       "   Tree(Lemma('more.r.01.more'), ['more']),\n",
       "   Tree(Lemma('sincerely.r.01.sincerely'), ['sincerely']),\n",
       "   Tree(Lemma('subscribe.v.03.support'), ['support']),\n",
       "   ['?']],\n",
       "  [['It'],\n",
       "   ['is'],\n",
       "   Tree(Lemma('convenient.a.01.convenient'), ['convenient']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('classify.v.01.classify'), ['classify']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('child.n.01.child'), ['child']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('onset.n.01.onset'), ['onset']),\n",
       "   Tree(Lemma('age.n.01.age'), ['ages']),\n",
       "   ['and'],\n",
       "   Tree('completion.n.00', ['completion']),\n",
       "   Tree(Lemma('age.n.01.age'), ['ages']),\n",
       "   ['as'],\n",
       "   ['``'],\n",
       "   Tree(Lemma('advanced.s.01.advanced'), ['advanced']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   ['``'],\n",
       "   Tree(Lemma('moderate.a.01.moderate'), ['moderate']),\n",
       "   [\"''\"],\n",
       "   ['('],\n",
       "   Tree(Lemma('modal.s.01.modal'), ['modal']),\n",
       "   [')'],\n",
       "   [','],\n",
       "   ['or'],\n",
       "   ['``'],\n",
       "   Tree('delayed.a.00', ['delayed']),\n",
       "   [\"''\"],\n",
       "   ['according', 'to'],\n",
       "   ['whether'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('child.n.01.child'), ['child']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('age.n.01.age'), ['age']),\n",
       "   Tree(Lemma('equivalent.n.01.equivalent'), ['equivalent']),\n",
       "   ['``'],\n",
       "   Tree(Lemma('point.n.09.dot'), ['dots']),\n",
       "   [\"''\"],\n",
       "   Tree(Lemma('appear.v.02.appear'), ['appeared']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('left.n.01.left'), ['left']),\n",
       "   ['of'],\n",
       "   [','],\n",
       "   ['upon'],\n",
       "   [','],\n",
       "   ['or'],\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('appropriate.a.01.appropriate'), ['appropriate']),\n",
       "   Tree(Lemma('short.a.02.short'), ['short']),\n",
       "   Tree(Lemma('cross.s.01.transverse'), ['transverse']),\n",
       "   Tree(Lemma('line.n.02.line'), ['line']),\n",
       "   ['.']],\n",
       "  [['Until'],\n",
       "   ['the'],\n",
       "   Tree('NE', ['Charter', 'of', 'Liberties']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('publish.v.02.issue'), ['issued']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('fall.n.01.fall'), ['fall']),\n",
       "   ['of'],\n",
       "   ['1958'],\n",
       "   [','],\n",
       "   ['there'],\n",
       "   Tree(Lemma('exist.v.01.be'), ['were']),\n",
       "   ['no'],\n",
       "   Tree(Lemma('guarantee.n.01.guarantee'), ['guarantees']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('meet.v.07.assemble'), ['assemble']),\n",
       "   ['or'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('unionize.v.02.organize'), ['organize']),\n",
       "   ['for'],\n",
       "   Tree(Lemma('political.a.03.political'), ['political']),\n",
       "   Tree(Lemma('purpose.n.01.purpose'), ['purposes']),\n",
       "   ['.']],\n",
       "  [['Because'],\n",
       "   Tree(Lemma('community.n.02.community'), ['community']),\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('discreteness.n.01.severalty'), ['severalty']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('property.n.01.property'), ['property']),\n",
       "   Tree(Lemma('be.v.02.be'), ['is']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('law.n.04.law_of_nature'), ['law', 'of', 'nature']),\n",
       "   ['no'],\n",
       "   Tree(Lemma('man.n.01.man'), ['man']),\n",
       "   ['can'],\n",
       "   Tree(Lemma('assert.v.01.assert'), ['assert']),\n",
       "   ['an'],\n",
       "   Tree(Lemma('absolutely.r.01.absolutely'), ['absolutely']),\n",
       "   Tree(Lemma('unalterable.a.01.unalterable'), ['unalterable']),\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   ['what'],\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   ['his'],\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('editor.n.01.editor'), ['editor']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Daily', 'Journal'])]),\n",
       "   Tree(Lemma('warn.v.01.warn'), ['warned']),\n",
       "   [','],\n",
       "   ['``'],\n",
       "   ['that'],\n",
       "   ['if'],\n",
       "   Tree('such.s.00', ['such']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('demonstration.n.03.demonstration'), ['demonstration']),\n",
       "   ['be'],\n",
       "   Tree(Lemma('make.v.01.make'), ['made']),\n",
       "   [','],\n",
       "   ['it'],\n",
       "   ['will'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('receive.v.02.find'), ['find']),\n",
       "   Tree(Lemma('support.n.03.support'), ['support']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('sanction.n.01.countenance'), ['countenance']),\n",
       "   ['from'],\n",
       "   ['any'],\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('man.n.01.man'), ['men']),\n",
       "   ['whose'],\n",
       "   Tree(Lemma('name.n.01.name'), ['names']),\n",
       "   ['are'],\n",
       "   Tree(Lemma('acknowledge.v.06.recognize'), ['recognized']),\n",
       "   ['as'],\n",
       "   Tree(Lemma('have.v.01.have'), ['having']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('speak_for.v.01.speak_for'), ['speak', 'for']),\n",
       "   Tree(Lemma('providence.n.01.Providence'), ['Providence']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['Whereas'],\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['John', 'Brown'])]),\n",
       "   ['has'],\n",
       "   Tree(Lemma('cheerfully.r.01.cheerfully'), ['cheerfully']),\n",
       "   Tree(Lemma('risk.v.01.risk'), ['risked']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('animation.n.01.life'), ['life']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('endeavor.v.01.endeavor'), ['endeavoring']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('rescue.v.01.deliver'), ['deliver']),\n",
       "   ['those'],\n",
       "   ['who'],\n",
       "   ['are'],\n",
       "   Tree(Lemma('deny.v.04.deny'), ['denied']),\n",
       "   ['all'],\n",
       "   Tree(Lemma('right.n.01.right'), ['rights']),\n",
       "   ['and'],\n",
       "   ['is'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('day.n.03.day'), ['day']),\n",
       "   Tree(Lemma('destine.v.01.doom'), ['doomed']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('suffer.v.01.suffer'), ['suffer']),\n",
       "   Tree(Lemma('death.n.03.death'), ['death']),\n",
       "   ['for'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('attempt.n.01.effort'), ['efforts']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('behalf.n.02.behalf'), ['behalf']),\n",
       "   ['of'],\n",
       "   ['those'],\n",
       "   ['who'],\n",
       "   Tree(Lemma('have.v.07.have'), ['have']),\n",
       "   ['no'],\n",
       "   Tree(Lemma('benefactor.n.01.helper'), ['helper']),\n",
       "   [':']],\n",
       "  [['``'],\n",
       "   ['If'],\n",
       "   ['they'],\n",
       "   Tree(Lemma('be.v.03.be'), ['are']),\n",
       "   Tree(Lemma('here.r.01.here'), ['here']),\n",
       "   [','],\n",
       "   Tree(Lemma('then.r.02.then'), ['then']),\n",
       "   Tree(Lemma('surely.r.01.surely'), ['surely']),\n",
       "   ['I'],\n",
       "   Tree(Lemma('have.v.01.have'), ['have']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('be.v.03.be'), ['be']),\n",
       "   Tree(Lemma('here.r.01.here'), ['here']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Rousseau'])]),\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   ['And'],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   Tree(Lemma('more.a.01.more'), ['more']),\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['.']],\n",
       "  [['What'],\n",
       "   Tree(Lemma('induce.v.02.make'), ['made']),\n",
       "   ['him'],\n",
       "   Tree(Lemma('think.v.01.think'), ['think']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['John'])]),\n",
       "   Tree(Lemma('have.v.11.have'), ['had']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('witness.v.01.witness'), ['witness']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('brother.n.01.brother'), ['brother']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('chagrin.n.01.humiliation'), ['humiliation']),\n",
       "   ['?']],\n",
       "  [['What'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   Tree(Lemma('have.v.11.have'), ['had']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['John'])]),\n",
       "   ['to'],\n",
       "   ['any'],\n",
       "   Tree(Lemma('particular.s.01.special'), ['special']),\n",
       "   Tree(Lemma('consideration.n.04.consideration'), ['consideration']),\n",
       "   ['?']],\n",
       "  [['We'],\n",
       "   Tree(Lemma('unanimously.r.01.unanimously'), ['unanimously']),\n",
       "   Tree(Lemma('agree.v.01.agree'), ['agreed']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Prokofieff'])]),\n",
       "   ['had'],\n",
       "   Tree(Lemma('acquire.v.05.win'), ['won']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('right.n.01.right'), ['rights']),\n",
       "   ['as'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('world.n.02.world'), ['world']),\n",
       "   Tree(Lemma('citizen.n.01.citizen'), ['citizen']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('first.s.05.first'), ['first']),\n",
       "   Tree(Lemma('social_station.n.01.rank'), ['ranks']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('twentieth.s.01.twentieth'), ['Twentieth']),\n",
       "   Tree(Lemma('century.n.01.century'), ['Century']),\n",
       "   Tree(Lemma('composer.n.01.composer'), ['Composers']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('besides.r.02.also'), ['Also']),\n",
       "   [','],\n",
       "   Tree('reserve.v.00', ['reserve']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('demand.v.03.demand'), ['demand']),\n",
       "   Tree(Lemma('proof.n.01.proof'), ['proof']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('death.n.03.death'), ['death']),\n",
       "   ['despite'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('fact.n.01.fact'), ['fact']),\n",
       "   ['that'],\n",
       "   ['you'],\n",
       "   [\"'ll\"],\n",
       "   Tree(Lemma('probably.r.01.probably'), ['probably']),\n",
       "   Tree(Lemma('never.r.01.never'), ['never']),\n",
       "   Tree(Lemma('use.v.01.use'), ['use']),\n",
       "   ['it'],\n",
       "   ['.']],\n",
       "  [['In'],\n",
       "   ['those'],\n",
       "   Tree(Lemma('day.n.02.day'), ['days']),\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree(Lemma('wife.n.01.wife'), ['wife']),\n",
       "   Tree(Lemma('have.v.01.have'), ['had']),\n",
       "   Tree(Lemma('mighty.r.01.mighty'), ['mighty']),\n",
       "   Tree(Lemma('few.a.01.few'), ['few']),\n",
       "   Tree(Lemma('right.n.01.right'), ['rights']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('domestic.a.02.domestic'), ['domestic']),\n",
       "   Tree(Lemma('sector.n.03.sphere'), ['sphere']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   Tree(Lemma('fewer.a.01.fewer'), ['fewer']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('sexual.a.01.sexual'), ['sexual']),\n",
       "   Tree(Lemma('sector.n.03.sphere'), ['sphere']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('immediately.r.01.immediately'), ['Immediately']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree('religious.a.00', ['religious']),\n",
       "   Tree(Lemma('group.n.01.group'), ['groups']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('city.n.01.city'), ['city']),\n",
       "   ['were'],\n",
       "   Tree(Lemma('embroil.v.01.embroil'), ['embroiled']),\n",
       "   ['in'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('angry.a.01.angry'), ['angry']),\n",
       "   Tree(Lemma('dispute.n.01.dispute'), ['dispute']),\n",
       "   ['over'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('alleged.s.01.alleged'), ['alleged']),\n",
       "   Tree(Lemma('invasion.n.02.invasion'), ['invasion']),\n",
       "   ['of'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('man.n.03.man'), ['man']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('freedom.n.01.freedom'), ['freedom']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('religion.n.01.religious_belief'), ['religious', 'belief']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('conscience.n.01.conscience'), ['conscience']),\n",
       "   ['.']],\n",
       "  [['By'],\n",
       "   ['what'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('superior.a.02.superior'), ['superior']),\n",
       "   Tree(Lemma('virtue.n.01.virtue'), ['virtue']),\n",
       "   [','],\n",
       "   Tree(Lemma('southerner.n.01.Southerner'), ['Southerners']),\n",
       "   Tree(Lemma('ask.v.03.ask'), ['ask']),\n",
       "   [','],\n",
       "   ['do'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('people.n.01.people'), ['people']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('north.n.01.North'), ['North']),\n",
       "   Tree(Lemma('make.v.01.do'), ['do']),\n",
       "   ['this'],\n",
       "   ['?']],\n",
       "  [['If'],\n",
       "   ['these'],\n",
       "   Tree(Lemma('people.n.01.people'), ['people']),\n",
       "   ['were'],\n",
       "   Tree(Lemma('deny.v.04.deny'), ['denied']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('voice.n.05.voice'), ['voice']),\n",
       "   ['('],\n",
       "   ['do'],\n",
       "   ['they'],\n",
       "   Tree(Lemma('have.v.01.have'), ['have']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('moral.a.01.moral'), ['moral']),\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('voice.n.05.voice'), ['voice']),\n",
       "   ['?'],\n",
       "   [')']],\n",
       "  [['And'],\n",
       "   Tree(Lemma('here.r.02.here'), ['here']),\n",
       "   Tree(Lemma('again.r.01.again'), ['again']),\n",
       "   ['we'],\n",
       "   Tree(Lemma('learn.v.02.hear'), ['hear']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('like.a.02.same'), ['same']),\n",
       "   Tree(Lemma('refrain.n.01.refrain'), ['refrain']),\n",
       "   Tree(Lemma('note.v.01.mention'), ['mentioned']),\n",
       "   ['above'],\n",
       "   [':'],\n",
       "   ['``'],\n",
       "   ['The'],\n",
       "   Tree(Lemma('overriding.s.01.paramount'), ['paramount']),\n",
       "   Tree(Lemma('goal.n.01.goal'), ['goal']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('united_states_government.n.01.United_States'), ['United', 'States']),\n",
       "   [','],\n",
       "   Tree(Lemma('determine.v.03.set'), ['set']),\n",
       "   Tree(Lemma('long_ago.r.01.long_ago'), ['long', 'ago']),\n",
       "   [','],\n",
       "   ['was'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('guard.v.02.guard'), ['guard']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['rights']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('person.n.01.individual'), ['individual']),\n",
       "   [','],\n",
       "   Tree(Lemma('guarantee.v.02.ensure'), ['ensure']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('development.n.02.development'), ['development']),\n",
       "   [','],\n",
       "   Tree(Lemma('enlarge.v.01.enlarge'), ['enlarge']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('opportunity.n.01.opportunity'), ['opportunity']),\n",
       "   [\"''\"],\n",
       "   ['.']],\n",
       "  [['The'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('bequeath.v.01.leave'), ['leave']),\n",
       "   Tree(Lemma('bequest.n.01.legacy'), ['legacies']),\n",
       "   ['should'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('well.r.07.substantially'), ['substantially']),\n",
       "   Tree(Lemma('reduce.v.01.reduce'), ['reduced']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('ultimately.r.01.ultimately'), ['ultimately']),\n",
       "   Tree(Lemma('extinguish.v.04.eliminate'), ['eliminated']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('attorney_general.n.03.Attorney_General'), ['Attorney', 'General']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Palmer'])]),\n",
       "   Tree(Lemma('make.v.01.make'), ['made']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('series.n.01.series'), ['series']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('foray.n.01.raid'), ['raids']),\n",
       "   ['that'],\n",
       "   Tree(Lemma('commit.v.03.send'), ['sent']),\n",
       "   Tree('more_than.r.00', ['more', 'than']),\n",
       "   ['4000'],\n",
       "   Tree(Lemma('alleged.s.02.so-called'), ['so-called']),\n",
       "   Tree(Lemma('radical.n.03.radical'), ['radicals']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('jail.n.01.jail'), ['jails']),\n",
       "   [','],\n",
       "   ['in'],\n",
       "   Tree(Lemma('direct.a.01.direct'), ['direct']),\n",
       "   Tree(Lemma('trespass.n.02.violation'), ['violation']),\n",
       "   ['of'],\n",
       "   ['their'],\n",
       "   Tree('constitutional.a.00', ['constitutional']),\n",
       "   Tree(Lemma('right.n.01.right'), ['rights']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('get.v.01.acquire'), ['acquire']),\n",
       "   Tree(Lemma('secret.s.01.secret'), ['secret']),\n",
       "   Tree(Lemma('procedure.n.01.process'), ['processes']),\n",
       "   [','],\n",
       "   Tree(Lemma('technical.a.02.technical'), ['technical']),\n",
       "   Tree(Lemma('data.n.01.data'), ['data']),\n",
       "   [','],\n",
       "   Tree(Lemma('invention.n.02.invention'), ['inventions']),\n",
       "   [','],\n",
       "   Tree(Lemma('patent.n.01.patent'), ['patent']),\n",
       "   Tree(Lemma('application.n.02.application'), ['applications']),\n",
       "   [','],\n",
       "   Tree(Lemma('patent.n.01.patent'), ['patents']),\n",
       "   [','],\n",
       "   Tree(Lemma('license.n.01.license'), ['licenses']),\n",
       "   [','],\n",
       "   Tree(Lemma('land.n.01.land'), ['land']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('interest.n.05.interest'), ['interests']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('land.n.01.land'), ['land']),\n",
       "   ['('],\n",
       "   Tree(Lemma('include.v.01.include'), ['including']),\n",
       "   Tree(Lemma('water_right.n.01.water_right'), ['water', 'rights']),\n",
       "   [')'],\n",
       "   [','],\n",
       "   Tree(Lemma('plant.n.01.plant'), ['plants']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('facility.n.01.facility'), ['facilities']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('other.a.01.other'), ['other']),\n",
       "   Tree(Lemma('property.n.01.property'), ['property']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('right.n.01.right'), ['rights']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('purchase.n.01.purchase'), ['purchase']),\n",
       "   [','],\n",
       "   Tree(Lemma('license.n.01.license'), ['license']),\n",
       "   [','],\n",
       "   Tree(Lemma('lease.n.02.lease'), ['lease']),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   Tree(Lemma('contribution.n.03.donation'), ['donation']),\n",
       "   [';']],\n",
       "  [['This'],\n",
       "   Tree(Lemma('subsection.n.01.subsection'), ['subsection']),\n",
       "   ['shall'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   ['be'],\n",
       "   Tree(Lemma('so.r.03.so'), ['so']),\n",
       "   Tree(Lemma('interpret.v.01.construe'), ['construed']),\n",
       "   ['as'],\n",
       "   ['to'],\n",
       "   Tree(Lemma('deprive.v.02.deprive'), ['deprive']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('owner.n.01.owner'), ['owner']),\n",
       "   ['of'],\n",
       "   ['any'],\n",
       "   Tree(Lemma('background.n.03.background'), ['background']),\n",
       "   Tree(Lemma('patent.n.01.patent'), ['patent']),\n",
       "   Tree(Lemma('associate.v.01.relate'), ['relating']),\n",
       "   Tree(Lemma('thereto.r.01.thereto'), ['thereto']),\n",
       "   ['of'],\n",
       "   Tree('such.s.00', ['such']),\n",
       "   Tree(Lemma('right.n.01.right'), ['rights']),\n",
       "   ['as'],\n",
       "   ['he'],\n",
       "   ['may'],\n",
       "   Tree(Lemma('have.v.01.have'), ['have']),\n",
       "   Tree(Lemma('thereunder.r.01.thereunder'), ['thereunder']),\n",
       "   ['.']],\n",
       "  [Tree('in_addition.r.00', ['In', 'addition']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('punishment.n.01.penalty'), ['penalties']),\n",
       "   Tree(Lemma('provide.v.03.provide'), ['provided']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('title.n.01.title'), ['title']),\n",
       "   Tree(Lemma('eighteen.s.01.18'), ['18']),\n",
       "   [','],\n",
       "   Tree(Lemma('united_states_government.n.01.United_States'), ['United', 'States']),\n",
       "   Tree(Lemma('code.n.01.code'), ['Code']),\n",
       "   [','],\n",
       "   Tree(Lemma('section.n.01.section'), ['section']),\n",
       "   ['1001'],\n",
       "   [','],\n",
       "   ['any'],\n",
       "   Tree(Lemma('person.n.01.person'), ['person']),\n",
       "   Tree(Lemma('guilty.a.01.guilty'), ['guilty']),\n",
       "   ['of'],\n",
       "   ['any'],\n",
       "   Tree(Lemma('act.n.02.act'), ['act']),\n",
       "   [','],\n",
       "   ['as'],\n",
       "   Tree(Lemma('provide.v.03.provide'), ['provided']),\n",
       "   Tree(Lemma('therein.r.01.therein'), ['therein']),\n",
       "   [','],\n",
       "   Tree('with_respect_to.s.00', ['with', 'respect', 'to']),\n",
       "   ['any'],\n",
       "   Tree(Lemma('topic.n.02.matter'), ['matter']),\n",
       "   ['under'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('title.n.01.title'), ['Title']),\n",
       "   [','],\n",
       "   ['shall'],\n",
       "   Tree(Lemma('forfeit.v.01.forfeit'), ['forfeit']),\n",
       "   ['all'],\n",
       "   Tree(Lemma('right.n.01.right'), ['rights']),\n",
       "   ['under'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('title.n.01.title'), ['Title']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   [','],\n",
       "   ['if'],\n",
       "   Tree(Lemma('payment.n.01.payment'), ['payment']),\n",
       "   ['shall'],\n",
       "   ['have'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('make.v.01.make'), ['made']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('award.v.02.grant'), ['granted']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('committee.n.01.commission'), ['Commission']),\n",
       "   ['shall'],\n",
       "   Tree(Lemma('take.v.01.take'), ['take']),\n",
       "   Tree('such.s.00', ['such']),\n",
       "   Tree(Lemma('action.n.01.action'), ['action']),\n",
       "   ['as'],\n",
       "   ['may'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   Tree(Lemma('necessary.a.01.necessary'), ['necessary']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('recover.v.01.recover'), ['recover']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('same.a.01.same'), ['same']),\n",
       "   ['.']],\n",
       "  [['Whoever'],\n",
       "   [','],\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('united_states.n.01.United_States'), ['United', 'States']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('elsewhere.r.01.elsewhere'), ['elsewhere']),\n",
       "   [','],\n",
       "   Tree(Lemma('pay.v.01.pay'), ['pays']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('offer.v.02.offer'), ['offers']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('pay.v.01.pay'), ['pay']),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   Tree(Lemma('promise.v.01.promise'), ['promises']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('pay.v.01.pay'), ['pay']),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   Tree(Lemma('receive.v.01.receive'), ['receives']),\n",
       "   ['on', 'account', 'of'],\n",
       "   Tree(Lemma('services.n.01.services'), ['services']),\n",
       "   Tree(Lemma('supply.v.01.render'), ['rendered']),\n",
       "   ['or'],\n",
       "   ['to'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('render.v.01.render'), ['rendered']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('connection.n.01.connection'), ['connection']),\n",
       "   ['with'],\n",
       "   ['any'],\n",
       "   Tree('such.s.00', ['such']),\n",
       "   Tree(Lemma('claim.n.01.claim'), ['claim']),\n",
       "   [','],\n",
       "   Tree(Lemma('compensation.n.01.compensation'), ['compensation']),\n",
       "   ['which'],\n",
       "   [','],\n",
       "   ['when'],\n",
       "   Tree(Lemma('add.v.04.add'), ['added']),\n",
       "   ['to'],\n",
       "   ['any'],\n",
       "   Tree(Lemma('sum.n.01.amount'), ['amount']),\n",
       "   Tree(Lemma('previously.r.01.previously'), ['previously']),\n",
       "   Tree(Lemma('pay.v.01.pay'), ['paid']),\n",
       "   ['on', 'account', 'of'],\n",
       "   Tree('such.s.00', ['such']),\n",
       "   Tree(Lemma('services.n.01.services'), ['services']),\n",
       "   [','],\n",
       "   ['will'],\n",
       "   Tree(Lemma('exceed.v.01.exceed'), ['exceed']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('sum.n.01.amount'), ['amount']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('fee.n.01.fee'), ['fees']),\n",
       "   Tree(Lemma('so.r.03.so'), ['so']),\n",
       "   Tree(Lemma('determine.v.03.determine'), ['determined']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('committee.n.01.commission'), ['Commission']),\n",
       "   [','],\n",
       "   ['shall'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   Tree(Lemma('guilty.a.01.guilty'), ['guilty']),\n",
       "   ['of'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('misdemeanor.n.01.misdemeanor'), ['misdemeanor']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   [','],\n",
       "   ['upon'],\n",
       "   Tree(Lemma('conviction.n.02.conviction'), ['conviction']),\n",
       "   Tree(Lemma('thereof.r.01.thereof'), ['thereof']),\n",
       "   [','],\n",
       "   ['shall'],\n",
       "   ['be'],\n",
       "   Tree('fine.v.00', ['fined']),\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree('more_than.r.00', ['more', 'than']),\n",
       "   ['$'],\n",
       "   ['5000'],\n",
       "   ['or'],\n",
       "   Tree(Lemma('imprison.v.01.imprison'), ['imprisoned']),\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree('more_than.r.00', ['more', 'than']),\n",
       "   Tree(Lemma('twelve.s.01.twelve'), ['twelve']),\n",
       "   Tree(Lemma('month.n.02.month'), ['months']),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   ['both'],\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['if'],\n",
       "   ['any'],\n",
       "   Tree('such.s.00', ['such']),\n",
       "   Tree(Lemma('payment.n.01.payment'), ['payment']),\n",
       "   ['shall'],\n",
       "   ['have'],\n",
       "   ['been'],\n",
       "   Tree(Lemma('make.v.01.make'), ['made']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('award.v.02.grant'), ['granted']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('committee.n.01.commission'), ['Commission']),\n",
       "   ['shall'],\n",
       "   Tree(Lemma('take.v.01.take'), ['take']),\n",
       "   Tree('such.s.00', ['such']),\n",
       "   Tree(Lemma('action.n.01.action'), ['action']),\n",
       "   ['as'],\n",
       "   ['may'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   Tree(Lemma('necessary.a.01.necessary'), ['necessary']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('recover.v.01.recover'), ['recover']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('same.a.01.same'), ['same']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   [','],\n",
       "   Tree('in_addition.r.00', ['in', 'addition']),\n",
       "   Tree(Lemma('thereto.r.01.thereto'), ['thereto']),\n",
       "   [','],\n",
       "   ['any'],\n",
       "   Tree('such.s.00', ['such']),\n",
       "   Tree(Lemma('person.n.01.person'), ['person']),\n",
       "   ['shall'],\n",
       "   Tree(Lemma('forfeit.v.01.forfeit'), ['forfeit']),\n",
       "   ['all'],\n",
       "   Tree(Lemma('right.n.01.right'), ['rights']),\n",
       "   ['under'],\n",
       "   ['this'],\n",
       "   Tree(Lemma('title.n.01.title'), ['title']),\n",
       "   ['.']],\n",
       "  [Tree('in_addition.r.00', ['In', 'addition']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('right_to_vote.n.01.right_to_vote'), ['right', 'to', 'vote']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['General', 'Motors'])]),\n",
       "   Tree(Lemma('stock.n.01.stock'), ['stock']),\n",
       "   Tree(Lemma('have.v.01.hold'), ['held']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['du', 'Pont'])]),\n",
       "   ['was'],\n",
       "   ['to'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('invest.v.04.vest'), ['vested']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['du', 'Pont'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('stockholder.n.01.stockholder'), ['stockholders']),\n",
       "   [','],\n",
       "   Tree('other_than.s.00', ['other', 'than']),\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Christiana'])]),\n",
       "   ['and'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Delaware'])]),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('stockholder.n.01.stockholder'), ['stockholders']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Delaware'])]),\n",
       "   [';'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['du', 'Pont'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Christiana'])]),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Delaware'])]),\n",
       "   ['were'],\n",
       "   ['to'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('enjoin.v.01.enjoin'), ['enjoined']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('get.v.01.acquire'), ['acquiring']),\n",
       "   Tree(Lemma('stock.n.01.stock'), ['stock']),\n",
       "   ['in'],\n",
       "   ['or'],\n",
       "   Tree(Lemma('exert.v.01.exercise'), ['exercising']),\n",
       "   Tree(Lemma('control.n.01.control'), ['control']),\n",
       "   ['over'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['General', 'Motors'])]),\n",
       "   [';'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['du', 'Pont'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Christiana'])]),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Delaware'])]),\n",
       "   ['were'],\n",
       "   ['to'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('forbid.v.01.prohibit'), ['prohibited']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('have.v.01.have'), ['have']),\n",
       "   ['any'],\n",
       "   Tree(Lemma('director.n.02.director'), ['director']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('officeholder.n.01.officer'), ['officer']),\n",
       "   Tree(Lemma('in_common.r.01.in_common'), ['in', 'common']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['General', 'Motors'])]),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('vice_versa.r.01.vice_versa'), ['vice', 'versa']),\n",
       "   [';'],\n",
       "   ['and'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['General', 'Motors'])]),\n",
       "   ['and'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['du', 'Pont'])]),\n",
       "   ['were'],\n",
       "   ['to'],\n",
       "   ['be'],\n",
       "   Tree(Lemma('order.v.01.order'), ['ordered']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('end.v.02.terminate'), ['terminate']),\n",
       "   ['any'],\n",
       "   Tree('agreement.n.4;1', ['agreement']),\n",
       "   ['that'],\n",
       "   Tree('provide_for.v.00', ['provided', 'for']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('purchase.n.01.purchase'), ['purchase']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['General', 'Motors'])]),\n",
       "   ['of'],\n",
       "   ['any'],\n",
       "   Tree(Lemma('specified.a.01.specified'), ['specified']),\n",
       "   Tree(Lemma('percentage.n.01.percentage'), ['percentage']),\n",
       "   ['of'],\n",
       "   ['its'],\n",
       "   Tree(Lemma('necessity.n.02.requirement'), ['requirements']),\n",
       "   ['of'],\n",
       "   ['any'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['du', 'Pont'])]),\n",
       "   Tree(Lemma('manufactured.s.01.manufactured'), ['manufactured']),\n",
       "   Tree(Lemma('merchandise.n.01.product'), ['product']),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('grant.n.03.grant'), ['grant']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('exclusive.s.01.exclusive'), ['exclusive']),\n",
       "   Tree(Lemma('patent_right.n.01.patent_right'), ['patent', 'rights']),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   ['for'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('grant.n.03.grant'), ['grant']),\n",
       "   ['by'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['General', 'Motors'])]),\n",
       "   ['to'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['du', 'Pont'])]),\n",
       "   ['of'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('discriminatory.s.04.preferential'), ['preferential']),\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('make.v.03.make'), ['make']),\n",
       "   ['or'],\n",
       "   Tree('sell.v.4;1', ['sell']),\n",
       "   ['any'],\n",
       "   Tree(Lemma('chemical.a.01.chemical'), ['chemical']),\n",
       "   Tree(Lemma('discovery.n.01.discovery'), ['discovery']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['General', 'Motors'])]),\n",
       "   [','],\n",
       "   ['or'],\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('care.n.06.maintenance'), ['maintenance']),\n",
       "   ['of'],\n",
       "   ['any'],\n",
       "   Tree(Lemma('joint.a.01.joint'), ['joint']),\n",
       "   Tree(Lemma('commercial_enterprise.n.01.commercial_enterprise'), ['commercial', 'enterprise']),\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('two.s.01.two'), ['two']),\n",
       "   Tree(Lemma('company.n.01.company'), ['companies']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('group.n.01.group'), [Tree('NE', ['Du', 'Pont'])]),\n",
       "   ['would'],\n",
       "   ['be'],\n",
       "   Tree('deny.v.3;4', ['denied']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('get.v.01.acquire'), ['acquire']),\n",
       "   ['any'],\n",
       "   Tree('additional.s.00', ['additional']),\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['General', 'Motors'])]),\n",
       "   Tree(Lemma('stock.n.01.stock'), ['stock']),\n",
       "   ['except'],\n",
       "   ['through'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['General', 'Motors'])]),\n",
       "   [\"'\"],\n",
       "   Tree(Lemma('distribution.n.03.distribution'), ['distributions']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('stock.n.01.stock'), ['stock']),\n",
       "   ['or'],\n",
       "   Tree(Lemma('subscription_right.n.01.subscription_right'), ['subscription', 'rights']),\n",
       "   ['to'],\n",
       "   ['its'],\n",
       "   Tree(Lemma('stockholder.n.01.stockholder'), ['stockholders']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('claim.v.01.claim'), ['claims']),\n",
       "   ['that'],\n",
       "   ['he'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('deny.v.03.deny'), ['denied']),\n",
       "   Tree(Lemma('due_process.n.01.due_process_of_law'), ['due', 'process', 'of', 'law']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('violation.n.02.violation'), ['violation']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree('NE', ['Fifth', 'Amendment']),\n",
       "   [','],\n",
       "   ['because'],\n",
       "   ['('],\n",
       "   ['1'],\n",
       "   [')'],\n",
       "   ['at'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('hearing.n.01.hearing'), ['hearing']),\n",
       "   ['before'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('hearing_examiner.n.01.hearing_officer'), ['hearing', 'officer']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Department', 'of', 'Justice', ','])]),\n",
       "   ['he'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('permit.v.01.permit'), ['permitted']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('refute.v.01.rebut'), ['rebut']),\n",
       "   Tree(Lemma('statement.n.01.statement'), ['statements']),\n",
       "   Tree(Lemma('impute.v.01.attribute'), ['attributed']),\n",
       "   ['to'],\n",
       "   ['him'],\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree('local.a.00', ['local']),\n",
       "   Tree(Lemma('board.n.01.board'), ['board']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['('],\n",
       "   ['2'],\n",
       "   [')'],\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree('trial.n.00', ['trial']),\n",
       "   [','],\n",
       "   ['he'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('deny.v.03.deny'), ['denied']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('have.v.01.have'), ['have']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('hearing_examiner.n.01.hearing_officer'), ['hearing', 'officer']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('report.n.01.report'), ['report']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('original.s.01.original'), ['original']),\n",
       "   Tree(Lemma('report.n.01.report'), ['report']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Federal', 'Bureau', 'of', 'Investigation'])]),\n",
       "   ['as'],\n",
       "   ['to'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('claim.n.02.claim'), ['claim']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('allege.v.01.say'), ['says']),\n",
       "   ['that'],\n",
       "   ['he'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('permit.v.01.permit'), ['permitted']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('refute.v.01.rebut'), ['rebut']),\n",
       "   ['before'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('hearing_examiner.n.01.hearing_officer'), ['hearing', 'officer']),\n",
       "   Tree(Lemma('statement.n.01.statement'), ['statements']),\n",
       "   Tree(Lemma('impute.v.01.attribute'), ['attributed']),\n",
       "   ['to'],\n",
       "   ['him'],\n",
       "   ['by'],\n",
       "   ['the'],\n",
       "   Tree('local.a.00', ['local']),\n",
       "   Tree(Lemma('board.n.01.board'), ['board']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   [','],\n",
       "   Tree(Lemma('further.r.01.further'), ['further']),\n",
       "   [','],\n",
       "   ['that'],\n",
       "   ['he'],\n",
       "   ['was'],\n",
       "   Tree(Lemma('deny.v.03.deny'), ['denied']),\n",
       "   ['at'],\n",
       "   Tree('trial.n.00', ['trial']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('have.v.01.have'), ['have']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Department', 'of', 'Justice'])]),\n",
       "   Tree(Lemma('hearing_examiner.n.01.hearing_officer'), ['hearing', 'officer']),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('report.n.01.report'), ['report']),\n",
       "   ['and'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('original.s.01.original'), ['original']),\n",
       "   Tree(Lemma('report.n.01.report'), ['report']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Federal', 'Bureau', 'of', 'Investigation'])]),\n",
       "   ['as'],\n",
       "   ['to'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('claim.n.02.claim'), ['claim']),\n",
       "   ['-'],\n",
       "   Tree(Lemma('all.a.01.all'), ['all']),\n",
       "   ['in'],\n",
       "   Tree(Lemma('violation.n.02.violation'), ['violation']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree('NE', ['Fifth', 'Amendment']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('petitioner.n.01.petitioner'), ['Petitioner']),\n",
       "   Tree(Lemma('besides.r.02.also'), ['also']),\n",
       "   Tree(Lemma('claim.v.02.claim'), ['claimed']),\n",
       "   ['at'],\n",
       "   Tree('trial.n.00', ['trial']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('inspect.v.01.inspect'), ['inspect']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('original.s.01.original'), ['original']),\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Federal', 'Bureau', 'of', 'Investigation'])]),\n",
       "   Tree(Lemma('report.n.01.report'), ['reports']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Department', 'of', 'Justice'])]),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('establish.v.08.base'), ['bases']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('present.a.01.present'), ['present']),\n",
       "   Tree(Lemma('contention.n.01.contention'), ['contention']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('general.a.01.general'), ['general']),\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('research.v.02.explore'), ['explore']),\n",
       "   [','],\n",
       "   Tree(Lemma('bespeak.v.01.indicate'), ['indicating']),\n",
       "   ['that'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('hope.v.01.hope'), ['hopes']),\n",
       "   ['to'],\n",
       "   Tree('find.v.4;1', ['find']),\n",
       "   ['some'],\n",
       "   Tree(Lemma('discrepancy.n.01.discrepancy'), ['discrepancy']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('sketch.n.03.resume'), ['resume']),\n",
       "   ['.']],\n",
       "  [['A'],\n",
       "   Tree(Lemma('child.n.01.minor'), ['minor']),\n",
       "   Tree(Lemma('be.v.01.be'), ['is']),\n",
       "   Tree('subject.s.00', ['subject']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('tax.n.01.tax'), ['tax']),\n",
       "   ['on'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('own.s.01.own'), ['own']),\n",
       "   Tree(Lemma('wage.n.01.earnings'), ['earnings']),\n",
       "   Tree(Lemma('even.r.02.even'), ['even']),\n",
       "   Tree('though.r.00', ['though']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('parent.n.01.parent'), ['parent']),\n",
       "   ['may'],\n",
       "   [','],\n",
       "   ['under'],\n",
       "   Tree('local.a.00', ['local']),\n",
       "   Tree(Lemma('law.n.01.law'), ['law']),\n",
       "   [','],\n",
       "   Tree(Lemma('have.v.01.have'), ['have']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   ['them'],\n",
       "   ['and'],\n",
       "   ['might'],\n",
       "   Tree(Lemma('actually.r.01.actually'), ['actually']),\n",
       "   ['have'],\n",
       "   Tree(Lemma('receive.v.01.receive'), ['received']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('money.n.01.money'), ['money']),\n",
       "   ['.']],\n",
       "  [['And'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('surely.r.01.certainly'), ['certainly']),\n",
       "   ['could'],\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   ['have'],\n",
       "   Tree(Lemma('guess.v.04.guess'), ['guessed']),\n",
       "   ['that'],\n",
       "   ['she'],\n",
       "   ['would'],\n",
       "   Tree(Lemma('resist.v.02.resist'), ['resist']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('demand.n.01.demand'), ['demand']),\n",
       "   ['for'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('gold.n.01.gold'), ['gold']),\n",
       "   ['or'],\n",
       "   ['that'],\n",
       "   ['she'],\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('yielding.s.01.yielding'), ['yielding']),\n",
       "   ['-'],\n",
       "   ['yes'],\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('credible.s.02.credible'), ['credible']),\n",
       "   Tree(Lemma('chump.n.01.fool'), ['fool']),\n",
       "   ['he'],\n",
       "   Tree(Lemma('have.v.01.have'), ['had']),\n",
       "   ['every'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('expect.v.01.expect'), ['expect']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Kitti'])]),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('thirty.s.01.thirty'), ['thirty']),\n",
       "   Tree(Lemma('year.n.01.year'), ['years']),\n",
       "   Tree(Lemma('young.a.01.young'), ['younger']),\n",
       "   ['than'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Stanley'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('tall.a.01.tall'), ['taller']),\n",
       "   ['than'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Stanley'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('pretty.s.01.pretty'), ['prettier']),\n",
       "   ['than'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Stanley'])]),\n",
       "   Tree(Lemma('have.v.01.have'), ['had']),\n",
       "   ['any'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('hope.v.01.hope'), ['hope']),\n",
       "   ['for'],\n",
       "   [','],\n",
       "   ['much', 'less'],\n",
       "   Tree(Lemma('expect.v.01.expect'), ['expect']),\n",
       "   ['.']],\n",
       "  [['``'],\n",
       "   ['You'],\n",
       "   Tree(Lemma('mean.v.01.mean'), ['mean']),\n",
       "   ['anyone'],\n",
       "   ['who'],\n",
       "   Tree(Lemma('stand_up.v.02.stand_up'), ['stood', 'up']),\n",
       "   ['for'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('right.n.01.right'), ['rights']),\n",
       "   [\"''\"],\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Curt'])]),\n",
       "   Tree(Lemma('state.v.01.say'), ['said']),\n",
       "   ['.']],\n",
       "  [['What'],\n",
       "   ['the'],\n",
       "   ['hell'],\n",
       "   Tree(Lemma('right.n.01.right'), ['right']),\n",
       "   ['did'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Eddie'])]),\n",
       "   Tree(Lemma('have.v.01.have'), ['have']),\n",
       "   Tree(Lemma('state.v.01.say'), ['saying']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('thing.n.03.thing'), ['thing']),\n",
       "   ['like'],\n",
       "   ['that'],\n",
       "   ['?']],\n",
       "  [['At'],\n",
       "   Tree(Lemma('right.n.02.right'), ['right']),\n",
       "   Tree(Lemma('be.v.03.be'), ['is']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('casual.s.03.casual'), ['casual']),\n",
       "   Tree(Lemma('style.n.03.style'), ['style']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('crushed.s.01.crushed'), ['crushed']),\n",
       "   Tree(Lemma('unlined.a.01.unlined'), ['unlined']),\n",
       "   Tree(Lemma('white.a.01.white'), ['white']),\n",
       "   Tree(Lemma('leather.n.01.leather'), ['leather']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('all_too.r.01.only_too'), ['Only', 'too']),\n",
       "   Tree(Lemma('frequently.r.01.often'), ['often']),\n",
       "   [','],\n",
       "   Tree(Lemma('however.r.01.however'), ['however']),\n",
       "   [','],\n",
       "   ['you'],\n",
       "   Tree(Lemma('experience.v.03.have'), ['have']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('impression.n.01.feeling'), ['feeling']),\n",
       "   ['that'],\n",
       "   ['you'],\n",
       "   ['are'],\n",
       "   Tree(Lemma('sit.v.01.sit'), ['sitting']),\n",
       "   ['in'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('room.n.01.room'), ['room']),\n",
       "   ['with'],\n",
       "   ['some'],\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('instrument.n.01.instrument'), ['instruments']),\n",
       "   Tree(Lemma('line_up.v.01.line_up'), ['lined', 'up']),\n",
       "   ['on'],\n",
       "   Tree(Lemma('one.s.01.one'), ['one']),\n",
       "   Tree(Lemma('wall.n.01.wall'), ['wall']),\n",
       "   ['to'],\n",
       "   ['your'],\n",
       "   Tree(Lemma('left.n.01.left'), ['left']),\n",
       "   ['and'],\n",
       "   ['others'],\n",
       "   Tree(Lemma('front.v.01.face'), ['facing']),\n",
       "   ['them'],\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('wall.n.01.wall'), ['wall']),\n",
       "   ['to'],\n",
       "   ['your'],\n",
       "   Tree(Lemma('right.n.02.right'), ['right']),\n",
       "   ['.']],\n",
       "  [['With'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('first.a.01.first'), ['first']),\n",
       "   Tree(Lemma('report.n.04.report'), ['reports']),\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Russell'])]),\n",
       "   [\"'s\"],\n",
       "   Tree(Lemma('horse.n.01.horse'), ['horse']),\n",
       "   Tree(Lemma('wheel.v.01.wheel'), ['wheeled']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.02.right'), ['right']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('run.v.01.run'), ['ran']),\n",
       "   ['towards'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('building.n.01.building'), ['buildings']),\n",
       "   ['while'],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Cook'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('follow.v.01.follow'), ['followed']),\n",
       "   ['by'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('hail.n.01.hail'), ['hail']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('bullet.n.01.bullet'), ['bullets']),\n",
       "   [','],\n",
       "   Tree(Lemma('rush.v.01.race'), ['raced']),\n",
       "   ['towards'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('arroyo.n.01.arroyo'), ['arroyo']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('location.n.01.location'), [Tree('NE', ['Salyer', \"'s\", 'Canyon'])]),\n",
       "   Tree(Lemma('immediately.r.02.immediately'), ['immediately']),\n",
       "   ['in', 'front', 'of'],\n",
       "   ['him'],\n",
       "   [','],\n",
       "   Tree(Lemma('barely.r.01.just'), ['just']),\n",
       "   Tree(Lemma('reach.v.01.reach'), ['reaching']),\n",
       "   ['it'],\n",
       "   ['as'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('horse.n.01.horse'), ['horse']),\n",
       "   Tree(Lemma('fall.v.07.fall'), ['fell']),\n",
       "   ['.']],\n",
       "  [['On'],\n",
       "   ['their'],\n",
       "   Tree(Lemma('right.n.02.right'), ['right']),\n",
       "   Tree(Lemma('rise.v.04.rise'), ['rose']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('embankment.n.01.embankment'), ['embankment']),\n",
       "   Tree(Lemma('cover.v.01.cover'), ['covered']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('brush.n.01.brush'), ['brush']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('tree.n.01.tree'), ['trees']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('thus.r.02.thus'), ['Thus']),\n",
       "   [','],\n",
       "   Tree(Lemma('stealthily.r.01.stealthily'), ['stealthily']),\n",
       "   ['they'],\n",
       "   Tree(Lemma('advance.v.01.advance'), ['advanced']),\n",
       "   Tree(Lemma('upriver.r.01.upstream'), ['upstream']),\n",
       "   [';'],\n",
       "   Tree(Lemma('then.r.01.then'), ['then']),\n",
       "   ['they'],\n",
       "   Tree(Lemma('turn.v.01.turn'), ['turned']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.02.right'), ['right']),\n",
       "   [','],\n",
       "   Tree(Lemma('climb.v.01.climb'), ['climbed']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('embankment.n.01.embankment'), ['embankment']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('walk.v.01.walk'), ['walked']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('valley.n.01.valley'), ['valley']),\n",
       "   Tree(Lemma('again.r.01.again'), ['again']),\n",
       "   ['.']],\n",
       "  [['Her'],\n",
       "   Tree(Lemma('living_quarters.n.01.quarters'), ['quarters']),\n",
       "   Tree(Lemma('be.v.03.be'), ['were']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.02.right'), ['right']),\n",
       "   ['as'],\n",
       "   ['you'],\n",
       "   Tree(Lemma('walk.v.01.walk'), ['walked']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('building.n.01.building'), ['building']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['her'],\n",
       "   Tree(Lemma('small.a.01.small'), ['small']),\n",
       "   Tree(Lemma('living_room.n.01.front_room'), ['front', 'room']),\n",
       "   ['was'],\n",
       "   Tree(Lemma('clog.v.01.clog'), ['clogged']),\n",
       "   ['with'],\n",
       "   Tree(Lemma('heavy.a.01.heavy'), ['heavy']),\n",
       "   Tree(Lemma('furniture.n.01.furniture'), ['furniture']),\n",
       "   ['-'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('large.a.01.big'), ['big']),\n",
       "   [','],\n",
       "   Tree(Lemma('round.a.01.round'), ['round']),\n",
       "   [','],\n",
       "   Tree(Lemma('oak.n.01.oak'), ['oak']),\n",
       "   Tree(Lemma('dining_table.n.01.dining_table'), ['dining', 'table']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('chair.n.01.chair'), ['chairs']),\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree(Lemma('buffet.n.01.buffet'), ['buffet']),\n",
       "   [','],\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('row.n.01.row'), ['row']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('unclaimed.s.01.unclaimed'), ['unclaimed']),\n",
       "   Tree(Lemma('letter.n.01.letter'), ['letters']),\n",
       "   Tree(Lemma('tuck.v.01.insert'), ['inserted']),\n",
       "   ['between'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('mirror.n.01.mirror'), ['mirror']),\n",
       "   ['and'],\n",
       "   ['its'],\n",
       "   Tree(Lemma('frame.n.01.frame'), ['frame']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Mynheer'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Sir', 'Francis'])]),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('valley.n.01.valley'), ['valley']),\n",
       "   Tree(Lemma('club.n.02.society'), ['society']),\n",
       "   [','],\n",
       "   ['the'],\n",
       "   Tree(Lemma('very.s.01.very'), ['very']),\n",
       "   Tree(Lemma('smell.n.01.smell'), ['smell']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('river.n.01.river'), ['river']),\n",
       "   ['on'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('right.n.02.right'), ['right']),\n",
       "   Tree(Lemma('sough.v.01.purl'), ['purling']),\n",
       "   Tree(Lemma('along.r.03.along'), ['along']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('bay.n.01.bay'), ['bay']),\n",
       "   ['past'],\n",
       "   Tree(Lemma('fish.n.01.fish'), ['fish']),\n",
       "   Tree(Lemma('weir.n.01.weir'), ['weirs']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('rock.n.01.rock'), ['rocks']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('ahead.r.01.ahead'), ['ahead']),\n",
       "   ['the'],\n",
       "   Tree('sleepy.s.01', ['sleepy']),\n",
       "   Tree(Lemma('ribbon.n.01.ribbon'), ['ribbon']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('moon.n.01.Moon'), ['moon']),\n",
       "   Tree(Lemma('drenched.s.01.drenched'), ['drenched']),\n",
       "   Tree(Lemma('road.n.01.road'), ['road']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('scarcity.n.01.scarcity'), ['Scarcity']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('paper.n.01.paper'), ['paper']),\n",
       "   Tree(Lemma('induce.v.02.cause'), ['caused']),\n",
       "   Tree(Lemma('many.a.01.many'), ['many']),\n",
       "   Tree(Lemma('southerner.n.01.Southerner'), ['Southerners']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('adopt.v.02.adopt'), ['adopt']),\n",
       "   ['the'],\n",
       "   Tree('practice.n.5;1', ['practice']),\n",
       "   ['of'],\n",
       "   Tree(Lemma('cross.s.01.cross'), ['cross']),\n",
       "   Tree(Lemma('writing.n.04.writing'), ['writing']),\n",
       "   [','],\n",
       "   Tree(Lemma('i.e..r.01.i.e.'), ['i.', 'e.']),\n",
       "   [','],\n",
       "   ['after'],\n",
       "   Tree(Lemma('write.v.01.write'), ['writing']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('left.n.01.left'), ['left']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('right.n.02.right'), ['right']),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('page.n.01.page'), ['page']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('usual.a.01.usual'), ['usual']),\n",
       "   Tree(Lemma('manner.n.01.manner'), ['manner']),\n",
       "   [','],\n",
       "   ['they'],\n",
       "   Tree(Lemma('give.v.15.give'), ['gave']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('sheet.n.02.sheet'), ['sheet']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('half.s.02.half'), ['half']),\n",
       "   Tree(Lemma('twist.n.13.turn'), ['turn']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('write.v.01.write'), ['wrote']),\n",
       "   ['from'],\n",
       "   Tree(Lemma('end.n.01.end'), ['end']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('end.n.01.end'), ['end']),\n",
       "   Tree(Lemma('across.r.02.across'), ['across']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('line.n.05.line'), ['lines']),\n",
       "   Tree(Lemma('previously.r.01.previously'), ['previously']),\n",
       "   Tree(Lemma('written.a.01.written'), ['written']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('private.n.01.private'), ['Private']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Jenkins', 'Lloyd', 'Jones'])]),\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('group.n.01.group'), [Tree('NE', ['Wisconsin', 'Light', 'Artillery'])]),\n",
       "   Tree(Lemma('write.v.02.write'), ['wrote']),\n",
       "   ['in'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('diary.n.01.diary'), ['diary']),\n",
       "   [':'],\n",
       "   ['``'],\n",
       "   ['I'],\n",
       "   Tree('stroll.v.00', ['strolled']),\n",
       "   ['among'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('alabaman.n.01.Alabaman'), ['Alabamans']),\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.02.right'), ['right']),\n",
       "   [','],\n",
       "   Tree(Lemma('find.v.01.find'), ['found']),\n",
       "   ['some'],\n",
       "   ['of'],\n",
       "   ['the'],\n",
       "   Tree('green.s.00', ['greenest']),\n",
       "   Tree(Lemma('specimen.n.01.specimen'), ['specimens']),\n",
       "   ['of'],\n",
       "   Tree('humanity.n.00', ['humanity']),\n",
       "   ['I'],\n",
       "   Tree(Lemma('think.v.02.think'), ['think']),\n",
       "   ['in'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('universe.n.01.universe'), ['universe']),\n",
       "   ['their'],\n",
       "   Tree(Lemma('ignorance.n.01.ignorance'), ['ignorance']),\n",
       "   Tree(Lemma('be.v.01.be'), ['being']),\n",
       "   Tree(Lemma('little.r.01.little'), ['little']),\n",
       "   Tree('less_than.r.00', ['less', 'than']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('slave.n.01.slave'), ['slave']),\n",
       "   ['they'],\n",
       "   Tree(Lemma('contemn.v.01.despise'), ['despise']),\n",
       "   ['with'],\n",
       "   ['as'],\n",
       "   Tree(Lemma('imperfect.a.01.imperfect'), ['imperfect']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('dialect.n.01.dialect'), ['dialect']),\n",
       "   [\"'\"],\n",
       "   ['They'],\n",
       "   Tree(Lemma('think.v.02.reckon'), ['Recooned']),\n",
       "   ['as'],\n",
       "   ['how'],\n",
       "   ['you'],\n",
       "   [\"'\"],\n",
       "   ['uns'],\n",
       "   ['all'],\n",
       "   ['would'],\n",
       "   Tree(Lemma('be.v.01.be'), ['be']),\n",
       "   ['a'],\n",
       "   Tree(Lemma('batch.n.02.heap'), ['heap']),\n",
       "   Tree(Lemma('worse.a.01.worse'), ['wus']),\n",
       "   ['to'],\n",
       "   ['we'],\n",
       "   [\"'\"],\n",
       "   ['uns'],\n",
       "   ['all'],\n",
       "   [\"''\"],\n",
       "   [\"'\"],\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('walk.v.01.walk'), ['walked']),\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('heavy.a.02.heavy'), ['heavy']),\n",
       "   Tree(Lemma('tilt.n.04.list'), ['list']),\n",
       "   ['to'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.02.right'), ['right']),\n",
       "   [','],\n",
       "   ['as'],\n",
       "   ['that'],\n",
       "   Tree(Lemma('leg.n.01.leg'), ['leg']),\n",
       "   Tree(Lemma('be.v.01.be'), ['was']),\n",
       "   Tree(Lemma('four.s.01.four'), ['four']),\n",
       "   Tree(Lemma('inch.n.01.inch'), ['inches']),\n",
       "   Tree(Lemma('short.a.02.short'), ['shorter']),\n",
       "   ['than'],\n",
       "   ['the'],\n",
       "   ['other'],\n",
       "   [','],\n",
       "   ['but'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('lurch.n.01.lurch'), ['lurch']),\n",
       "   ['did'],\n",
       "   Tree(Lemma('not.r.01.not'), ['not']),\n",
       "   Tree(Lemma('reduce.v.01.reduce'), ['reduce']),\n",
       "   ['his'],\n",
       "   Tree(Lemma('feline.a.01.feline'), ['feline']),\n",
       "   Tree(Lemma('adeptness.n.01.quickness'), ['quickness']),\n",
       "   ['with'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('gun.n.01.gun'), ['guns']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Chandler'])]),\n",
       "   [','],\n",
       "   Tree(Lemma('look_to.v.01.look_to'), ['looking', 'to']),\n",
       "   Tree(Lemma('right.n.02.right'), ['right']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('left.n.01.left'), ['left']),\n",
       "   ['to'],\n",
       "   Tree(Lemma('determine.v.08.see'), ['see']),\n",
       "   ['how'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('serviceman.n.01.man'), ['men']),\n",
       "   ['were'],\n",
       "   Tree(Lemma('do.v.04.fare'), ['faring']),\n",
       "   [','],\n",
       "   Tree(Lemma('suddenly.r.01.suddenly'), ['suddenly']),\n",
       "   Tree(Lemma('see.v.01.see'), ['saw']),\n",
       "   ['another'],\n",
       "   Tree(Lemma('human_body.n.01.figure'), ['figure']),\n",
       "   Tree(Lemma('jump.v.01.bound'), ['bounding']),\n",
       "   ['up'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('hill.n.01.hill'), ['hill']),\n",
       "   [','],\n",
       "   Tree(Lemma('hurl.v.01.hurl'), ['hurling']),\n",
       "   Tree(Lemma('grenade.n.01.grenade'), ['grenades']),\n",
       "   ['and'],\n",
       "   Tree('holler.v.2;1', ['hollering']),\n",
       "   ['the'],\n",
       "   Tree(Lemma('war_cry.n.02.battle_cry'), ['battle', 'cry']),\n",
       "   ['as'],\n",
       "   ['he'],\n",
       "   Tree(Lemma('run.v.01.run'), ['ran']),\n",
       "   ['.']],\n",
       "  [Tree(Lemma('person.n.01.person'), [Tree('NE', ['Cooper'])]),\n",
       "   Tree(Lemma('be.v.03.be'), ['was']),\n",
       "   ['beside'],\n",
       "   ['his'],\n",
       "   Tree(Lemma('car.n.01.car'), ['car']),\n",
       "   [','],\n",
       "   ['on'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('curb.n.01.curb'), ['curb']),\n",
       "   ['at'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('right.n.02.right'), ['right']),\n",
       "   [','],\n",
       "   Tree(Lemma('merely.r.01.just'), ['just']),\n",
       "   Tree(Lemma('stand.v.01.stand'), ['standing']),\n",
       "   ['there'],\n",
       "   Tree(Lemma('morosely.r.01.morosely'), ['morosely']),\n",
       "   [';'],\n",
       "   ['he'],\n",
       "   ['did'],\n",
       "   Tree(\"n't.r.00\", [\"n't\"]),\n",
       "   Tree(Lemma('even.r.01.even'), ['even']),\n",
       "   Tree(Lemma('look.v.01.look'), ['look']),\n",
       "   Tree(Lemma('up.r.01.up'), ['up']),\n",
       "   ['.']],\n",
       "  [['He'],\n",
       "   Tree(Lemma('slam.v.02.slam'), ['slammed']),\n",
       "   ['into'],\n",
       "   ['the'],\n",
       "   Tree(Lemma('wall.n.01.wall'), ['wall']),\n",
       "   [','],\n",
       "   Tree(Lemma('bounce.v.01.bounce'), ['bounced']),\n",
       "   Tree(Lemma('back.r.01.back'), ['back']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   Tree(Lemma('get.v.19.catch'), ['caught']),\n",
       "   Tree(Lemma('person.n.01.person'), [Tree('NE', ['Curt'])]),\n",
       "   ['with'],\n",
       "   ['a'],\n",
       "   Tree(Lemma('roundhouse.n.02.roundhouse'), ['roundhouse']),\n",
       "   Tree(Lemma('right.n.05.right'), ['right']),\n",
       "   ['which'],\n",
       "   Tree(Lemma('send.v.01.send'), ['sent']),\n",
       "   ['him'],\n",
       "   Tree(Lemma('spin.v.01.spin'), ['spinning']),\n",
       "   ['.']],\n",
       "  [['Regardless', 'of'],\n",
       "   Tree(Lemma('right.n.07.right'), ['rights']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('wrong.n.01.wrong'), ['wrongs']),\n",
       "   [','],\n",
       "   ['a'],\n",
       "   Tree(Lemma('population.n.01.population'), ['population']),\n",
       "   ['and'],\n",
       "   ['an'],\n",
       "   Tree(Lemma('area.n.01.area'), ['area']),\n",
       "   Tree(Lemma('appropriate.a.01.appropriate'), ['appropriate']),\n",
       "   ['to'],\n",
       "   ['a'],\n",
       "   Tree('pre.s.00', ['pre']),\n",
       "   Tree(Lemma('world_war_i.n.01.World_War_I'), ['World', 'War', 'I']),\n",
       "   [','],\n",
       "   Tree(Lemma('world_power.n.01.great_power'), ['great', 'power']),\n",
       "   ['have'],\n",
       "   ['been'],\n",
       "   [','],\n",
       "   ['following'],\n",
       "   Tree(Lemma('conquest.n.01.conquest'), ['conquest']),\n",
       "   [','],\n",
       "   Tree(Lemma('govern.v.03.rule'), ['ruled']),\n",
       "   ['against'],\n",
       "   ['their'],\n",
       "   Tree(Lemma('volition.n.01.will'), ['will']),\n",
       "   ['by'],\n",
       "   ['a'],\n",
       "   Tree('neighboring.s.00', ['neighboring']),\n",
       "   Tree(Lemma('people.n.01.people'), ['people']),\n",
       "   [','],\n",
       "   ['and'],\n",
       "   ['have'],\n",
       "   ['had'],\n",
       "   Tree(Lemma('inflict.v.01.impose'), ['imposed']),\n",
       "   ['upon'],\n",
       "   ['them'],\n",
       "   Tree(Lemma('social.a.01.social'), ['social']),\n",
       "   ['and'],\n",
       "   Tree(Lemma('economic.a.01.economic'), ['economic']),\n",
       "   Tree(Lemma('control.n.02.control'), ['controls']),\n",
       "   ['they'],\n",
       "   Tree(Lemma('disfavor.n.02.dislike'), ['dislike']),\n",
       "   ['.']]],\n",
       " [2, 6, 11, 49, 61, 62, 63])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.get_word_data('right', 'n')\n",
    "sel.get_selected_sense_sents(sel.get_senses_for_curr_word())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sense</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>02</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       freq\n",
       "sense      \n",
       "01        1\n",
       "02        1"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_type_cnts('bass', 'n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bert] *",
   "language": "python",
   "name": "conda-env-bert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
