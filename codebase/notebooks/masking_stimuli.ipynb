{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from core.rabagliati_13_analysis import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/rabagliati_2013_stimuli.csv')\n",
    "df = df[~df['target'].isin(['moose', 'mousse'])] #BERT tokenization issues\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatting the dataframe so we can run BERT through it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pos'] = ['n'] * len(df.index)\n",
    "df['word'] = df['target']\n",
    "word_pos_pairs = df[['word', 'pos']].drop_duplicates()\n",
    "word_pos_pairs.to_csv('../data/r_13_for_semcor.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating masked language modeling predictions. We replace the target token with a [MASK] and see what BERT predicts when the identity of the word is NOT given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_results = masking_embeds_preds(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting which words have types of both senses that were used in the stimuli vs. only one sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_sense_types, one_sense_types, available_sense = check_semcor_data(word_pos_pairs, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15,\n",
       " ['chicken',\n",
       "  'fish',\n",
       "  'herbs',\n",
       "  'letter',\n",
       "  'button',\n",
       "  'bow',\n",
       "  'line',\n",
       "  'bat',\n",
       "  'nail',\n",
       "  'pitcher',\n",
       "  'band',\n",
       "  'sun',\n",
       "  'son',\n",
       "  'knight',\n",
       "  'night'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(both_sense_types), both_sense_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, ['lamb', 'turkey', 'duck', 'glasses', 'mouse', 'roll', 'cards', 'bark'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_sense_types), one_sense_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We predict the sense of the masked token by comparing it to SEMCOR data, both using nearest neighbors and picking which sense's centroid is closest to the masked token. \n",
    "\n",
    "Global accuracy scores are just above 60%, which shows that even if the token itself is not in the sentence, BERT is able to pick up some sense_related distinctions, but is not as accurate as the participants or the MLE-based algorithm they were compared to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sathvik/Desktop/Berkeley/Research/thesis/codebase/core/rabagliati_13_analysis.py:275: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  two_senses['nn_preds'] = e_preds\n",
      "/Users/sathvik/Desktop/Berkeley/Research/thesis/codebase/core/rabagliati_13_analysis.py:276: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  two_senses['centroid_preds'] = c_preds\n",
      "/Users/sathvik/Desktop/Berkeley/Research/thesis/codebase/core/rabagliati_13_analysis.py:308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  one_sense['nn_preds'] = one_sense_nn\n",
      "/Users/sathvik/Desktop/Berkeley/Research/thesis/codebase/core/rabagliati_13_analysis.py:309: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  one_sense['centroid_preds'] = one_sense_centroid\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6190476190476191"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = generate_sense_predictions(df, mask_results, both_sense_types, one_sense_types, available_sense)\n",
    "sum(all_data['centroid_preds'] == all_data['wn_sense']) / len(all_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6071428571428571"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(all_data['nn_preds'] == all_data['wn_sense']) / len(all_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result shows that unlike 4 year old children in the study, BERT is much more reliably able to distinguish homonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rel_type</th>\n",
       "      <th>centroid_acc</th>\n",
       "      <th>nn_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>reg_pol</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>irreg_pol</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hom</td>\n",
       "      <td>0.535714</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rel_type  centroid_acc    nn_acc\n",
       "0    reg_pol      0.458333  0.500000\n",
       "1  irreg_pol      0.812500  0.656250\n",
       "2        hom      0.535714  0.642857"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_table(all_data, 'rel_type')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When disambiguating context is in the previous sentence, the accuracy is higher, which is different from the human data- accuracy was higher when the context was in the same sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_ctx</th>\n",
       "      <th>centroid_acc</th>\n",
       "      <th>nn_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>curr</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.595238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prev</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentence_ctx  centroid_acc    nn_acc\n",
       "0         curr      0.595238  0.595238\n",
       "1         prev      0.642857  0.619048"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_table(all_data, \"sentence_ctx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:bert]",
   "language": "python",
   "name": "conda-env-bert-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
